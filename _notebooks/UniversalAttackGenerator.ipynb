{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UniversalAttackGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPyNJ1D18NsHb0fkrKZ4j2e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-mehabadi/grad-maker/blob/main/_notebooks/UniversalAttackGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Areas:\n",
        "* Domain Generalization in Classification\n",
        "* Domain Generalization in Mitosis Detection\n",
        "* Universal Adversarial Example Generator\n",
        "* An Aproach to Optimize Robustness and Performance Simultaneously\n",
        "* Multi-Tasking using GradMaker\n",
        "* Applications in Federated Learning\n"
      ],
      "metadata": {
        "id": "E8WgzonygTWZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJMQ7eV0h8OH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import gc\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# config\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# Param\n",
        "num_epochs = 1\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "u74EILoTirev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST datasets\n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "# MNIST dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "wArywMbNix04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN(two layer)\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(7 * 7 * 32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "zj9hJEY-iYaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet(num_classes).to(device)\n",
        "\n",
        "# Loss and optimize\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train\n",
        "model.train()\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backprop and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{total_step}], Training Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "print(f'Model Accuracy on the 10000 test images: {validate(model, test_loader):.4f} %')"
      ],
      "metadata": {
        "id": "8oNT6HY4i95Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7251710b-5fbe-48ae-dcb6-b442d56a957a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [100/600], Training Loss: 0.1575\n",
            "Epoch [1/1], Step [200/600], Training Loss: 0.1005\n",
            "Epoch [1/1], Step [300/600], Training Loss: 0.0808\n",
            "Epoch [1/1], Step [400/600], Training Loss: 0.0707\n",
            "Epoch [1/1], Step [500/600], Training Loss: 0.0668\n",
            "Epoch [1/1], Step [600/600], Training Loss: 0.0631\n",
            "Model Accuracy on the 10000 test images: 98.5800 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now let's generate the attack\n"
      ],
      "metadata": {
        "id": "1Gu0Na3Cm17K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gc_collect(*vars):\n",
        "    for var in vars:\n",
        "        del var\n",
        "    gc.collect()\n",
        "\n",
        "def empty_cache():\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "JOMa4bXAqURa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adv_clip(adv, real, alpha=0):\n",
        "    return torch.clamp(adv, min=torch.clamp(real-alpha, min=0.),\n",
        "                       max=torch.clamp(real+alpha, max=1.))"
      ],
      "metadata": {
        "id": "EZRHHYGPtooo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(model, X, y):\n",
        "    outputs = model(X)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total = y.size(0)\n",
        "    correct = (predicted == y).sum().item()\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "Cd_ila4WwHzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_maker(domain_grads, epsilon=0.5, alpha=0.05, alpha_schedule='exp'):\n",
        "    iters = 50000\n",
        "    dgr = domain_grads.view(domain_grads.shape[0], -1).to(device)\n",
        "    number_of_domains, dim = dgr.shape\n",
        "\n",
        "    #\n",
        "    g = torch.randn(dim).to(device)\n",
        "    u_ = torch.zeros(number_of_domains).to(device)\n",
        "    \n",
        "    iter = 0\n",
        "    while (not torch.abs(torch.min(dgr@g)-epsilon)<=0.001) and (iter < iters):\n",
        "        u_ = u_ + alpha*(epsilon - (dgr@g))\n",
        "        g = (1./number_of_domains)*torch.sum(((1+(u_>=0)*u_).reshape(number_of_domains, 1))*dgr, axis=0)\n",
        "        iter += 1\n",
        "    return g.view(domain_grads.shape[1:])"
      ],
      "metadata": {
        "id": "dPUqrpyqxrDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, dloader, pert=None, is_batched=True):\n",
        "    model.eval()\n",
        "    # with torch.no_grad()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    if pert is not None:\n",
        "        pert_ = pert(model, dloader) if not is_batched else None\n",
        "    for images, labels in dloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        if pert is not None:\n",
        "            print(\"213123\")\n",
        "            print(f\"X.size()={images.size()}, y.size()={labels.size()}\")\n",
        "            images = Variable(images.clone(), requires_grad=True)\n",
        "            # labels = Variable(labels.clone(), requires_grad=True)\n",
        "            print(images.requires_grad)\n",
        "            pert_ = pert(model, images, labels) if is_batched else pert_\n",
        "            print(\"12432544\")\n",
        "            images = images.data.detach() + pert_.data.detach()\n",
        "            gc_collect(pert_, images, labels)\n",
        "            empty_cache()\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    return (100 * correct / total)"
      ],
      "metadata": {
        "id": "xbwHn38JktUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate(model, train_loader, fgsm, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "_Bga54ilxi6S",
        "outputId": "d56cf002-ac2f-4080-ecf2-56f4a2e4e20b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "213123\n",
            "X.size()=torch.Size([100, 1, 28, 28]), y.size()=torch.Size([100])\n",
            "True\n",
            "84723ryskdfhaszjkdaslkdj\n",
            "12432544\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-57bab512d8a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgsm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-102-25dde1c6f15b>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dloader, pert, is_batched)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mpert_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_batched\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpert_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"12432544\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mimages\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpert_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mgc_collect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpert_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: a leaf Variable that requires grad is being used in an in-place operation."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = next(iter(train_loader))\n",
        "X, y = X.to(device), y.to(device)\n",
        "# dX(model,X, y)\n",
        "print(f\"X.size()={X.size()}, y.size()={y.size()}\")\n",
        "fgsm(model, X, y).size()"
      ],
      "metadata": {
        "id": "AxR7cAhJwhT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dX(model, X, y):\n",
        "    # X = Variable(X.data, requires_grad=True)\n",
        "    outputs = model(X)\n",
        "    loss = F.cross_entropy(outputs, y)\n",
        "    # X.retain_grad()\n",
        "    print(\"84723ryskdfhaszjkdaslkdj\")\n",
        "    loss.backward()\n",
        "    # print(\"84723ryskdfhaszjkdaslkdj\")\n",
        "    return X.grad.data.clone()\n",
        "\n",
        "def fgsm(model, X, y, eps=0.1):\n",
        "    advs = X + eps * torch.sign(dX(model, X, y))\n",
        "    return adv_clip(advs, X, alpha=eps) - X\n",
        "\n",
        "def universal_v1(model, X, y, alpha=0.01, steps=20, eps=0.15):\n",
        "    X_first = X.clone()\n",
        "    for step in range(steps):\n",
        "        X_grad = dX(model, X, y)\n",
        "        X_advs = adv_clip(X + alpha * torch.sign(gradient_maker(X_grad)), X, eps)\n",
        "        X = Variable(X_advs.data, requires_grad=False)\n",
        "        \n",
        "        #\n",
        "        gc_collect(X, X_advs)\n",
        "        empty_cache()\n",
        "    return X - X_first\n",
        "\n",
        "def universal_v2(model, dataloader, alpha=0.01, steps=20, eps=0.15):\n",
        "    pert = None\n",
        "    for step in range(steps):\n",
        "        grads = []\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            if pert is None:\n",
        "                pert = torch.zeros_like(images)\n",
        "            images_grads = dX(model, adv_clip(images + pert), labels)\n",
        "            grads.append(gradient_maker(images_grads))\n",
        "        pert += alpha * torch.sign(gradient_maker(torch.stack((grads))))\n",
        "    return pert"
      ],
      "metadata": {
        "id": "AMvW44JI2HO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate(model, train_loader, fgsm, is_batched=True)"
      ],
      "metadata": {
        "id": "jiseeISyTTFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validate(model, train_loader, None)"
      ],
      "metadata": {
        "id": "0xP9sJrrTLVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validate(model, test_loader, None)"
      ],
      "metadata": {
        "id": "WWkvIBfXTQ0i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}