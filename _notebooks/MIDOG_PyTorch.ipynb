{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-mehabadi/grad-maker/blob/main/_notebooks/MIDOG_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vdrTb_ri5wU"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torchvision\n",
        "\n",
        "# from torchvision.models.detection import retinanet_resnet50_fpn\n",
        "# from torchvision.ops import sigmoid_focal_loss\n",
        "# from torch.optim import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YL1dcDWrL2in",
        "outputId": "7906e7bc-f34e-4ac3-a8ce-7e9a0ef9899e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (5.5.0)\n",
            "Collecting plotly\n",
            "  Downloading plotly-5.7.0-py2.py3-none-any.whl (28.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 28.8 MB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly) (1.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly) (8.0.1)\n",
            "Installing collected packages: plotly\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.5.0\n",
            "    Uninstalling plotly-5.5.0:\n",
            "      Successfully uninstalled plotly-5.5.0\n",
            "Successfully installed plotly-5.7.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  javascript-common libjs-jquery libopenslide0 python-asn1crypto\n",
            "  python-blinker python-cffi-backend python-click python-colorama\n",
            "  python-cryptography python-enum34 python-flask python-idna python-ipaddress\n",
            "  python-itsdangerous python-jinja2 python-markupsafe\n",
            "  python-openslide-examples python-openssl python-pkg-resources\n",
            "  python-pyinotify python-simplejson python-six python-werkzeug\n",
            "  python3-olefile python3-pil\n",
            "Suggested packages:\n",
            "  apache2 | lighttpd | httpd python-blinker-doc python-cryptography-doc\n",
            "  python-cryptography-vectors python-enum34-doc python-flask-doc\n",
            "  python-jinja2-doc python-openssl-doc python-openssl-dbg python-setuptools\n",
            "  python-pyinotify-doc ipython python-genshi python-lxml python-greenlet\n",
            "  python-redis python-pylibmc | python-memcache python-termcolor\n",
            "  python-watchdog python-werkzeug-doc python-pil-doc python3-pil-dbg\n",
            "The following NEW packages will be installed:\n",
            "  javascript-common libjs-jquery libopenslide0 python-asn1crypto\n",
            "  python-blinker python-cffi-backend python-click python-colorama\n",
            "  python-cryptography python-enum34 python-flask python-idna python-ipaddress\n",
            "  python-itsdangerous python-jinja2 python-markupsafe\n",
            "  python-openslide-examples python-openssl python-pkg-resources\n",
            "  python-pyinotify python-simplejson python-six python-werkzeug\n",
            "  python3-olefile python3-openslide python3-pil\n",
            "0 upgraded, 26 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 1,998 kB of archives.\n",
            "After this operation, 9,740 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 javascript-common all 11 [6,066 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjs-jquery all 3.2.1-1 [152 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenslide0 amd64 3.4.1+dfsg-2 [79.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-asn1crypto all 0.24.0-1 [72.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-blinker all 1.4+dfsg1-0.1 [13.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-cffi-backend amd64 1.11.5-1 [63.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-colorama all 0.3.7-1 [22.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-click all 6.7-3 [56.4 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-enum34 all 1.1.6-2 [34.8 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-idna all 2.6-1 [32.4 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-ipaddress all 1.0.17-1 [18.2 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-cryptography amd64 2.1.4-1ubuntu1.4 [276 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-itsdangerous all 0.24+dfsg1-2 [11.9 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-markupsafe amd64 1.0-1build1 [13.0 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-jinja2 all 2.10-1ubuntu0.18.04.1 [94.8 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-werkzeug all 0.14.1+dfsg1-1ubuntu0.1 [174 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-flask all 0.12.2-3ubuntu0.1 [62.4 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-pil amd64 5.1.0-1ubuntu0.7 [331 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-openslide amd64 1.1.1-2ubuntu4 [16.1 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-openslide-examples all 1.1.1-2ubuntu4 [168 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-openssl all 17.5.0-1ubuntu1 [41.3 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pyinotify all 0.9.6-1 [24.6 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-simplejson amd64 3.13.2-1 [61.2 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-olefile all 0.45.1-1 [33.3 kB]\n",
            "Fetched 1,998 kB in 0s (4,477 kB/s)\n",
            "Selecting previously unselected package javascript-common.\n",
            "(Reading database ... 155455 files and directories currently installed.)\n",
            "Preparing to unpack .../00-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../01-libjs-jquery_3.2.1-1_all.deb ...\n",
            "Unpacking libjs-jquery (3.2.1-1) ...\n",
            "Selecting previously unselected package libopenslide0.\n",
            "Preparing to unpack .../02-libopenslide0_3.4.1+dfsg-2_amd64.deb ...\n",
            "Unpacking libopenslide0 (3.4.1+dfsg-2) ...\n",
            "Selecting previously unselected package python-asn1crypto.\n",
            "Preparing to unpack .../03-python-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python-blinker.\n",
            "Preparing to unpack .../04-python-blinker_1.4+dfsg1-0.1_all.deb ...\n",
            "Unpacking python-blinker (1.4+dfsg1-0.1) ...\n",
            "Selecting previously unselected package python-cffi-backend.\n",
            "Preparing to unpack .../05-python-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python-colorama.\n",
            "Preparing to unpack .../06-python-colorama_0.3.7-1_all.deb ...\n",
            "Unpacking python-colorama (0.3.7-1) ...\n",
            "Selecting previously unselected package python-click.\n",
            "Preparing to unpack .../07-python-click_6.7-3_all.deb ...\n",
            "Unpacking python-click (6.7-3) ...\n",
            "Selecting previously unselected package python-enum34.\n",
            "Preparing to unpack .../08-python-enum34_1.1.6-2_all.deb ...\n",
            "Unpacking python-enum34 (1.1.6-2) ...\n",
            "Selecting previously unselected package python-idna.\n",
            "Preparing to unpack .../09-python-idna_2.6-1_all.deb ...\n",
            "Unpacking python-idna (2.6-1) ...\n",
            "Selecting previously unselected package python-ipaddress.\n",
            "Preparing to unpack .../10-python-ipaddress_1.0.17-1_all.deb ...\n",
            "Unpacking python-ipaddress (1.0.17-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../11-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-cryptography.\n",
            "Preparing to unpack .../12-python-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking python-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Selecting previously unselected package python-itsdangerous.\n",
            "Preparing to unpack .../13-python-itsdangerous_0.24+dfsg1-2_all.deb ...\n",
            "Unpacking python-itsdangerous (0.24+dfsg1-2) ...\n",
            "Selecting previously unselected package python-markupsafe.\n",
            "Preparing to unpack .../14-python-markupsafe_1.0-1build1_amd64.deb ...\n",
            "Unpacking python-markupsafe (1.0-1build1) ...\n",
            "Selecting previously unselected package python-jinja2.\n",
            "Preparing to unpack .../15-python-jinja2_2.10-1ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking python-jinja2 (2.10-1ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package python-werkzeug.\n",
            "Preparing to unpack .../16-python-werkzeug_0.14.1+dfsg1-1ubuntu0.1_all.deb ...\n",
            "Unpacking python-werkzeug (0.14.1+dfsg1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-flask.\n",
            "Preparing to unpack .../17-python-flask_0.12.2-3ubuntu0.1_all.deb ...\n",
            "Unpacking python-flask (0.12.2-3ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-pil:amd64.\n",
            "Preparing to unpack .../18-python3-pil_5.1.0-1ubuntu0.7_amd64.deb ...\n",
            "Unpacking python3-pil:amd64 (5.1.0-1ubuntu0.7) ...\n",
            "Selecting previously unselected package python3-openslide.\n",
            "Preparing to unpack .../19-python3-openslide_1.1.1-2ubuntu4_amd64.deb ...\n",
            "Unpacking python3-openslide (1.1.1-2ubuntu4) ...\n",
            "Selecting previously unselected package python-openslide-examples.\n",
            "Preparing to unpack .../20-python-openslide-examples_1.1.1-2ubuntu4_all.deb ...\n",
            "Unpacking python-openslide-examples (1.1.1-2ubuntu4) ...\n",
            "Selecting previously unselected package python-openssl.\n",
            "Preparing to unpack .../21-python-openssl_17.5.0-1ubuntu1_all.deb ...\n",
            "Unpacking python-openssl (17.5.0-1ubuntu1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../22-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-pyinotify.\n",
            "Preparing to unpack .../23-python-pyinotify_0.9.6-1_all.deb ...\n",
            "Unpacking python-pyinotify (0.9.6-1) ...\n",
            "Selecting previously unselected package python-simplejson.\n",
            "Preparing to unpack .../24-python-simplejson_3.13.2-1_amd64.deb ...\n",
            "Unpacking python-simplejson (3.13.2-1) ...\n",
            "Selecting previously unselected package python3-olefile.\n",
            "Preparing to unpack .../25-python3-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python3-olefile (0.45.1-1) ...\n",
            "Setting up python-idna (2.6-1) ...\n",
            "Setting up python-simplejson (3.13.2-1) ...\n",
            "Setting up libjs-jquery (3.2.1-1) ...\n",
            "Setting up python-asn1crypto (0.24.0-1) ...\n",
            "Setting up python3-pil:amd64 (5.1.0-1ubuntu0.7) ...\n",
            "Setting up python-blinker (1.4+dfsg1-0.1) ...\n",
            "Setting up python3-olefile (0.45.1-1) ...\n",
            "Setting up python-colorama (0.3.7-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-markupsafe (1.0-1build1) ...\n",
            "Setting up python-werkzeug (0.14.1+dfsg1-1ubuntu0.1) ...\n",
            "Setting up python-pyinotify (0.9.6-1) ...\n",
            "Setting up python-cffi-backend (1.11.5-1) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up libopenslide0 (3.4.1+dfsg-2) ...\n",
            "Setting up python-enum34 (1.1.6-2) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up python-itsdangerous (0.24+dfsg1-2) ...\n",
            "Setting up python-ipaddress (1.0.17-1) ...\n",
            "Setting up python-jinja2 (2.10-1ubuntu0.18.04.1) ...\n",
            "Setting up python-click (6.7-3) ...\n",
            "Setting up python3-openslide (1.1.1-2ubuntu4) ...\n",
            "Setting up python-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Setting up python-flask (0.12.2-3ubuntu0.1) ...\n",
            "Setting up python-openssl (17.5.0-1ubuntu1) ...\n",
            "Setting up python-openslide-examples (1.1.1-2ubuntu4) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting object-detection-fastai\n",
            "  Downloading object_detection_fastai-0.0.10-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from object-detection-fastai) (1.0.2)\n",
            "Requirement already satisfied: openslide-python>=1.1.1 in /usr/lib/python3/dist-packages (from object-detection-fastai) (1.1.1)\n",
            "Requirement already satisfied: fastai==1.0.61 in /usr/local/lib/python3.7/dist-packages (from object-detection-fastai) (1.0.61)\n",
            "Requirement already satisfied: torchvision>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from object-detection-fastai) (0.11.1+cu111)\n",
            "Collecting opencv-python>=4.5.1.48\n",
            "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.5 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from object-detection-fastai) (1.21.5)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from object-detection-fastai) (1.10.0+cu111)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61->object-detection-fastai) (1.4.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61->object-detection-fastai) (4.6.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61->object-detection-fastai) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61->object-detection-fastai) (2.23.0)\n",
            "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61->object-detection-fastai) (1.0.2)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61->object-detection-fastai) (7.352.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61->object-detection-fastai) (7.1.2)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61->object-detection-fastai) (1.3.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61->object-detection-fastai) (3.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61->object-detection-fastai) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61->object-detection-fastai) (1.3.5)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61->object-detection-fastai) (2.8.1)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.61->object-detection-fastai) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.61->object-detection-fastai) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.61->object-detection-fastai) (2.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.61->object-detection-fastai) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.61->object-detection-fastai) (4.64.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.61->object-detection-fastai) (3.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.61->object-detection-fastai) (0.9.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.61->object-detection-fastai) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.61->object-detection-fastai) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.61->object-detection-fastai) (1.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.61->object-detection-fastai) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.61->object-detection-fastai) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.61->object-detection-fastai) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.61->object-detection-fastai) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.61->object-detection-fastai) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.61->object-detection-fastai) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.61->object-detection-fastai) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.61->object-detection-fastai) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.61->object-detection-fastai) (2.10)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.61->object-detection-fastai) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.61->object-detection-fastai) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.61->object-detection-fastai) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.61->object-detection-fastai) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai==1.0.61->object-detection-fastai) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==1.0.61->object-detection-fastai) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->object-detection-fastai) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->object-detection-fastai) (3.1.0)\n",
            "Installing collected packages: opencv-python, object-detection-fastai\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed object-detection-fastai-0.0.10 opencv-python-4.5.5.64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "!pip install -U plotly\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "# import plotly\n",
        "# import plotly.graph_objects as go\n",
        "# import plotly.express as px\n",
        "# from plotly.subplots import make_subplots\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "!apt-get install python3-openslide\n",
        "from openslide import open_slide\n",
        "\n",
        "!pip install -U object-detection-fastai\n",
        "\n",
        "from object_detection_fastai.helper.wsi_loader import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hx_1Uo1OKTDF",
        "outputId": "f175af78-6ac0-46a8-a66c-50cefd451767"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')\n",
        "\n",
        "folder = \"MyDrive/MIDOG_Challenge\" #param {type:\"string\"}\n",
        "midog_folder = Path(\"/drive\") / Path(folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_d9wFimCL7_O",
        "outputId": "5c3b78f3-d26e-4a09-d0fa-a369386c750e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  file_name  image_id  width  height                             box  \\\n",
              "0  001.tiff         1   7215    5412          [4336, 346, 4386, 396]   \n",
              "1  001.tiff         1   7215    5412            [756, 872, 806, 922]   \n",
              "2  001.tiff         1   7215    5412          [270, 4044, 320, 4094]   \n",
              "3  001.tiff         1   7215    5412  [6672.5, 706.5, 6722.5, 756.5]   \n",
              "4  002.tiff         2   7215    5412          [1872, 319, 1922, 369]   \n",
              "\n",
              "             cat       scanner  \n",
              "0  hard negative  Hamamatsu XR  \n",
              "1  hard negative  Hamamatsu XR  \n",
              "2  hard negative  Hamamatsu XR  \n",
              "3  hard negative  Hamamatsu XR  \n",
              "4  hard negative  Hamamatsu XR  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab54e786-e738-4831-81dc-095092fb9f34\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>image_id</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>box</th>\n",
              "      <th>cat</th>\n",
              "      <th>scanner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001.tiff</td>\n",
              "      <td>1</td>\n",
              "      <td>7215</td>\n",
              "      <td>5412</td>\n",
              "      <td>[4336, 346, 4386, 396]</td>\n",
              "      <td>hard negative</td>\n",
              "      <td>Hamamatsu XR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001.tiff</td>\n",
              "      <td>1</td>\n",
              "      <td>7215</td>\n",
              "      <td>5412</td>\n",
              "      <td>[756, 872, 806, 922]</td>\n",
              "      <td>hard negative</td>\n",
              "      <td>Hamamatsu XR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001.tiff</td>\n",
              "      <td>1</td>\n",
              "      <td>7215</td>\n",
              "      <td>5412</td>\n",
              "      <td>[270, 4044, 320, 4094]</td>\n",
              "      <td>hard negative</td>\n",
              "      <td>Hamamatsu XR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>001.tiff</td>\n",
              "      <td>1</td>\n",
              "      <td>7215</td>\n",
              "      <td>5412</td>\n",
              "      <td>[6672.5, 706.5, 6722.5, 756.5]</td>\n",
              "      <td>hard negative</td>\n",
              "      <td>Hamamatsu XR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>002.tiff</td>\n",
              "      <td>2</td>\n",
              "      <td>7215</td>\n",
              "      <td>5412</td>\n",
              "      <td>[1872, 319, 1922, 369]</td>\n",
              "      <td>hard negative</td>\n",
              "      <td>Hamamatsu XR</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab54e786-e738-4831-81dc-095092fb9f34')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab54e786-e738-4831-81dc-095092fb9f34 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab54e786-e738-4831-81dc-095092fb9f34');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "annotation_file = midog_folder / \"MIDOG.json\"\n",
        "image_folder = midog_folder / \"images\"\n",
        "\n",
        "hamamatsu_rx_ids = list(range(0, 51))\n",
        "hamamatsu_360_ids = list(range(51, 101))\n",
        "aperio_ids = list(range(101, 151))\n",
        "leica_ids = list(range(151, 201))\n",
        "\n",
        "rows = []\n",
        "with open(annotation_file) as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "    #categories = {cat[\"id\"]: cat[\"name\"] for cat in data[\"categories\"]}\n",
        "    categories = {1: 'mitotic figure', 2: 'hard negative'}\n",
        "\n",
        "    for row in data[\"images\"]:\n",
        "        file_name = row[\"file_name\"]\n",
        "        image_id = row[\"id\"]\n",
        "        width = row[\"width\"]\n",
        "        height = row[\"height\"]\n",
        "\n",
        "        scanner  = \"Hamamatsu XR\"\n",
        "        if image_id in hamamatsu_360_ids:\n",
        "            scanner  = \"Hamamatsu S360\"\n",
        "        if image_id in aperio_ids:\n",
        "            scanner  = \"Aperio CS\"\n",
        "        if image_id in leica_ids:\n",
        "            scanner  = \"Leica GT450\"\n",
        "         \n",
        "        for annotation in [anno for anno in data['annotations'] if anno[\"image_id\"] == image_id]:\n",
        "            box = annotation[\"bbox\"]\n",
        "            cat = categories[annotation[\"category_id\"]]\n",
        "\n",
        "            rows.append([file_name, image_id, width, height, box, cat, scanner])\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\"file_name\", \"image_id\", \"width\", \"height\", \"box\", \"cat\", \"scanner\"])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tndWOPFMNmDW"
      },
      "outputs": [],
      "source": [
        "def sample_function(y, classes, size, level_dimensions, level):\n",
        "    width, height = level_dimensions[level]\n",
        "    if len(y[0]) == 0:\n",
        "        return randint(0, width - size[0]), randint(0, height -size[1])\n",
        "    else:\n",
        "        #if randint(0, 5) < 2:\n",
        "        if True:\n",
        "            class_id = np.random.choice(classes, 1)[0] # select a random class\n",
        "            ids = np.array(y[1]) == class_id # filter the annotations according to the selected class\n",
        "            xmin, ymin, _, _ = np.array(y[0])[ids][randint(0, np.count_nonzero(ids) - 1)] # randomly select one of the filtered annotatons as seed for the training patch\n",
        "            \n",
        "            # To have the selected annotation not in the center of the patch and an random offset.\n",
        "            xmin += random.randint(-size[0]/2, size[0]/2) \n",
        "            ymin += random.randint(-size[1]/2, size[1]/2)\n",
        "            xmin, ymin = max(0, int(xmin - size[0] / 2)), max(0, int(ymin -size[1] / 2))\n",
        "            xmin, ymin = min(xmin, width - size[0]), min(ymin, height - size[1])\n",
        "            return xmin, ymin\n",
        "        else:\n",
        "            return randint(0, width - size[0]), randint(0, height -size[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88EiKHq2O_eh"
      },
      "outputs": [],
      "source": [
        "def create_wsi_container(annotations_df: pd.DataFrame):\n",
        "\n",
        "    container = []\n",
        "\n",
        "    for image_name in tqdm(annotations_df[\"file_name\"].unique()):\n",
        "\n",
        "        image_annos = annotations_df[annotations_df[\"file_name\"] == image_name]\n",
        "\n",
        "        bboxes = [box   for box   in image_annos[\"box\"]]\n",
        "        labels = [label for label in image_annos[\"cat\"]]\n",
        "\n",
        "        container.append(SlideContainer(image_folder/image_name, y=[bboxes, labels], level=res_level,width=patch_size, height=patch_size, sample_func=sample_function))\n",
        "\n",
        "    return container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "YMKiW-ulLEVJ",
        "outputId": "42a5bb50-b18f-4cb2-991e-063d57af795e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:14<00:00,  3.42it/s]\n",
            "100%|██████████| 50/50 [00:27<00:00,  1.80it/s]\n",
            "100%|██████████| 50/50 [00:22<00:00,  2.24it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Created: 50 training WSI container and 50 validation WSI container'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_scanner = \"Hamamatsu XR\" #param [\"Hamamatsu XR\", \"Hamamatsu S360\", \"Aperio CS\"]  {allow-input: true}\n",
        "train2_scanner = \"Aperio CS\" #param [\"Hamamatsu XR\", \"Hamamatsu S360\", \"Aperio CS\"]  {allow-input: true}\n",
        "val_scanner = \"Hamamatsu S360\" #param [\"Hamamatsu XR\", \"Hamamatsu S360\", \"Aperio CS\"]  {allow-input: true}\n",
        "\n",
        "patch_size = 256 #param [256, 512, 1024]\n",
        "res_level = 0\n",
        "\n",
        "train_annos = df[df[\"scanner\"].isin(train_scanner.split(\",\"))]\n",
        "train_container = create_wsi_container(train_annos)\n",
        "\n",
        "train2_annos = df[df[\"scanner\"].isin(train2_scanner.split(\",\"))]\n",
        "train2_container = create_wsi_container(train2_annos)\n",
        "\n",
        "val_annos = df[df[\"scanner\"].isin(val_scanner.split(\",\"))]\n",
        "valid_container = create_wsi_container(val_annos)\n",
        "\n",
        "f\"Created: {len(train_container)} training WSI container and {len(valid_container)} validation WSI container\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qRKGGHTM4hB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "train_samples_per_scanner = 100 #param {type:\"integer\"} 1500\n",
        "val_samples_per_scanner = 50 #param {type:\"integer\"} 500\n",
        "\n",
        "train_images = list(np.random.choice(train_container, train_samples_per_scanner))\n",
        "train2_images = list(np.random.choice(train2_container, train_samples_per_scanner))\n",
        "valid_images = list(np.random.choice(valid_container, val_samples_per_scanner))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOd6KMmOQURo",
        "outputId": "0e8f999e-7edf-48a4-d880-60ad51a03706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/fastai/vision/transform.py:247: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release.\n",
            "torch.linalg.solve has its arguments reversed and does not return the LU factorization.\n",
            "To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack.\n",
            "X = torch.solve(B, A).solution\n",
            "should be replaced with\n",
            "X = torch.linalg.solve(A, B) (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:766.)\n",
            "  return _solve_func(B,A)[0][:,0]\n"
          ]
        }
      ],
      "source": [
        "batch_size = 4 #param {type:\"integer\"}\n",
        "\n",
        "#markdown Lets add some basic data [augmentation](https://docs.fast.ai/vision.augment.html)\n",
        "do_flip = True #param {type:\"boolean\"}\n",
        "flip_vert = True #param {type:\"boolean\"}\n",
        "max_rotate = 90 #param {type:\"number\"}\n",
        "max_zoom = 1.1 #param {type:\"number\"}\n",
        "max_lighting = 0.2 #param {type:\"number\"}\n",
        "max_warp = 0.2 #param {type:\"number\"}\n",
        "p_affine = 0.75 #param {type:\"number\"}\n",
        "p_lighting = 0.75 #param {type:\"number\"}\n",
        "\n",
        "\n",
        "\n",
        "tfms = get_transforms(do_flip=do_flip,\n",
        "                      flip_vert=flip_vert,\n",
        "                      max_rotate=max_rotate,\n",
        "                      max_zoom=max_zoom,\n",
        "                      max_lighting=max_lighting,\n",
        "                      max_warp=max_warp,\n",
        "                      p_affine=p_affine,\n",
        "                      p_lighting=p_lighting)\n",
        "\n",
        "train, train2, valid = ObjectItemListSlide(train_images), ObjectItemListSlide(train2_images), ObjectItemListSlide(valid_images)\n",
        "\n",
        "class ImageBBox(ImagePoints):\n",
        "    \"Support applying transforms to a `flow` of bounding boxes.\"\n",
        "    def __init__(self, flow:FlowField, scale:bool=True, y_first:bool=True, labels:Collection=None,\n",
        "                 classes:dict=None, pad_idx:int=0):\n",
        "        super().__init__(flow, scale, y_first)\n",
        "        self.pad_idx = pad_idx\n",
        "        if labels is not None and len(labels)>0 and not isinstance(labels[0],Category):\n",
        "            labels = array([Category(l,classes[l]) for l in labels])\n",
        "        self.labels = labels\n",
        "\n",
        "    def clone(self) -> 'ImageBBox':\n",
        "        \"Mimic the behavior of torch.clone for `Image` objects.\"\n",
        "        flow = FlowField(self.size, self.flow.flow.clone())\n",
        "        return self.__class__(flow, scale=False, y_first=False, labels=self.labels, pad_idx=self.pad_idx)\n",
        "\n",
        "    @classmethod\n",
        "    def create(cls, h:int, w:int, bboxes:Collection[Collection[int]], labels:Collection=None, classes:dict=None,\n",
        "               pad_idx:int=0, scale:bool=True)->'ImageBBox':\n",
        "        \"Create an ImageBBox object from `bboxes`.\"\n",
        "        if isinstance(bboxes, np.ndarray) and bboxes.dtype == np.object: bboxes = np.array([bb for bb in bboxes])\n",
        "        bboxes = tensor(bboxes).float()\n",
        "        tr_corners = torch.cat([bboxes[:,0][:,None], bboxes[:,3][:,None]], 1)\n",
        "        bl_corners = bboxes[:,1:3].flip(1)\n",
        "        bboxes = torch.cat([bboxes[:,:2], tr_corners, bl_corners, bboxes[:,2:]], 1)\n",
        "        flow = FlowField((h,w), bboxes.view(-1,2))\n",
        "        return cls(flow, labels=labels, classes=classes, pad_idx=pad_idx, y_first=True, scale=scale)\n",
        "\n",
        "    def _compute_boxes(self) -> Tuple[LongTensor, LongTensor]:\n",
        "        bboxes = self.flow.flow.flip(1).view(-1, 4, 2).contiguous()\n",
        "        mins, maxes = bboxes.min(dim=1)[0], bboxes.max(dim=1)[0]\n",
        "        bboxes = torch.cat([mins, maxes], 1)\n",
        "        mask = (bboxes[:,2]-bboxes[:,0] > 0) * (bboxes[:,3]-bboxes[:,1] > 0)\n",
        "        if len(mask) == 0: return tensor([self.pad_idx] * 4), tensor([self.pad_idx])\n",
        "        res = bboxes[mask]\n",
        "        if self.labels is None: return res,None\n",
        "        return res, self.labels[to_np(mask).astype(bool)]\n",
        "\n",
        "    @property\n",
        "    def data(self)->Union[FloatTensor, Tuple[FloatTensor,LongTensor]]:\n",
        "        bboxes,lbls = self._compute_boxes()\n",
        "        lbls = np.array([o.data for o in lbls]) if lbls is not None else None\n",
        "        return bboxes if lbls is None else (bboxes, lbls)\n",
        "\n",
        "    def show(self, y:Image=None, ax:plt.Axes=None, figsize:tuple=(3,3), title:Optional[str]=None, hide_axis:bool=True,\n",
        "        color:str='white', **kwargs):\n",
        "        \"Show the `ImageBBox` on `ax`.\"\n",
        "        if ax is None: _,ax = plt.subplots(figsize=figsize)\n",
        "        bboxes, lbls = self._compute_boxes()\n",
        "        h,w = self.flow.size\n",
        "        bboxes.add_(1).mul_(torch.tensor([h/2, w/2, h/2, w/2])).long()\n",
        "        for i, bbox in enumerate(bboxes):\n",
        "            if lbls is not None: text = str(lbls[i])\n",
        "            else: text=None\n",
        "            _draw_rect(ax, bb2hw(bbox), text=text, color=color)\n",
        "\n",
        "\n",
        "class SlideObjectCategoryList(ObjectCategoryList):\n",
        "\n",
        "    def get(self, i, x: int=0, y: int=0):\n",
        "        h, w = self.x.items[i].shape\n",
        "        bboxes, labels = self.items[i]\n",
        "\n",
        "        bboxes = np.array([box for box in bboxes]) if len(np.array(bboxes).shape) == 1 else  np.array(bboxes)\n",
        "        labels = np.array(labels)\n",
        "\n",
        "        if len(labels) > 0:\n",
        "            bboxes[:, [0, 2]] = bboxes[:, [0, 2]] - x\n",
        "            bboxes[:, [1, 3]] = bboxes[:, [1, 3]] - y\n",
        "\n",
        "            bb_widths = (bboxes[:, 2] - bboxes[:, 0]) / 2\n",
        "            bb_heights = (bboxes[:, 3] - bboxes[:, 1]) / 2\n",
        "\n",
        "            ids = ((bboxes[:, 0] + bb_widths) > 0) \\\n",
        "                      & ((bboxes[:, 1] + bb_heights) > 0) \\\n",
        "                      & ((bboxes[:, 2] - bb_widths) < w) \\\n",
        "                      & ((bboxes[:, 3] - bb_heights) < h)\n",
        "\n",
        "            bboxes = bboxes[ids]\n",
        "            bboxes = np.clip(bboxes, 0, max(h,w))\n",
        "            bboxes = bboxes[:, [1, 0, 3, 2]]\n",
        "\n",
        "\n",
        "            labels = labels[ids]\n",
        "        \n",
        "        if len(labels) == 0:\n",
        "            labels = np.array([0])\n",
        "            bboxes = np.array([[0, 0, patch_size, patch_size]])\n",
        "\n",
        "        xx = ImageBBox.create(h, w, bboxes, labels, classes=self.classes, pad_idx=self.pad_idx, scale=True)\n",
        "        # print(xx.data)\n",
        "        s = torch.tensor([xx.flow.size[0]/2, xx.flow.size[1]/2])[None]\n",
        "        xx.flow.flow = (xx.flow.flow+1)*s[0][0]\n",
        "        # print(xx.data)\n",
        "        # print(xx.data)\n",
        "        return xx\n",
        "\n",
        "\n",
        "\n",
        "item_list = ItemLists(\".\", train, valid)\n",
        "lls = item_list.label_from_func(lambda x: x.y, label_cls=SlideObjectCategoryList)\n",
        "lls = lls.transform(tfms, tfm_y=False, size=patch_size)\n",
        "data = lls.databunch(bs=batch_size, collate_fn=bb_pad_collate,num_workers=0).normalize()\n",
        "\n",
        "item2_list = ItemLists(\".\", train2, valid)\n",
        "lls2 = item2_list.label_from_func(lambda x: x.y, label_cls=SlideObjectCategoryList)\n",
        "lls2 = lls2.transform(tfms, tfm_y=False, size=patch_size)\n",
        "data2 = lls2.databunch(bs=batch_size, collate_fn=bb_pad_collate,num_workers=0).normalize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdqoSQ17j3oN"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGvV5w5EqxVF"
      },
      "outputs": [],
      "source": [
        "from random import shuffle\n",
        "\n",
        "def pcgrad(domain_grads):\n",
        "    \"\"\" Projecting conflicting gradients (PCGrad). \"\"\"\n",
        "    task_order = list(range(len(domain_grads)))\n",
        "\n",
        "    # Run tasks in random order\n",
        "    shuffle(task_order)\n",
        "\n",
        "    # Initialize task gradients\n",
        "    grad_pc = [g.clone() for g in domain_grads]\n",
        "\n",
        "    for i in task_order:\n",
        "\n",
        "        # Run other tasks\n",
        "        other_tasks = [j for j in task_order if j != i]\n",
        "\n",
        "        for j in other_tasks:\n",
        "            grad_j = domain_grads[j]\n",
        "\n",
        "            # Compute inner product and check for conflicting gradients\n",
        "            inner_prod = torch.dot(grad_pc[i], grad_j)\n",
        "            if inner_prod < 0:\n",
        "                # Sustract the conflicting component\n",
        "                grad_pc[i] -= inner_prod / (grad_j ** 2).sum() * grad_j\n",
        "\n",
        "    # Sum task gradients\n",
        "    new_grads = torch.stack(grad_pc).sum(0)\n",
        "\n",
        "    return new_grads\n",
        "\n",
        "def gradient_maker(domain_grads):\n",
        "    dgr = torch.stack((domain_grads))\n",
        "\n",
        "    alpha = 0.01\n",
        "    epsilon = 100\n",
        "    number_of_domains, dim = dgr.shape\n",
        "\n",
        "    g = torch.zeros(dim).to(device)\n",
        "    u_ = torch.zeros(number_of_domains).to(device)\n",
        "\n",
        "    for i in range(5):\n",
        "        u_ = u_ + alpha*(epsilon - (dgr@g))\n",
        "        g = (1./number_of_domains)*torch.sum(((1+(u_>=0)*u_).view(number_of_domains, 1))*dgr, axis=0)\n",
        "\n",
        "    return g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKFM15RPwCsL"
      },
      "outputs": [],
      "source": [
        "def get_loop_data(data):\n",
        "  X, y = data\n",
        "\n",
        "  boxes = map(lambda xx: list(map(lambda yy: np.array([0.,0.,patch_size*1.,patch_size*1.]) if torch.all(yy.eq(torch.tensor([0.,0.,0.,0.]))) else yy, xx)), y[0])\n",
        "  boxes = list(boxes)\n",
        "  ys = list(map(\n",
        "      lambda x: {\"boxes\": torch.tensor(list(map(lambda xx: xx.tolist(), x[0]))).to(device), \"labels\": x[1].to(device)},\n",
        "      zip(boxes, y[1])))\n",
        "  \n",
        "  return X.to(device), ys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBi4UFrDFvQ6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def validate(net, loader, criterion=None):\n",
        "    # iterates the loader and returns loss of the network on the whole loader\n",
        "    net.eval()\n",
        "    total_score = 0\n",
        "    count = 0\n",
        "    for i, data in enumerate(loader):\n",
        "        # X, y = data[0].to(device), data[1].to(device)\n",
        "        # X, y = data\n",
        "        # y_pred = net(X)\n",
        "        # loss = criterion(y_pred, y)\n",
        "\n",
        "        X, y = get_loop_data(data)\n",
        "        # img = Image.fromarray(data[0][0].detach().numpy(), 'RGB')\n",
        "        # img.show()\n",
        "\n",
        "        # plt.imshow(  data[0][0].permute(1, 2, 0)  )\n",
        "        \n",
        "        outputs = net(X, y)\n",
        "        for output in outputs:\n",
        "            # print(outputs)\n",
        "            total_score += output['scores'].detach().cpu().numpy().mean().item()\n",
        "            count += 1\n",
        "        # print(loss)\n",
        "        # print(\"train loss:\", loss)\n",
        "\n",
        "        # classification_loss = loss['classification']\n",
        "        # regression_loss = loss['bbox_regression']\n",
        "\n",
        "        # loss_sum = classification_loss.mean() + regression_loss.mean()\n",
        "\n",
        "        # total_loss += loss.item()\n",
        "        # correct_predictions += torch.sum(torch.argmax(y_pred, dim=1)==y).item()\n",
        "\n",
        "    # total_loss /= len(loader)\n",
        "    # correct_predictions /= (len(loader)*loader.batch_size)\n",
        "\n",
        "    return total_score/count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCRmJJpkGUHB"
      },
      "outputs": [],
      "source": [
        "def get_grads(net):\n",
        "    grads = []\n",
        "    # for p in self.network.parameters():\n",
        "    for p in net.parameters():\n",
        "      try:\n",
        "        grads.append(p.grad.data.clone().flatten())\n",
        "      except:\n",
        "        continue\n",
        "    # print(grads)\n",
        "    return torch.cat(grads)\n",
        "\n",
        "def set_grads(net, new_grads):\n",
        "    start = 0\n",
        "    # for k, p in enumerate(self.network.parameters()):\n",
        "    for k, p in enumerate(net.parameters()):\n",
        "        dims = p.shape\n",
        "        end = start + dims.numel()\n",
        "        # print(\"new_grads\",new_grads.shape)\n",
        "        p.grad.data = new_grads[start:end].reshape(dims)\n",
        "        start = end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzs7ik2ww5RE"
      },
      "outputs": [],
      "source": [
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmKQooBNFSK9"
      },
      "outputs": [],
      "source": [
        "from os import X_OK\n",
        "def train_GM(net, opt, criterion, trainloaders, grad_fn, epochs=50, testloader=None):\n",
        "\n",
        "    make_batches = lambda: zip(*trainloaders)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "        for batch_number, domains_batches in enumerate(make_batches()):\n",
        "            count = 0\n",
        "            train_loss = 0\n",
        "\n",
        "            net.train()\n",
        "            opt.zero_grad()\n",
        "            domains_grads = []\n",
        "\n",
        "            with torch.set_grad_enabled(True):\n",
        "                for domain_number, domain_batch in enumerate(domains_batches):\n",
        "     \n",
        "                    X, y = get_loop_data(domain_batch)\n",
        "                    \n",
        "                    loss = net(X, y)\n",
        "\n",
        "                    classification_loss = loss['classification']\n",
        "                    regression_loss = loss['bbox_regression']\n",
        "\n",
        "\n",
        "                    total_loss = classification_loss.mean() + regression_loss.mean()\n",
        "                    total_loss.backward()\n",
        "\n",
        "                    # print('c', classification_loss.item(), 'r', regression_loss.item(), 't', total_loss.item())\n",
        "                    count += 1\n",
        "                    train_loss += total_loss.item()\n",
        "\n",
        "                    del total_loss\n",
        "                    del loss\n",
        "\n",
        "\n",
        "                    domains_grads.append(get_grads(net))\n",
        "                    opt.zero_grad()\n",
        "            \n",
        "            #\n",
        "            gc.collect()\n",
        "            \n",
        "            new_grads = grad_fn(domains_grads)\n",
        "            set_grads(net, new_grads)\n",
        "            opt.step()\n",
        "\n",
        "            train_loss /= count\n",
        "            print(f'Epoch: {epoch}, Batch number: {batch_number}, Train loss: {train_loss:.5f}')\n",
        "\n",
        "        if testloader != None:\n",
        "            train_f1_score = 0. # (validate(net, trainloaders[0]) + validate(net, trainloaders[1]))/2\n",
        "            val_f1_score = validate(net, testloader)\n",
        "            print('********************************************************************************')\n",
        "            print(f'Finished epoch: {epoch}, Training F1-Score: {train_f1_score:.5f}, Validation F1-Score: {val_f1_score:.5f}')\n",
        "            print('********************************************************************************')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wyojugnQ6Po"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import RetinaNet\n",
        "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
        "\n",
        "# backbone = torchvision.models.resnet50()\n",
        "\n",
        "# backbone.out_channels = 1280\n",
        "# anchor_generator = AnchorGenerator(\n",
        "#     sizes=((32),),\n",
        "#     aspect_ratios=((1.0),)\n",
        "# )\n",
        "\n",
        "# put the pieces together inside a RetinaNet model\n",
        "# model_GM = RetinaNet(backbone,\n",
        "#                   num_classes=2,\n",
        "#                  anchor_generator=anchor_generator)\n",
        "\n",
        "# https://pytorch.org/vision/stable/_modules/torchvision/models/detection/retinanet.html\n",
        "# https://pytorch.org/vision/main/generated/torchvision.models.detection.retinanet_resnet50_fpn.html\n",
        "model_GM = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=False, pretrained_backbone=False)\n",
        "criterion = torchvision.ops.sigmoid_focal_loss\n",
        "optimizer = torch.optim.Adam(model_GM.parameters(), lr=0.001, betas=(0.9, 0.999), weight_decay=0.0005)\n",
        "\n",
        "model_GM.to(device)\n",
        "\n",
        "train_dl1 = data.train_dl.dl\n",
        "train_dl2 = data2.train_dl.dl\n",
        "\n",
        "valid_dl = data.valid_dl.dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsQvobk1ycLj"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.empty_cache()\n",
        "\n",
        "# torch.cuda.memory_summary(device=None, abbreviated=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UVrkaNK9Fdge",
        "outputId": "0eaaa3fa-cab5-41ab-b1f9-508974b37b0c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, Batch number: 0, Train loss: 2.16417\n",
            "Epoch: 0, Batch number: 1, Train loss: 28329.26270\n",
            "Epoch: 0, Batch number: 2, Train loss: 2.00083\n",
            "Epoch: 0, Batch number: 3, Train loss: 38.08365\n",
            "Epoch: 0, Batch number: 4, Train loss: 2.25905\n",
            "Epoch: 0, Batch number: 5, Train loss: 2.65457\n",
            "Epoch: 0, Batch number: 6, Train loss: 2.43708\n",
            "Epoch: 0, Batch number: 7, Train loss: 2.57926\n",
            "Epoch: 0, Batch number: 8, Train loss: 2.74641\n",
            "Epoch: 0, Batch number: 9, Train loss: 3.02642\n",
            "Epoch: 0, Batch number: 10, Train loss: 5.09432\n",
            "Epoch: 0, Batch number: 11, Train loss: 5.45908\n",
            "Epoch: 0, Batch number: 12, Train loss: 3.20125\n",
            "Epoch: 0, Batch number: 13, Train loss: 3.90113\n",
            "Epoch: 0, Batch number: 14, Train loss: 2.76156\n",
            "Epoch: 0, Batch number: 15, Train loss: 2.71140\n",
            "Epoch: 0, Batch number: 16, Train loss: 2.50702\n",
            "Epoch: 0, Batch number: 17, Train loss: 3.61308\n",
            "Epoch: 0, Batch number: 18, Train loss: 4.51286\n",
            "Epoch: 0, Batch number: 19, Train loss: 2.52922\n",
            "Epoch: 0, Batch number: 20, Train loss: 2.14735\n",
            "Epoch: 0, Batch number: 21, Train loss: 2.11204\n",
            "Epoch: 0, Batch number: 22, Train loss: 2.07284\n",
            "Epoch: 0, Batch number: 23, Train loss: 2.19963\n",
            "Epoch: 0, Batch number: 24, Train loss: 1.80417\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: RuntimeWarning: Mean of empty slice.\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************************************************************************\n",
            "Finished epoch: 0, Training F1-Score: 0.00000, Validation F1-Score: nan\n",
            "********************************************************************************\n",
            "Epoch: 1, Batch number: 0, Train loss: 1.55335\n",
            "Epoch: 1, Batch number: 1, Train loss: 1.71405\n",
            "Epoch: 1, Batch number: 2, Train loss: 1.65776\n",
            "Epoch: 1, Batch number: 3, Train loss: 1.56707\n",
            "Epoch: 1, Batch number: 4, Train loss: 1.68661\n",
            "Epoch: 1, Batch number: 5, Train loss: 1.57085\n",
            "Epoch: 1, Batch number: 6, Train loss: 1.65160\n",
            "Epoch: 1, Batch number: 7, Train loss: 1.44983\n",
            "Epoch: 1, Batch number: 8, Train loss: 1.44038\n",
            "Epoch: 1, Batch number: 9, Train loss: 1.55160\n",
            "Epoch: 1, Batch number: 10, Train loss: 1.33733\n",
            "Epoch: 1, Batch number: 11, Train loss: 1.34685\n",
            "Epoch: 1, Batch number: 12, Train loss: 1.90033\n",
            "Epoch: 1, Batch number: 13, Train loss: 1.58320\n",
            "Epoch: 1, Batch number: 14, Train loss: 1.68070\n",
            "Epoch: 1, Batch number: 15, Train loss: 1.61441\n",
            "Epoch: 1, Batch number: 16, Train loss: 1.89203\n",
            "Epoch: 1, Batch number: 17, Train loss: 1.53005\n",
            "Epoch: 1, Batch number: 18, Train loss: 1.40598\n",
            "Epoch: 1, Batch number: 19, Train loss: 1.51509\n",
            "Epoch: 1, Batch number: 20, Train loss: 1.58437\n",
            "Epoch: 1, Batch number: 21, Train loss: 1.68309\n",
            "Epoch: 1, Batch number: 22, Train loss: 1.61891\n",
            "Epoch: 1, Batch number: 23, Train loss: 1.42920\n",
            "Epoch: 1, Batch number: 24, Train loss: 1.47916\n",
            "********************************************************************************\n",
            "Finished epoch: 1, Training F1-Score: 0.00000, Validation F1-Score: nan\n",
            "********************************************************************************\n",
            "Epoch: 2, Batch number: 0, Train loss: 1.37287\n",
            "Epoch: 2, Batch number: 1, Train loss: 1.34940\n",
            "Epoch: 2, Batch number: 2, Train loss: 1.26196\n",
            "Epoch: 2, Batch number: 3, Train loss: 1.07132\n",
            "Epoch: 2, Batch number: 4, Train loss: 1.18444\n",
            "Epoch: 2, Batch number: 5, Train loss: 1.21170\n",
            "Epoch: 2, Batch number: 6, Train loss: 1.07725\n",
            "Epoch: 2, Batch number: 7, Train loss: 1.10244\n",
            "Epoch: 2, Batch number: 8, Train loss: 1.08341\n",
            "Epoch: 2, Batch number: 9, Train loss: 1.06638\n",
            "Epoch: 2, Batch number: 10, Train loss: 1.16232\n",
            "Epoch: 2, Batch number: 11, Train loss: 1.17146\n",
            "Epoch: 2, Batch number: 12, Train loss: 1.14329\n",
            "Epoch: 2, Batch number: 13, Train loss: 0.95705\n",
            "Epoch: 2, Batch number: 14, Train loss: 1.11292\n",
            "Epoch: 2, Batch number: 15, Train loss: 1.11530\n",
            "Epoch: 2, Batch number: 16, Train loss: 1.01993\n",
            "Epoch: 2, Batch number: 17, Train loss: 1.13947\n",
            "Epoch: 2, Batch number: 18, Train loss: 1.08022\n",
            "Epoch: 2, Batch number: 19, Train loss: 0.93002\n",
            "Epoch: 2, Batch number: 20, Train loss: 0.87724\n",
            "Epoch: 2, Batch number: 21, Train loss: 1.11997\n",
            "Epoch: 2, Batch number: 22, Train loss: 1.61247\n",
            "Epoch: 2, Batch number: 23, Train loss: 1.47981\n",
            "Epoch: 2, Batch number: 24, Train loss: 1.43751\n",
            "********************************************************************************\n",
            "Finished epoch: 2, Training F1-Score: 0.00000, Validation F1-Score: nan\n",
            "********************************************************************************\n",
            "Epoch: 3, Batch number: 0, Train loss: 1.45331\n",
            "Epoch: 3, Batch number: 1, Train loss: 1.37510\n",
            "Epoch: 3, Batch number: 2, Train loss: 1.36004\n",
            "Epoch: 3, Batch number: 3, Train loss: 1.36895\n",
            "Epoch: 3, Batch number: 4, Train loss: 1.23383\n",
            "Epoch: 3, Batch number: 5, Train loss: 1.40552\n",
            "Epoch: 3, Batch number: 6, Train loss: 1.11243\n",
            "Epoch: 3, Batch number: 7, Train loss: 1.18457\n",
            "Epoch: 3, Batch number: 8, Train loss: 1.30772\n",
            "Epoch: 3, Batch number: 9, Train loss: 1.41698\n",
            "Epoch: 3, Batch number: 10, Train loss: 1.37546\n",
            "Epoch: 3, Batch number: 11, Train loss: 1.33818\n",
            "Epoch: 3, Batch number: 12, Train loss: 1.40600\n",
            "Epoch: 3, Batch number: 13, Train loss: 1.15027\n",
            "Epoch: 3, Batch number: 14, Train loss: 1.00122\n",
            "Epoch: 3, Batch number: 15, Train loss: 1.27976\n",
            "Epoch: 3, Batch number: 16, Train loss: 1.36921\n",
            "Epoch: 3, Batch number: 17, Train loss: 1.86334\n",
            "Epoch: 3, Batch number: 18, Train loss: 1.38911\n",
            "Epoch: 3, Batch number: 19, Train loss: 2.43895\n",
            "Epoch: 3, Batch number: 20, Train loss: 2.22980\n",
            "Epoch: 3, Batch number: 21, Train loss: 2.46951\n",
            "Epoch: 3, Batch number: 22, Train loss: 1.38136\n",
            "Epoch: 3, Batch number: 23, Train loss: 1.48393\n",
            "Epoch: 3, Batch number: 24, Train loss: 1.38765\n",
            "********************************************************************************\n",
            "Finished epoch: 3, Training F1-Score: 0.00000, Validation F1-Score: 0.06883\n",
            "********************************************************************************\n",
            "Epoch: 4, Batch number: 0, Train loss: 1.27620\n",
            "Epoch: 4, Batch number: 1, Train loss: 1.91851\n",
            "Epoch: 4, Batch number: 2, Train loss: 1.57082\n",
            "Epoch: 4, Batch number: 3, Train loss: 1.55231\n",
            "Epoch: 4, Batch number: 4, Train loss: 1.63025\n",
            "Epoch: 4, Batch number: 5, Train loss: 1.64028\n",
            "Epoch: 4, Batch number: 6, Train loss: 1.48186\n",
            "Epoch: 4, Batch number: 7, Train loss: 1.58115\n",
            "Epoch: 4, Batch number: 8, Train loss: 1.54526\n",
            "Epoch: 4, Batch number: 9, Train loss: 1.40894\n",
            "Epoch: 4, Batch number: 10, Train loss: 1.42949\n",
            "Epoch: 4, Batch number: 11, Train loss: 1.39609\n",
            "Epoch: 4, Batch number: 12, Train loss: 1.54319\n",
            "Epoch: 4, Batch number: 13, Train loss: 1.37394\n",
            "Epoch: 4, Batch number: 14, Train loss: 1.40474\n",
            "Epoch: 4, Batch number: 15, Train loss: 1.33951\n",
            "Epoch: 4, Batch number: 16, Train loss: 1.36867\n",
            "Epoch: 4, Batch number: 17, Train loss: 1.35259\n",
            "Epoch: 4, Batch number: 18, Train loss: 1.34505\n",
            "Epoch: 4, Batch number: 19, Train loss: 1.36979\n",
            "Epoch: 4, Batch number: 20, Train loss: 1.17568\n",
            "Epoch: 4, Batch number: 21, Train loss: 1.27859\n",
            "Epoch: 4, Batch number: 22, Train loss: 1.04965\n",
            "Epoch: 4, Batch number: 23, Train loss: 1.00548\n",
            "Epoch: 4, Batch number: 24, Train loss: 1.35390\n",
            "********************************************************************************\n",
            "Finished epoch: 4, Training F1-Score: 0.00000, Validation F1-Score: nan\n",
            "********************************************************************************\n",
            "Epoch: 5, Batch number: 0, Train loss: 1.23324\n",
            "Epoch: 5, Batch number: 1, Train loss: 1.40762\n",
            "Epoch: 5, Batch number: 2, Train loss: 1.33994\n",
            "Epoch: 5, Batch number: 3, Train loss: 1.29540\n",
            "Epoch: 5, Batch number: 4, Train loss: 1.40152\n",
            "Epoch: 5, Batch number: 5, Train loss: 1.51990\n",
            "Epoch: 5, Batch number: 6, Train loss: 1.44053\n",
            "Epoch: 5, Batch number: 7, Train loss: 1.23468\n",
            "Epoch: 5, Batch number: 8, Train loss: 1.34092\n",
            "Epoch: 5, Batch number: 9, Train loss: 1.35911\n",
            "Epoch: 5, Batch number: 10, Train loss: 1.11330\n",
            "Epoch: 5, Batch number: 11, Train loss: 2.50324\n",
            "Epoch: 5, Batch number: 12, Train loss: 1.50278\n",
            "Epoch: 5, Batch number: 13, Train loss: 1.52683\n",
            "Epoch: 5, Batch number: 14, Train loss: 2.84741\n",
            "Epoch: 5, Batch number: 15, Train loss: 1.64654\n",
            "Epoch: 5, Batch number: 16, Train loss: 1.62473\n",
            "Epoch: 5, Batch number: 17, Train loss: 1.54561\n",
            "Epoch: 5, Batch number: 18, Train loss: 1.55078\n",
            "Epoch: 5, Batch number: 19, Train loss: 1.59408\n",
            "Epoch: 5, Batch number: 20, Train loss: 1.40574\n",
            "Epoch: 5, Batch number: 21, Train loss: 1.69459\n",
            "Epoch: 5, Batch number: 22, Train loss: 1.47442\n",
            "Epoch: 5, Batch number: 23, Train loss: 1.53203\n",
            "Epoch: 5, Batch number: 24, Train loss: 1.48108\n",
            "********************************************************************************\n",
            "Finished epoch: 5, Training F1-Score: 0.00000, Validation F1-Score: nan\n",
            "********************************************************************************\n",
            "Epoch: 6, Batch number: 0, Train loss: 1.45577\n",
            "Epoch: 6, Batch number: 1, Train loss: 1.55579\n",
            "Epoch: 6, Batch number: 2, Train loss: 1.51603\n",
            "Epoch: 6, Batch number: 3, Train loss: 1.49376\n",
            "Epoch: 6, Batch number: 4, Train loss: 1.41271\n",
            "Epoch: 6, Batch number: 5, Train loss: 1.45802\n",
            "Epoch: 6, Batch number: 6, Train loss: 1.43850\n",
            "Epoch: 6, Batch number: 7, Train loss: 1.43129\n",
            "Epoch: 6, Batch number: 8, Train loss: 1.49848\n",
            "Epoch: 6, Batch number: 9, Train loss: 1.37656\n",
            "Epoch: 6, Batch number: 10, Train loss: 1.45879\n",
            "Epoch: 6, Batch number: 11, Train loss: 1.41120\n",
            "Epoch: 6, Batch number: 12, Train loss: 1.36193\n",
            "Epoch: 6, Batch number: 13, Train loss: 1.40500\n",
            "Epoch: 6, Batch number: 14, Train loss: 1.34788\n",
            "Epoch: 6, Batch number: 15, Train loss: 1.35692\n",
            "Epoch: 6, Batch number: 16, Train loss: 1.41305\n",
            "Epoch: 6, Batch number: 17, Train loss: 1.37574\n",
            "Epoch: 6, Batch number: 18, Train loss: 1.36401\n",
            "Epoch: 6, Batch number: 19, Train loss: 1.34038\n",
            "Epoch: 6, Batch number: 20, Train loss: 1.30874\n",
            "Epoch: 6, Batch number: 21, Train loss: 1.14362\n",
            "Epoch: 6, Batch number: 22, Train loss: 1.05590\n",
            "Epoch: 6, Batch number: 23, Train loss: 1.49046\n",
            "Epoch: 6, Batch number: 24, Train loss: 1.30057\n",
            "********************************************************************************\n",
            "Finished epoch: 6, Training F1-Score: 0.00000, Validation F1-Score: nan\n",
            "********************************************************************************\n",
            "Epoch: 7, Batch number: 0, Train loss: 1.38452\n",
            "Epoch: 7, Batch number: 1, Train loss: 1.36578\n",
            "Epoch: 7, Batch number: 2, Train loss: 1.43071\n",
            "Epoch: 7, Batch number: 3, Train loss: 1.48263\n",
            "Epoch: 7, Batch number: 4, Train loss: 1.46379\n",
            "Epoch: 7, Batch number: 5, Train loss: 1.46094\n",
            "Epoch: 7, Batch number: 6, Train loss: 1.33697\n",
            "Epoch: 7, Batch number: 7, Train loss: 1.30665\n",
            "Epoch: 7, Batch number: 8, Train loss: 1.27550\n",
            "Epoch: 7, Batch number: 9, Train loss: 1.24508\n",
            "Epoch: 7, Batch number: 10, Train loss: 1.80655\n",
            "Epoch: 7, Batch number: 11, Train loss: 1.48742\n",
            "Epoch: 7, Batch number: 12, Train loss: 1.50306\n",
            "Epoch: 7, Batch number: 13, Train loss: 1.44793\n",
            "Epoch: 7, Batch number: 14, Train loss: 1.43570\n",
            "Epoch: 7, Batch number: 15, Train loss: 1.35349\n",
            "Epoch: 7, Batch number: 16, Train loss: 1.42585\n",
            "Epoch: 7, Batch number: 17, Train loss: 1.43279\n",
            "Epoch: 7, Batch number: 18, Train loss: 1.36670\n",
            "Epoch: 7, Batch number: 19, Train loss: 1.27057\n",
            "Epoch: 7, Batch number: 20, Train loss: 1.33045\n",
            "Epoch: 7, Batch number: 21, Train loss: 1.35771\n",
            "Epoch: 7, Batch number: 22, Train loss: 1.38965\n",
            "Epoch: 7, Batch number: 23, Train loss: 1.30371\n",
            "Epoch: 7, Batch number: 24, Train loss: 1.29871\n",
            "********************************************************************************\n",
            "Finished epoch: 7, Training F1-Score: 0.00000, Validation F1-Score: nan\n",
            "********************************************************************************\n",
            "Epoch: 8, Batch number: 0, Train loss: 1.23301\n",
            "Epoch: 8, Batch number: 1, Train loss: 1.21543\n",
            "Epoch: 8, Batch number: 2, Train loss: 1.19148\n",
            "Epoch: 8, Batch number: 3, Train loss: 5.82785\n",
            "Epoch: 8, Batch number: 4, Train loss: 1.33276\n",
            "Epoch: 8, Batch number: 5, Train loss: 1.34383\n",
            "Epoch: 8, Batch number: 6, Train loss: 1.31730\n",
            "Epoch: 8, Batch number: 7, Train loss: 1.27812\n",
            "Epoch: 8, Batch number: 8, Train loss: 1.37825\n",
            "Epoch: 8, Batch number: 9, Train loss: 1.30140\n",
            "Epoch: 8, Batch number: 10, Train loss: 1.25381\n",
            "Epoch: 8, Batch number: 11, Train loss: 1.33848\n",
            "Epoch: 8, Batch number: 12, Train loss: 1.23191\n",
            "Epoch: 8, Batch number: 13, Train loss: 1.11602\n",
            "Epoch: 8, Batch number: 14, Train loss: 1.08764\n",
            "Epoch: 8, Batch number: 15, Train loss: 1.27745\n",
            "Epoch: 8, Batch number: 16, Train loss: 1.09496\n",
            "Epoch: 8, Batch number: 17, Train loss: 1.29464\n",
            "Epoch: 8, Batch number: 18, Train loss: 1.26263\n",
            "Epoch: 8, Batch number: 19, Train loss: 3.36917\n",
            "Epoch: 8, Batch number: 20, Train loss: 1.29819\n",
            "Epoch: 8, Batch number: 21, Train loss: 1.75070\n",
            "Epoch: 8, Batch number: 22, Train loss: 1.72976\n",
            "Epoch: 8, Batch number: 23, Train loss: 1.76436\n",
            "Epoch: 8, Batch number: 24, Train loss: 2.06597\n",
            "********************************************************************************\n",
            "Finished epoch: 8, Training F1-Score: 0.00000, Validation F1-Score: nan\n",
            "********************************************************************************\n",
            "Epoch: 9, Batch number: 0, Train loss: 1.57325\n",
            "Epoch: 9, Batch number: 1, Train loss: 1.32941\n",
            "Epoch: 9, Batch number: 2, Train loss: 1.57344\n",
            "Epoch: 9, Batch number: 3, Train loss: 1.41517\n",
            "Epoch: 9, Batch number: 4, Train loss: 1.46027\n",
            "Epoch: 9, Batch number: 5, Train loss: 1.22459\n",
            "Epoch: 9, Batch number: 6, Train loss: 1.05218\n",
            "Epoch: 9, Batch number: 7, Train loss: 1.55410\n",
            "Epoch: 9, Batch number: 8, Train loss: 8.93857\n",
            "Epoch: 9, Batch number: 9, Train loss: 3.24986\n",
            "Epoch: 9, Batch number: 10, Train loss: 13.72410\n",
            "Epoch: 9, Batch number: 11, Train loss: 1.56013\n",
            "Epoch: 9, Batch number: 12, Train loss: 4.36166\n",
            "Epoch: 9, Batch number: 13, Train loss: 2.21721\n",
            "Epoch: 9, Batch number: 14, Train loss: 1.87711\n",
            "Epoch: 9, Batch number: 15, Train loss: 1.93107\n",
            "Epoch: 9, Batch number: 16, Train loss: 1.68427\n",
            "Epoch: 9, Batch number: 17, Train loss: 1.72129\n",
            "Epoch: 9, Batch number: 18, Train loss: 1.87146\n",
            "Epoch: 9, Batch number: 19, Train loss: 1.78624\n",
            "Epoch: 9, Batch number: 20, Train loss: 1.56904\n",
            "Epoch: 9, Batch number: 21, Train loss: 8.27768\n",
            "Epoch: 9, Batch number: 22, Train loss: 2.19050\n",
            "Epoch: 9, Batch number: 23, Train loss: 1.60620\n",
            "Epoch: 9, Batch number: 24, Train loss: 1.54537\n",
            "********************************************************************************\n",
            "Finished epoch: 9, Training F1-Score: 0.00000, Validation F1-Score: nan\n",
            "********************************************************************************\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-6f2541496218>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_GM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_GM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_dl1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist_test_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_GM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# _, svhn_test_acc = validate(model_GM, svhn_testloader, criterion)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable float object"
          ]
        }
      ],
      "source": [
        "train_GM(model_GM, optimizer, criterion, [train_dl1, train_dl2], pcgrad, 10, valid_dl)\n",
        "\n",
        "_, mnist_test_acc = validate(model_GM, valid_dl, criterion)\n",
        "# _, svhn_test_acc = validate(model_GM, svhn_testloader, criterion)\n",
        "\n",
        "print(f'Test Acc: {mnist_test_acc:.5f}')\n",
        "        # f', SVHN Test Acc: {svhn_test_acc:.5f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIL5dALDZVWR"
      },
      "outputs": [],
      "source": [
        "_, mnist_test_acc = validate(model_GM, valid_dl, criterion)\n",
        "# _, svhn_test_acc = validate(model_GM, svhn_testloader, criterion)\n",
        "\n",
        "print(f'Test Acc: {mnist_test_acc:.5f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMI00ODCaDID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d126f2a8-9443-4133-8323-d51caa646a9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'boxes': tensor([[ 69.8425, 148.5489,  97.7951, 176.8014],\n",
            "        [ 59.5955, 148.5371,  87.5594, 176.7938],\n",
            "        [ 80.0242, 148.5543, 108.0110, 176.8428],\n",
            "        [ 49.3207, 148.5326,  77.3133, 176.8146],\n",
            "        [ 74.8074, 158.7111, 102.8589, 187.0270],\n",
            "        [ 39.0393, 148.5282,  67.0630, 176.8392],\n",
            "        [ 64.5624, 158.6945,  92.6249, 187.0165],\n",
            "        [ 85.0027, 158.7247, 113.0805, 187.0681],\n",
            "        [ 64.6776, 138.3693,  92.6873, 166.6986],\n",
            "        [ 28.7652, 148.5212,  56.8140, 176.8535],\n",
            "        [ 69.8425, 148.5489,  97.7951, 176.8014],\n",
            "        [ 90.1429, 148.5481, 118.2129, 176.9131],\n",
            "        [ 54.3055, 158.6975,  82.3825, 187.0351],\n",
            "        [ 54.4232, 138.3561,  82.4474, 166.6920],\n",
            "        [ 74.8658, 138.3766, 102.9029, 166.7351],\n",
            "        [ 44.0514, 158.7131,  72.1400, 187.0657],\n",
            "        [ 59.5955, 148.5371,  87.5594, 176.7938],\n",
            "        [ 18.5023, 148.5267,  46.5675, 176.8738],\n",
            "        [ 44.1444, 138.3456,  72.1957, 166.7001],\n",
            "        [ 79.9912, 153.6388, 107.9945, 181.9258],\n",
            "        [ 33.7926, 158.7070,  61.8986, 187.0765],\n",
            "        [ 49.3207, 148.5326,  77.3133, 176.8146],\n",
            "        [ 23.5375, 158.7002,  51.6546, 187.0805],\n",
            "        [ 95.1533, 158.7272, 123.2986, 187.1346],\n",
            "        [ 33.8598, 138.3284,  61.9422, 166.7040],\n",
            "        [ 13.2825, 158.7104,  41.4096, 187.0966],\n",
            "        [  8.2143, 148.5202,  36.3326, 176.9085],\n",
            "        [ 69.6896, 158.7019,  97.7438, 187.0180],\n",
            "        [ 39.0393, 148.5282,  67.0630, 176.8392],\n",
            "        [ 80.0036, 143.4685, 108.0133, 171.7913],\n",
            "        [ 84.9877, 138.3634, 113.1045, 166.7897],\n",
            "        [ 23.5780, 138.3144,  51.6914, 166.7151],\n",
            "        [ 59.4328, 158.6929,  87.5036, 187.0226],\n",
            "        [ 90.1294, 153.6401, 118.2027, 181.9922],\n",
            "        [ 28.7652, 148.5212,  56.8140, 176.8535],\n",
            "        [ 64.6776, 138.3693,  92.6873, 166.6986],\n",
            "        [ 49.1790, 158.7061,  77.2612, 187.0510],\n",
            "        [100.2513, 148.5245, 128.4223, 176.9741],\n",
            "        [146.3459, 148.5137, 174.5249, 176.9592],\n",
            "        [ 13.3005, 138.3087,  41.4431, 166.7351],\n",
            "        [ 84.8263, 168.8957, 113.0440, 197.3484],\n",
            "        [ 54.4232, 138.3561,  82.4474, 166.6920],\n",
            "        [ 38.9221, 158.7133,  67.0192, 187.0742],\n",
            "        [ 18.4744, 153.6205,  46.5515, 181.9728],\n",
            "        [ 74.5821, 168.8732, 102.8078, 197.3258],\n",
            "        [171.8973,   0.0000, 200.1113,  28.4288],\n",
            "        [ 79.8092, 163.8017, 107.9451, 192.1850],\n",
            "        [ 95.0428, 168.9088, 123.2785, 197.3837],\n",
            "        [136.0954, 148.4801, 164.2966, 176.9407],\n",
            "        [ 44.1444, 138.3456,  72.1957, 166.7001],\n",
            "        [ 28.6646, 158.7005,  56.7775, 187.0768],\n",
            "        [105.3030, 158.7141, 133.5280, 187.1956],\n",
            "        [ 53.7122, 132.7910, 106.1068, 184.6995],\n",
            "        [141.1270, 158.6747, 169.3712, 187.1579],\n",
            "        [ 38.7289, 168.8939,  66.9634, 197.3600],\n",
            "        [182.0361,   5.0746, 210.3008,  33.5589],\n",
            "        [217.9422,  10.2557, 246.1779,  38.7464],\n",
            "        [ 18.4902, 143.4247,  46.5726, 171.7919],\n",
            "        [ 43.0592, 142.4187,  95.7558, 194.3779],\n",
            "        [ 63.3992, 142.6494, 116.1084, 194.6609],\n",
            "        [ 90.0124, 163.8163, 118.1736, 192.2288],\n",
            "        [ 64.3150, 168.8463,  92.5631, 197.3155],\n",
            "        [ 28.4949, 168.8827,  56.7337, 197.3512],\n",
            "        [ 33.2710, 132.6100,  85.7105, 184.5441],\n",
            "        [156.4817, 148.4979, 184.7169, 176.9939],\n",
            "        [  8.1958, 153.6179,  36.3197, 182.0047],\n",
            "        [ 90.1141, 143.4540, 118.2163, 171.8571],\n",
            "        [ 33.8598, 138.3284,  61.9422, 166.7040],\n",
            "        [ 48.9516, 168.8707,  77.1996, 197.3485],\n",
            "        [ 18.2357, 168.8729,  46.4904, 197.3545]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0637, 0.0629, 0.0622, 0.0615, 0.0600, 0.0599, 0.0590, 0.0589, 0.0587,\n",
            "        0.0582, 0.0580, 0.0580, 0.0580, 0.0579, 0.0578, 0.0574, 0.0574, 0.0571,\n",
            "        0.0568, 0.0567, 0.0565, 0.0562, 0.0557, 0.0556, 0.0554, 0.0553, 0.0549,\n",
            "        0.0549, 0.0548, 0.0546, 0.0541, 0.0540, 0.0538, 0.0536, 0.0533, 0.0532,\n",
            "        0.0531, 0.0530, 0.0529, 0.0528, 0.0527, 0.0525, 0.0524, 0.0523, 0.0522,\n",
            "        0.0521, 0.0520, 0.0517, 0.0517, 0.0516, 0.0515, 0.0514, 0.0512, 0.0511,\n",
            "        0.0510, 0.0510, 0.0510, 0.0510, 0.0509, 0.0509, 0.0508, 0.0508, 0.0507,\n",
            "        0.0507, 0.0507, 0.0506, 0.0505, 0.0505, 0.0504, 0.0503],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2,\n",
            "        2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2,\n",
            "        2, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2],\n",
            "       device='cuda:0')}, {'boxes': tensor([[136.2711, 163.8955, 164.3179, 192.2244],\n",
            "        [131.1356, 153.6823, 159.2005, 182.0366],\n",
            "        [146.4094, 169.0092, 174.5156, 197.3941],\n",
            "        [223.0781,  76.7798, 251.2603, 105.2445],\n",
            "        [136.1395, 174.0412, 164.2779, 202.4167],\n",
            "        [125.9410, 163.8086, 154.0621, 192.1763],\n",
            "        [141.2874, 153.6841, 169.4081, 182.0966],\n",
            "        [223.0651,  66.5652, 251.2647,  95.0484],\n",
            "        [222.9999,  86.9828, 251.2298, 115.4768],\n",
            "        [131.0450, 143.4479, 159.1760, 171.8656],\n",
            "        [146.3071, 179.1880, 174.4860, 207.6111],\n",
            "        [136.2711, 163.8955, 164.3179, 192.2244],\n",
            "        [120.8346, 153.5921, 148.9630, 181.9796],\n",
            "        [217.9791, 184.3584, 246.1705, 212.8078],\n",
            "        [212.9202, 174.1291, 241.0826, 202.5600],\n",
            "        [120.8023, 143.3826, 148.9564, 171.8016],\n",
            "        [131.1356, 153.6823, 159.2005, 182.0366],\n",
            "        [217.9559, 194.5696, 246.1689, 223.0292],\n",
            "        [141.2765, 174.0776, 169.3936, 202.4483],\n",
            "        [ 49.0221,  40.9567,  77.2319,  69.4248],\n",
            "        [151.4387, 158.7745, 179.6213, 187.2383],\n",
            "        [222.9776,  56.3290, 251.2441,  84.8704],\n",
            "        [223.0781,  76.7798, 251.2603, 105.2445],\n",
            "        [125.9410, 163.8086, 154.0621, 192.1763],\n",
            "        [146.4165, 163.9085, 174.5228, 192.3033],\n",
            "        [151.3528, 189.4204, 179.6027, 217.9056],\n",
            "        [156.4774, 168.9823, 184.7026, 197.4717],\n",
            "        [130.9503, 133.1763, 159.1570, 161.6546],\n",
            "        [ 59.2155,  46.0670,  87.4521,  74.5553],\n",
            "        [156.4613, 179.2160, 184.7041, 207.7124],\n",
            "        [217.9260, 204.7897, 246.1708, 233.2819],\n",
            "        [141.1751, 143.4120, 169.3749, 171.8883],\n",
            "        [212.8568, 163.8970, 241.0719, 192.3816],\n",
            "        [212.9371,  76.7407, 241.1266, 105.1890],\n",
            "        [ 49.0058,  30.7443,  77.2327,  59.2350],\n",
            "        [ 38.7643,  40.9286,  66.9987,  69.4159],\n",
            "        [207.7228, 184.2295, 235.9517, 212.6896],\n",
            "        [222.8622,  97.1950, 251.1901, 125.7687],\n",
            "        [ 59.2076,  35.8630,  87.4506,  64.3677]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0592, 0.0577, 0.0567, 0.0559, 0.0555, 0.0554, 0.0544, 0.0544, 0.0543,\n",
            "        0.0543, 0.0542, 0.0541, 0.0540, 0.0537, 0.0534, 0.0528, 0.0527, 0.0525,\n",
            "        0.0521, 0.0517, 0.0516, 0.0514, 0.0512, 0.0511, 0.0510, 0.0509, 0.0508,\n",
            "        0.0508, 0.0508, 0.0507, 0.0507, 0.0507, 0.0506, 0.0506, 0.0504, 0.0504,\n",
            "        0.0504, 0.0502, 0.0500], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1,\n",
            "        1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')}, {'boxes': tensor([[177.7029,   5.1813, 205.3770,  33.1675],\n",
            "        [167.4545,   5.1675, 195.1416,  33.1600],\n",
            "        [ 18.9438,   5.1793,  46.6519,  33.1927],\n",
            "        ...,\n",
            "        [ 34.8355,  30.7218,  86.2293,  81.6724],\n",
            "        [ 65.3086,  61.5653, 116.7975, 112.5579],\n",
            "        [ 85.0312, 173.3796, 137.1591, 224.9889]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0800, 0.0794, 0.0784, 0.0783, 0.0770, 0.0769, 0.0759, 0.0741, 0.0738,\n",
            "        0.0735, 0.0734, 0.0732, 0.0727, 0.0726, 0.0726, 0.0722, 0.0720, 0.0719,\n",
            "        0.0718, 0.0717, 0.0716, 0.0714, 0.0713, 0.0713, 0.0713, 0.0711, 0.0710,\n",
            "        0.0704, 0.0703, 0.0703, 0.0702, 0.0702, 0.0700, 0.0699, 0.0698, 0.0698,\n",
            "        0.0697, 0.0696, 0.0696, 0.0696, 0.0695, 0.0695, 0.0690, 0.0689, 0.0689,\n",
            "        0.0684, 0.0684, 0.0680, 0.0680, 0.0676, 0.0675, 0.0674, 0.0673, 0.0671,\n",
            "        0.0670, 0.0669, 0.0669, 0.0669, 0.0668, 0.0666, 0.0663, 0.0661, 0.0661,\n",
            "        0.0661, 0.0659, 0.0658, 0.0656, 0.0655, 0.0655, 0.0654, 0.0653, 0.0652,\n",
            "        0.0652, 0.0652, 0.0652, 0.0651, 0.0649, 0.0648, 0.0648, 0.0648, 0.0647,\n",
            "        0.0647, 0.0646, 0.0645, 0.0644, 0.0644, 0.0642, 0.0640, 0.0639, 0.0639,\n",
            "        0.0638, 0.0638, 0.0638, 0.0637, 0.0637, 0.0637, 0.0636, 0.0636, 0.0636,\n",
            "        0.0634, 0.0634, 0.0634, 0.0634, 0.0633, 0.0633, 0.0633, 0.0633, 0.0632,\n",
            "        0.0632, 0.0632, 0.0631, 0.0630, 0.0629, 0.0629, 0.0628, 0.0628, 0.0628,\n",
            "        0.0628, 0.0626, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0623, 0.0622,\n",
            "        0.0622, 0.0621, 0.0620, 0.0620, 0.0619, 0.0619, 0.0619, 0.0618, 0.0618,\n",
            "        0.0618, 0.0618, 0.0618, 0.0617, 0.0617, 0.0615, 0.0615, 0.0615, 0.0614,\n",
            "        0.0614, 0.0614, 0.0614, 0.0613, 0.0613, 0.0613, 0.0613, 0.0612, 0.0612,\n",
            "        0.0612, 0.0612, 0.0612, 0.0611, 0.0611, 0.0611, 0.0610, 0.0609, 0.0608,\n",
            "        0.0608, 0.0607, 0.0607, 0.0606, 0.0606, 0.0606, 0.0605, 0.0605, 0.0604,\n",
            "        0.0603, 0.0602, 0.0602, 0.0601, 0.0600, 0.0599, 0.0599, 0.0599, 0.0599,\n",
            "        0.0598, 0.0597, 0.0597, 0.0597, 0.0597, 0.0596, 0.0596, 0.0596, 0.0594,\n",
            "        0.0594, 0.0594, 0.0594, 0.0594, 0.0593, 0.0593, 0.0592, 0.0592, 0.0591,\n",
            "        0.0591, 0.0591, 0.0591, 0.0591, 0.0590, 0.0590, 0.0589, 0.0589, 0.0589,\n",
            "        0.0589, 0.0588, 0.0588, 0.0588, 0.0587, 0.0586, 0.0586, 0.0586, 0.0585,\n",
            "        0.0585, 0.0585, 0.0585, 0.0584, 0.0584, 0.0584, 0.0583, 0.0582, 0.0582,\n",
            "        0.0582, 0.0582, 0.0582, 0.0582, 0.0582, 0.0582, 0.0582, 0.0581, 0.0581,\n",
            "        0.0581, 0.0581, 0.0581, 0.0581, 0.0581, 0.0580, 0.0580, 0.0580, 0.0580,\n",
            "        0.0580, 0.0580, 0.0580, 0.0579, 0.0579, 0.0579, 0.0579, 0.0578, 0.0578,\n",
            "        0.0578, 0.0578, 0.0578, 0.0577, 0.0577, 0.0577, 0.0577, 0.0577, 0.0576,\n",
            "        0.0576, 0.0576, 0.0576, 0.0574, 0.0574, 0.0574, 0.0573, 0.0573, 0.0573,\n",
            "        0.0573, 0.0573, 0.0573, 0.0573, 0.0573, 0.0573, 0.0573, 0.0572, 0.0572,\n",
            "        0.0572, 0.0572, 0.0571, 0.0571, 0.0571, 0.0571, 0.0570, 0.0570, 0.0568,\n",
            "        0.0568, 0.0567, 0.0566, 0.0565, 0.0565, 0.0565, 0.0563, 0.0562, 0.0561,\n",
            "        0.0560, 0.0559, 0.0559], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1,\n",
            "        2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2,\n",
            "        1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2,\n",
            "        2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1,\n",
            "        2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
            "        2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1,\n",
            "        2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1,\n",
            "        2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2,\n",
            "        1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1,\n",
            "        1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1], device='cuda:0')}, {'boxes': tensor([[ 13.1685, 107.5425,  41.3824, 136.0156]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0515], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2], device='cuda:0')}]\n",
            "[{'boxes': tensor([[  8.1859,  46.1350,  36.3009,  74.5222],\n",
            "        [ 13.3093,  35.9083,  41.4225,  64.3048],\n",
            "        [  8.1196,  56.3575,  36.2705,  84.7713],\n",
            "        [  8.0831, 138.2588,  36.2317, 166.6663],\n",
            "        [  8.0773,  66.5870,  36.2596,  95.0326],\n",
            "        [ 18.2677,  46.0884,  46.4609,  74.5411],\n",
            "        [  8.1093, 128.0843,  36.2658, 156.5228],\n",
            "        [212.8528, 102.4089, 241.0648, 130.8762],\n",
            "        [ 23.4369,  30.7567,  51.6152,  59.2007],\n",
            "        [212.8496,  92.1903, 241.0684, 120.6643],\n",
            "        [ 13.2577,  25.6594,  41.4277,  54.1032],\n",
            "        [  8.1859,  46.1350,  36.3009,  74.5222],\n",
            "        [  8.0231,  76.7991,  36.2431, 105.2713],\n",
            "        [  7.9689, 148.4476,  36.2046, 176.9218],\n",
            "        [ 18.2096,  56.3151,  46.4524,  84.8036],\n",
            "        [217.8419, 112.6297, 246.1287, 141.1597],\n",
            "        [212.8165,  81.9306, 241.0606, 110.4192],\n",
            "        [ 13.3093,  35.9083,  41.4225,  64.3048]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0558, 0.0547, 0.0544, 0.0540, 0.0525, 0.0523, 0.0521, 0.0520, 0.0516,\n",
            "        0.0513, 0.0512, 0.0512, 0.0508, 0.0506, 0.0503, 0.0503, 0.0501, 0.0500],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1], device='cuda:0')}, {'boxes': tensor([[ 13.4281, 174.1456,  41.4445, 202.4564],\n",
            "        [ 44.1396,  35.9177,  72.1687,  64.2357],\n",
            "        [  8.3194, 163.9269,  36.3451, 192.2489],\n",
            "        [ 44.1074,  46.1411,  72.1541,  74.4785],\n",
            "        [ 13.3565, 184.3487,  41.4243, 212.6901],\n",
            "        [ 23.6191, 117.8130,  51.6742, 146.1559],\n",
            "        [ 39.0075,  25.6814,  67.0431,  54.0065],\n",
            "        [ 38.9518,  56.3618,  67.0305,  84.7196],\n",
            "        [ 13.3838, 122.9089,  41.4427, 151.2481],\n",
            "        [ 23.5876, 179.2400,  51.6567, 207.5872],\n",
            "        [  8.2694, 153.6904,  36.3310, 182.0482],\n",
            "        [ 28.7274, 107.6041,  56.8015, 135.9811],\n",
            "        [ 18.4750, 163.9160,  46.5394, 192.2766],\n",
            "        [ 28.7225,   5.1659,  56.7963,  33.5121],\n",
            "        [ 33.8673,  35.8644,  61.9349,  64.1990],\n",
            "        [ 33.8560,  46.1094,  61.9387,  74.4639],\n",
            "        [ 33.8369,  15.4352,  61.9043,  43.7935],\n",
            "        [ 23.5285, 128.0214,  51.6390, 156.4006],\n",
            "        [ 13.4139, 112.7002,  41.4694, 141.0465],\n",
            "        [ 54.2290,  35.8958,  82.3409,  64.2926],\n",
            "        [  8.2150, 133.1586,  36.3154, 161.5351],\n",
            "        [  8.2183, 143.4265,  36.3163, 171.8101],\n",
            "        [ 33.7324, 117.7946,  61.8597, 146.1996],\n",
            "        [ 23.5326, 189.4487,  51.6449, 217.8255],\n",
            "        [ 49.1653,  25.6949,  77.2613,  54.0886],\n",
            "        [ 28.7201,  25.6136,  56.7989,  53.9534],\n",
            "        [ 38.8602,  66.5703,  67.0016,  94.9759],\n",
            "        [ 49.0769,  56.3476,  77.2104,  84.7545],\n",
            "        [ 13.4281, 174.1456,  41.4445, 202.4564],\n",
            "        [ 13.2619, 194.5753,  41.4039, 222.9744],\n",
            "        [ 44.1300,  41.0295,  72.1644,  69.3527],\n",
            "        [ 54.1614,  46.1007,  82.3097,  74.5171],\n",
            "        [ 23.5705,  15.3725,  51.6748,  43.7422],\n",
            "        [  8.3194, 163.9269,  36.3451, 192.2489],\n",
            "        [ 33.7480, 179.2434,  61.8766, 207.6455],\n",
            "        [ 28.6706, 169.0092,  56.7787, 197.3979],\n",
            "        [ 38.8500,   5.1523,  66.9801,  33.5393],\n",
            "        [ 18.4079, 153.6630,  46.5205, 182.0638],\n",
            "        [ 18.3805, 138.2595,  46.5152, 166.6633],\n",
            "        [ 39.0225,  30.7893,  67.0523,  59.1016],\n",
            "        [ 33.7146, 189.4589,  61.8674, 217.8756],\n",
            "        [ 13.3565, 184.3487,  41.4243, 212.6901],\n",
            "        [  8.1868, 215.0771,  36.3237, 243.4845],\n",
            "        [ 38.8090, 107.5578,  66.9717, 135.9999],\n",
            "        [ 44.0743,  51.2514,  72.1392,  79.6072],\n",
            "        [ 33.7532,  97.3532,  61.9013, 125.7891],\n",
            "        [ 49.0417,  66.5735,  77.2159,  95.0070],\n",
            "        [ 23.6191, 117.8130,  51.6742, 146.1559],\n",
            "        [ 33.6686, 128.0137,  61.8440, 156.4495],\n",
            "        [ 13.2530, 204.8406,  41.4066, 233.2613],\n",
            "        [ 23.4787, 199.6755,  51.6401, 228.0983],\n",
            "        [ 38.7913,  76.8004,  66.9923, 105.2560],\n",
            "        [ 18.3647, 215.0428,  46.5308, 243.4693],\n",
            "        [ 43.9724,  15.4346,  72.1142,  43.8664],\n",
            "        [ 13.3838, 122.9089,  41.4427, 151.2481],\n",
            "        [ 49.1968,  30.8074,  77.2649,  59.1697],\n",
            "        [ 23.5876, 179.2400,  51.6567, 207.5872],\n",
            "        [ 28.6243,  56.2787,  56.7948,  84.7034],\n",
            "        [ 28.5537, 138.2476,  56.7359, 166.6883],\n",
            "        [  8.2694, 153.6904,  36.3310, 182.0482],\n",
            "        [ 28.7225,   5.1659,  56.7963,  33.5121],\n",
            "        [ 33.8667,  20.5502,  61.9160,  48.8842],\n",
            "        [  3.0899, 174.0713,  31.2221, 202.4626],\n",
            "        [ 38.9067,  61.4656,  67.0140,  89.8440],\n",
            "        [ 33.6828, 199.6830,  61.8665, 228.1237],\n",
            "        [ 28.6245, 158.7512,  56.7720, 187.1740],\n",
            "        [ 28.7274, 107.6041,  56.8015, 135.9811],\n",
            "        [ 38.7993, 169.0060,  66.9789, 197.4554],\n",
            "        [ 18.4485, 102.4667,  46.5831, 130.8875],\n",
            "        [ 18.4134,   5.0962,  46.5722,  33.5145],\n",
            "        [ 38.7878,  87.0696,  66.9942, 115.5368],\n",
            "        [ 18.4750, 163.9160,  46.5394, 192.2766],\n",
            "        [ 33.8619,  40.9844,  61.9394,  69.3312],\n",
            "        [ 23.5285, 128.0214,  51.6390, 156.4006],\n",
            "        [ 33.8413,  51.2297,  61.9314,  79.5903],\n",
            "        [ 48.9915,  76.7958,  77.2126, 105.2680],\n",
            "        [ 28.5898, 209.9134,  56.7716, 238.3533],\n",
            "        [  8.2150, 133.1586,  36.3154, 161.5351],\n",
            "        [  3.0786, 122.9197,  31.2236, 151.3312],\n",
            "        [ 13.4139, 112.7002,  41.4694, 141.0465],\n",
            "        [ 28.5709, 148.4911,  56.7537, 176.9377],\n",
            "        [ 43.8666,  97.3065,  72.0839, 125.7910],\n",
            "        [ 38.7563, 209.9438,  66.9698, 238.4098],\n",
            "        [ 23.5326, 189.4487,  51.6449, 217.8255],\n",
            "        [ 59.2725,  25.6487,  87.4641,  54.1238],\n",
            "        [ 33.7324, 117.7946,  61.8597, 146.1996],\n",
            "        [ 54.1995,  40.9966,  82.3235,  69.3970],\n",
            "        [ 38.7772, 158.7553,  66.9786, 187.2174],\n",
            "        [  8.2183, 143.4265,  36.3163, 171.8101],\n",
            "        [ 28.5433,  66.4872,  56.7660,  94.9584],\n",
            "        [ 23.4879,  35.7761,  51.6708,  64.2062],\n",
            "        [ 13.2619, 194.5753,  41.4039, 222.9744],\n",
            "        [ 43.8222, 184.3524,  72.0636, 212.8557],\n",
            "        [ 28.7023,  30.7110,  56.8021,  59.0673],\n",
            "        [ 43.8020, 194.5908,  72.0575, 223.1021],\n",
            "        [ 32.9470,  20.0600,  85.5314,  72.2668],\n",
            "        [ 18.3512,  25.5329,  46.5463,  53.9708],\n",
            "        [ 23.5705,  15.3725,  51.6748,  43.7422],\n",
            "        [ 44.0427,  20.5760,  72.1382,  48.9681],\n",
            "        [ 49.0579,  61.4609,  77.2118,  89.8810],\n",
            "        [ 89.9539,  10.2286, 118.1863,  38.7050],\n",
            "        [ 38.8500,   5.1523,  66.9801,  33.5393],\n",
            "        [ 28.4947, 220.0574,  56.7528, 248.5389],\n",
            "        [ 38.7411, 148.4988,  66.9728, 176.9858],\n",
            "        [ 33.7347, 184.3520,  61.8719, 212.7586],\n",
            "        [ 48.9389,  87.0370,  77.1964, 115.5462],\n",
            "        [ 38.8192,  71.6809,  66.9941, 100.1139],\n",
            "        [ 79.7119,   5.0922, 107.9489,  33.5655],\n",
            "        [ 18.3805, 138.2595,  46.5152, 166.6633],\n",
            "        [ 28.6706, 169.0092,  56.7787, 197.3979],\n",
            "        [ 18.4079, 153.6630,  46.5205, 182.0638],\n",
            "        [ 38.7114, 138.2442,  66.9594, 166.7449]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0611, 0.0604, 0.0602, 0.0599, 0.0592, 0.0590, 0.0587, 0.0584, 0.0580,\n",
            "        0.0579, 0.0579, 0.0576, 0.0575, 0.0575, 0.0574, 0.0570, 0.0569, 0.0568,\n",
            "        0.0567, 0.0566, 0.0565, 0.0562, 0.0562, 0.0562, 0.0562, 0.0561, 0.0560,\n",
            "        0.0560, 0.0557, 0.0556, 0.0552, 0.0551, 0.0550, 0.0549, 0.0549, 0.0549,\n",
            "        0.0549, 0.0548, 0.0547, 0.0544, 0.0543, 0.0543, 0.0542, 0.0541, 0.0541,\n",
            "        0.0541, 0.0541, 0.0540, 0.0539, 0.0537, 0.0533, 0.0533, 0.0532, 0.0531,\n",
            "        0.0531, 0.0530, 0.0530, 0.0530, 0.0530, 0.0529, 0.0528, 0.0527, 0.0527,\n",
            "        0.0527, 0.0526, 0.0526, 0.0526, 0.0526, 0.0525, 0.0525, 0.0524, 0.0524,\n",
            "        0.0523, 0.0522, 0.0522, 0.0521, 0.0518, 0.0518, 0.0518, 0.0517, 0.0517,\n",
            "        0.0516, 0.0516, 0.0516, 0.0516, 0.0515, 0.0515, 0.0514, 0.0514, 0.0512,\n",
            "        0.0512, 0.0511, 0.0510, 0.0508, 0.0507, 0.0507, 0.0506, 0.0506, 0.0506,\n",
            "        0.0505, 0.0504, 0.0504, 0.0504, 0.0504, 0.0503, 0.0503, 0.0502, 0.0502,\n",
            "        0.0502, 0.0501, 0.0501, 0.0501], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1,\n",
            "        2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1,\n",
            "        1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 1,\n",
            "        2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 2], device='cuda:0')}, {'boxes': tensor([[218.0323, 112.6683, 246.1969, 141.0920],\n",
            "        [136.0867, 122.9184, 164.2643, 151.3571],\n",
            "        [212.9418, 102.4389, 241.0970, 130.8619],\n",
            "        [207.7953, 112.6141, 235.9769, 141.0508],\n",
            "        [ 48.9978, 143.3643,  77.2102, 171.8254],\n",
            "        [130.9455, 215.0410, 159.1639, 243.5124],\n",
            "        [217.9059, 122.8540, 246.1501, 151.3357],\n",
            "        [222.9599, 102.4231, 251.2263, 130.9777],\n",
            "        [125.8547, 122.8713, 154.0634, 151.3280],\n",
            "        [ 43.9063, 133.1492,  72.1112, 161.6176],\n",
            "        [187.2502, 117.7626, 215.4704, 146.2450],\n",
            "        [202.6457, 102.3978, 230.8569, 130.8650],\n",
            "        [197.4909, 117.7384, 225.7142, 146.2216],\n",
            "        [207.7280, 122.8341, 235.9572, 151.3103]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0539, 0.0528, 0.0527, 0.0519, 0.0513, 0.0512, 0.0510, 0.0507, 0.0507,\n",
            "        0.0506, 0.0504, 0.0502, 0.0501, 0.0501], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')}, {'boxes': tensor([[213.2166, 128.0781, 241.1520, 156.3139],\n",
            "        [202.9832, 128.0714, 230.9275, 156.3150],\n",
            "        [131.2508, 143.4344, 159.2122, 171.7004],\n",
            "        ...,\n",
            "        [115.2050, 173.1241, 167.7139, 225.2632],\n",
            "        [185.8215, 183.5029, 238.7906, 235.8222],\n",
            "        [ 32.6579, 132.5323,  85.3759, 184.7998]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0640, 0.0630, 0.0630, 0.0618, 0.0618, 0.0615, 0.0613, 0.0609, 0.0607,\n",
            "        0.0605, 0.0604, 0.0604, 0.0604, 0.0601, 0.0598, 0.0598, 0.0597, 0.0595,\n",
            "        0.0594, 0.0594, 0.0594, 0.0593, 0.0592, 0.0590, 0.0590, 0.0590, 0.0589,\n",
            "        0.0588, 0.0588, 0.0587, 0.0587, 0.0586, 0.0584, 0.0584, 0.0584, 0.0584,\n",
            "        0.0584, 0.0583, 0.0582, 0.0581, 0.0581, 0.0581, 0.0580, 0.0580, 0.0579,\n",
            "        0.0578, 0.0578, 0.0578, 0.0577, 0.0576, 0.0576, 0.0575, 0.0575, 0.0575,\n",
            "        0.0575, 0.0575, 0.0575, 0.0574, 0.0574, 0.0572, 0.0572, 0.0571, 0.0571,\n",
            "        0.0570, 0.0570, 0.0569, 0.0569, 0.0569, 0.0568, 0.0568, 0.0568, 0.0567,\n",
            "        0.0567, 0.0567, 0.0567, 0.0567, 0.0567, 0.0567, 0.0566, 0.0566, 0.0566,\n",
            "        0.0566, 0.0565, 0.0565, 0.0565, 0.0564, 0.0564, 0.0564, 0.0563, 0.0563,\n",
            "        0.0562, 0.0562, 0.0562, 0.0561, 0.0561, 0.0561, 0.0561, 0.0560, 0.0560,\n",
            "        0.0560, 0.0560, 0.0560, 0.0560, 0.0558, 0.0558, 0.0558, 0.0557, 0.0556,\n",
            "        0.0556, 0.0555, 0.0555, 0.0554, 0.0554, 0.0554, 0.0554, 0.0554, 0.0554,\n",
            "        0.0554, 0.0553, 0.0553, 0.0553, 0.0553, 0.0552, 0.0552, 0.0552, 0.0552,\n",
            "        0.0552, 0.0551, 0.0551, 0.0550, 0.0550, 0.0550, 0.0550, 0.0550, 0.0549,\n",
            "        0.0549, 0.0549, 0.0549, 0.0549, 0.0549, 0.0548, 0.0548, 0.0548, 0.0548,\n",
            "        0.0548, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547, 0.0546, 0.0546, 0.0546,\n",
            "        0.0546, 0.0546, 0.0546, 0.0545, 0.0545, 0.0545, 0.0545, 0.0544, 0.0544,\n",
            "        0.0544, 0.0544, 0.0543, 0.0543, 0.0543, 0.0543, 0.0542, 0.0542, 0.0541,\n",
            "        0.0541, 0.0541, 0.0541, 0.0541, 0.0540, 0.0540, 0.0540, 0.0539, 0.0539,\n",
            "        0.0539, 0.0538, 0.0538, 0.0538, 0.0538, 0.0538, 0.0538, 0.0538, 0.0538,\n",
            "        0.0537, 0.0537, 0.0537, 0.0537, 0.0536, 0.0536, 0.0536, 0.0536, 0.0536,\n",
            "        0.0536, 0.0535, 0.0535, 0.0535, 0.0535, 0.0534, 0.0534, 0.0534, 0.0534,\n",
            "        0.0534, 0.0534, 0.0533, 0.0533, 0.0533, 0.0533, 0.0532, 0.0532, 0.0532,\n",
            "        0.0532, 0.0532, 0.0532, 0.0531, 0.0531, 0.0531, 0.0531, 0.0531, 0.0531,\n",
            "        0.0531, 0.0530, 0.0530, 0.0530, 0.0529, 0.0529, 0.0529, 0.0529, 0.0529,\n",
            "        0.0529, 0.0529, 0.0529, 0.0529, 0.0528, 0.0528, 0.0528, 0.0528, 0.0528,\n",
            "        0.0528, 0.0527, 0.0527, 0.0527, 0.0527, 0.0527, 0.0527, 0.0526, 0.0526,\n",
            "        0.0526, 0.0526, 0.0526, 0.0526, 0.0525, 0.0525, 0.0525, 0.0525, 0.0525,\n",
            "        0.0524, 0.0524, 0.0524, 0.0522, 0.0522, 0.0521, 0.0518, 0.0517, 0.0515,\n",
            "        0.0513, 0.0511, 0.0511, 0.0510, 0.0509, 0.0508, 0.0508, 0.0507, 0.0506,\n",
            "        0.0505, 0.0504, 0.0504, 0.0504, 0.0504, 0.0503, 0.0503, 0.0503, 0.0501],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
            "        2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2,\n",
            "        2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2,\n",
            "        2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 1,\n",
            "        1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2,\n",
            "        1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2,\n",
            "        1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "       device='cuda:0')}]\n",
            "[{'boxes': tensor([[193.0039, 204.9095, 220.7370, 232.9791],\n",
            "        [203.2406, 204.9119, 230.9747, 232.9832],\n",
            "        [182.7597, 204.9039, 210.4983, 232.9770],\n",
            "        ...,\n",
            "        [135.9361, 123.4796, 188.1169, 175.8944],\n",
            "        [105.9198, 132.7198, 157.7192, 184.1349],\n",
            "        [136.1192, 182.4597, 188.5330, 233.8942]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0753, 0.0752, 0.0751, 0.0750, 0.0750, 0.0748, 0.0748, 0.0747, 0.0745,\n",
            "        0.0745, 0.0743, 0.0743, 0.0741, 0.0741, 0.0740, 0.0740, 0.0739, 0.0738,\n",
            "        0.0736, 0.0733, 0.0730, 0.0730, 0.0728, 0.0722, 0.0722, 0.0721, 0.0719,\n",
            "        0.0717, 0.0714, 0.0714, 0.0714, 0.0708, 0.0706, 0.0703, 0.0702, 0.0699,\n",
            "        0.0698, 0.0696, 0.0696, 0.0688, 0.0687, 0.0687, 0.0684, 0.0683, 0.0682,\n",
            "        0.0681, 0.0681, 0.0680, 0.0679, 0.0679, 0.0677, 0.0677, 0.0677, 0.0676,\n",
            "        0.0676, 0.0676, 0.0675, 0.0673, 0.0672, 0.0672, 0.0671, 0.0669, 0.0668,\n",
            "        0.0668, 0.0667, 0.0666, 0.0666, 0.0665, 0.0665, 0.0664, 0.0661, 0.0661,\n",
            "        0.0660, 0.0660, 0.0660, 0.0660, 0.0658, 0.0658, 0.0656, 0.0656, 0.0655,\n",
            "        0.0655, 0.0652, 0.0652, 0.0652, 0.0651, 0.0651, 0.0651, 0.0650, 0.0649,\n",
            "        0.0648, 0.0648, 0.0647, 0.0647, 0.0645, 0.0645, 0.0644, 0.0643, 0.0642,\n",
            "        0.0642, 0.0642, 0.0641, 0.0641, 0.0640, 0.0639, 0.0639, 0.0638, 0.0632,\n",
            "        0.0632, 0.0631, 0.0630, 0.0630, 0.0629, 0.0629, 0.0624, 0.0624, 0.0624,\n",
            "        0.0623, 0.0623, 0.0623, 0.0622, 0.0622, 0.0622, 0.0621, 0.0619, 0.0619,\n",
            "        0.0618, 0.0618, 0.0613, 0.0613, 0.0612, 0.0612, 0.0611, 0.0609, 0.0609,\n",
            "        0.0609, 0.0608, 0.0607, 0.0607, 0.0607, 0.0607, 0.0607, 0.0607, 0.0606,\n",
            "        0.0606, 0.0606, 0.0606, 0.0605, 0.0604, 0.0603, 0.0602, 0.0600, 0.0600,\n",
            "        0.0600, 0.0599, 0.0598, 0.0598, 0.0597, 0.0596, 0.0595, 0.0595, 0.0594,\n",
            "        0.0594, 0.0593, 0.0592, 0.0592, 0.0592, 0.0591, 0.0587, 0.0587, 0.0585,\n",
            "        0.0584, 0.0583, 0.0582, 0.0582, 0.0581, 0.0581, 0.0581, 0.0580, 0.0579,\n",
            "        0.0579, 0.0578, 0.0576, 0.0575, 0.0574, 0.0574, 0.0573, 0.0573, 0.0572,\n",
            "        0.0572, 0.0572, 0.0572, 0.0572, 0.0571, 0.0570, 0.0570, 0.0570, 0.0570,\n",
            "        0.0569, 0.0569, 0.0568, 0.0566, 0.0566, 0.0565, 0.0565, 0.0565, 0.0564,\n",
            "        0.0564, 0.0564, 0.0563, 0.0562, 0.0561, 0.0561, 0.0560, 0.0560, 0.0559,\n",
            "        0.0559, 0.0559, 0.0558, 0.0558, 0.0558, 0.0553, 0.0553, 0.0552, 0.0552,\n",
            "        0.0552, 0.0552, 0.0551, 0.0551, 0.0551, 0.0548, 0.0548, 0.0548, 0.0547,\n",
            "        0.0547, 0.0547, 0.0547, 0.0546, 0.0545, 0.0545, 0.0544, 0.0544, 0.0544,\n",
            "        0.0543, 0.0543, 0.0543, 0.0543, 0.0543, 0.0541, 0.0540, 0.0539, 0.0539,\n",
            "        0.0539, 0.0538, 0.0538, 0.0538, 0.0538, 0.0537, 0.0537, 0.0537, 0.0535,\n",
            "        0.0535, 0.0534, 0.0533, 0.0533, 0.0532, 0.0532, 0.0531, 0.0531, 0.0530,\n",
            "        0.0530, 0.0529, 0.0529, 0.0529, 0.0527, 0.0527, 0.0527, 0.0527, 0.0526,\n",
            "        0.0526, 0.0526, 0.0526, 0.0526, 0.0525, 0.0525, 0.0524, 0.0522, 0.0519,\n",
            "        0.0518, 0.0518, 0.0515, 0.0510, 0.0510, 0.0510, 0.0509, 0.0508, 0.0506,\n",
            "        0.0504, 0.0504, 0.0504], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1,\n",
            "        1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1,\n",
            "        2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 2,\n",
            "        2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1,\n",
            "        2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1,\n",
            "        1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1,\n",
            "        1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1,\n",
            "        2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1,\n",
            "        1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 2,\n",
            "        1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1,\n",
            "        1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2], device='cuda:0')}, {'boxes': tensor([[1.3134e+02, 1.6390e+02, 1.5922e+02, 1.9209e+02],\n",
            "        [3.9092e+01, 1.9975e+02, 6.7070e+01, 2.2803e+02],\n",
            "        [8.5136e+01, 1.0247e+02, 1.1313e+02, 1.3076e+02],\n",
            "        [6.4659e+01, 1.1270e+02, 9.2658e+01, 1.4100e+02],\n",
            "        [3.9090e+01, 1.8955e+02, 6.7077e+01, 2.1784e+02],\n",
            "        [1.3640e+02, 1.5374e+02, 1.6435e+02, 1.8203e+02],\n",
            "        [7.4909e+01, 1.0757e+02, 1.0290e+02, 1.3586e+02],\n",
            "        [1.4134e+02, 1.6386e+02, 1.6936e+02, 1.9216e+02],\n",
            "        [1.3134e+02, 1.6390e+02, 1.5922e+02, 1.9209e+02],\n",
            "        [4.9227e+01, 1.9974e+02, 7.7246e+01, 2.2805e+02],\n",
            "        [5.4437e+01, 1.1271e+02, 8.2439e+01, 1.4100e+02],\n",
            "        [3.8994e+01, 2.0995e+02, 6.7034e+01, 2.3826e+02],\n",
            "        [8.2550e+00, 1.1782e+02, 3.6306e+01, 1.4616e+02],\n",
            "        [1.5161e+02, 1.2805e+02, 1.7967e+02, 1.5639e+02],\n",
            "        [1.2103e+02, 1.6386e+02, 1.4902e+02, 1.9211e+02],\n",
            "        [8.5043e+01, 1.1264e+02, 1.1310e+02, 1.4096e+02],\n",
            "        [1.4138e+02, 4.6130e+01, 1.6944e+02, 7.4468e+01],\n",
            "        [1.2621e+02, 1.5375e+02, 1.5418e+02, 1.8203e+02],\n",
            "        [8.5087e+01, 9.2270e+01, 1.1314e+02, 1.2062e+02],\n",
            "        [1.3103e+02, 1.7404e+02, 1.5914e+02, 2.0237e+02],\n",
            "        [4.9193e+01, 1.8953e+02, 7.7246e+01, 2.1789e+02],\n",
            "        [9.5240e+01, 1.0757e+02, 1.2332e+02, 1.3593e+02],\n",
            "        [1.4140e+02, 1.2293e+02, 1.6945e+02, 1.5126e+02],\n",
            "        [1.4652e+02, 3.5932e+01, 1.7458e+02, 6.4282e+01],\n",
            "        [5.9395e+01, 1.2287e+02, 8.7485e+01, 1.5121e+02],\n",
            "        [1.5165e+02, 1.1785e+02, 1.7970e+02, 1.4621e+02],\n",
            "        [3.8953e+01, 4.6132e+01, 6.7027e+01, 7.4484e+01],\n",
            "        [8.2127e+00, 1.0762e+02, 3.6291e+01, 1.3600e+02],\n",
            "        [7.4759e+01, 1.1775e+02, 1.0284e+02, 1.4610e+02],\n",
            "        [1.3317e+01, 1.2802e+02, 4.1411e+01, 1.5638e+02],\n",
            "        [4.9162e+01, 2.0991e+02, 7.7242e+01, 2.3825e+02],\n",
            "        [7.4908e+01, 9.7370e+01, 1.0294e+02, 1.2570e+02],\n",
            "        [3.9092e+01, 1.9975e+02, 6.7070e+01, 2.2803e+02],\n",
            "        [3.9000e+01, 1.7931e+02, 6.7057e+01, 2.0766e+02],\n",
            "        [1.3113e+02, 5.1224e+01, 1.5921e+02, 7.9581e+01],\n",
            "        [6.4665e+01, 1.0250e+02, 9.2699e+01, 1.3085e+02],\n",
            "        [9.0145e+01, 6.1504e+01, 1.1823e+02, 8.9874e+01],\n",
            "        [1.5154e+02, 1.3827e+02, 1.7965e+02, 1.6663e+02],\n",
            "        [9.5226e+01, 1.1778e+02, 1.2333e+02, 1.4614e+02],\n",
            "        [1.4131e+02, 1.3313e+02, 1.6942e+02, 1.6150e+02],\n",
            "        [2.8748e+01, 1.9457e+02, 5.6825e+01, 2.2291e+02],\n",
            "        [8.5136e+01, 1.0247e+02, 1.1313e+02, 1.3076e+02],\n",
            "        [1.4643e+02, 1.5365e+02, 1.7450e+02, 1.8202e+02],\n",
            "        [6.4659e+01, 1.1270e+02, 9.2658e+01, 1.4100e+02],\n",
            "        [2.8735e+01, 2.0480e+02, 5.6825e+01, 2.3316e+02],\n",
            "        [1.4126e+02, 5.6322e+01, 1.6939e+02, 8.4716e+01],\n",
            "        [1.3626e+02, 3.5906e+01, 1.6435e+02, 6.4267e+01],\n",
            "        [4.4081e+01, 1.1777e+02, 7.2169e+01, 1.4613e+02],\n",
            "        [1.0548e+02, 1.1781e+02, 1.3358e+02, 1.4618e+02],\n",
            "        [3.9090e+01, 1.8955e+02, 6.7077e+01, 2.1784e+02],\n",
            "        [9.5179e+01, 9.7363e+01, 1.2329e+02, 1.2577e+02],\n",
            "        [1.5147e+02, 4.6100e+01, 1.7960e+02, 7.4506e+01],\n",
            "        [2.3548e+01, 1.3315e+02, 5.1657e+01, 1.6153e+02],\n",
            "        [1.6171e+02, 1.2805e+02, 1.8985e+02, 1.5646e+02],\n",
            "        [7.4909e+01, 1.0757e+02, 1.0290e+02, 1.3586e+02],\n",
            "        [1.4134e+02, 1.6386e+02, 1.6936e+02, 1.9216e+02],\n",
            "        [2.8680e+01, 5.1211e+01, 5.6796e+01, 7.9594e+01],\n",
            "        [9.5259e+01, 5.1281e+01, 1.2336e+02, 7.9666e+01],\n",
            "        [1.4134e+02, 1.4343e+02, 1.6943e+02, 1.7181e+02],\n",
            "        [1.5663e+02, 3.5887e+01, 1.8475e+02, 6.4289e+01],\n",
            "        [1.3108e+02, 1.2288e+02, 1.5919e+02, 1.5126e+02],\n",
            "        [1.3640e+02, 1.5374e+02, 1.6435e+02, 1.8203e+02],\n",
            "        [2.8732e+01, 1.8435e+02, 5.6821e+01, 2.1272e+02],\n",
            "        [9.0049e+01, 7.1723e+01, 1.1819e+02, 1.0013e+02],\n",
            "        [1.6173e+02, 1.1782e+02, 1.8986e+02, 1.4625e+02],\n",
            "        [2.8660e+01, 2.1502e+02, 5.6797e+01, 2.4341e+02],\n",
            "        [4.9227e+01, 1.9974e+02, 7.7246e+01, 2.2805e+02],\n",
            "        [3.8994e+01, 2.0995e+02, 6.7034e+01, 2.3826e+02],\n",
            "        [5.4437e+01, 1.1271e+02, 8.2439e+01, 1.4100e+02],\n",
            "        [1.2084e+02, 5.1214e+01, 1.4896e+02, 7.9601e+01],\n",
            "        [1.6170e+02, 1.3826e+02, 1.8985e+02, 1.6668e+02],\n",
            "        [1.8396e+01, 1.1782e+02, 4.6521e+01, 1.4622e+02],\n",
            "        [8.1333e+00, 9.7373e+01, 3.6280e+01, 1.2581e+02],\n",
            "        [8.4963e+01, 8.1988e+01, 1.1310e+02, 1.1040e+02],\n",
            "        [1.5161e+02, 1.2805e+02, 1.7967e+02, 1.5639e+02],\n",
            "        [3.3735e+01, 1.3829e+02, 6.1876e+01, 1.6670e+02],\n",
            "        [1.1571e+02, 1.1780e+02, 1.4382e+02, 1.4619e+02],\n",
            "        [1.0029e+02, 1.2801e+02, 1.2844e+02, 1.5642e+02],\n",
            "        [8.2550e+00, 1.1782e+02, 3.6306e+01, 1.4616e+02],\n",
            "        [5.9314e+01, 2.0485e+02, 8.7455e+01, 2.3326e+02],\n",
            "        [6.9524e+01, 1.2798e+02, 9.7695e+01, 1.5640e+02],\n",
            "        [3.8931e+01, 3.5944e+01, 6.7052e+01, 6.4354e+01],\n",
            "        [5.4354e+01, 1.0250e+02, 8.2445e+01, 1.3089e+02],\n",
            "        [1.4114e+02, 1.7402e+02, 1.6933e+02, 2.0242e+02],\n",
            "        [1.2103e+02, 1.6386e+02, 1.4902e+02, 1.9211e+02],\n",
            "        [8.5043e+01, 1.1264e+02, 1.1310e+02, 1.4096e+02],\n",
            "        [1.7195e+02, 8.7070e+01, 2.0012e+02, 1.1549e+02],\n",
            "        [1.2079e+02, 1.7400e+02, 1.4894e+02, 2.0239e+02],\n",
            "        [3.3761e+01, 1.2804e+02, 6.1897e+01, 1.5645e+02],\n",
            "        [1.4138e+02, 4.6130e+01, 1.6944e+02, 7.4468e+01],\n",
            "        [8.4937e+01, 1.2283e+02, 1.1309e+02, 1.5124e+02],\n",
            "        [1.3096e+02, 6.1391e+01, 1.5914e+02, 8.9818e+01],\n",
            "        [1.0027e+02, 6.1436e+01, 1.2841e+02, 8.9842e+01],\n",
            "        [4.4069e+01, 1.0757e+02, 7.2187e+01, 1.3596e+02],\n",
            "        [4.9098e+01, 1.7930e+02, 7.7229e+01, 2.0772e+02],\n",
            "        [1.3103e+02, 1.7404e+02, 1.5914e+02, 2.0237e+02],\n",
            "        [1.9751e+02, 5.1005e+00, 2.2569e+02, 3.3516e+01],\n",
            "        [1.1562e+02, 5.1065e+00, 1.4379e+02, 3.3522e+01],\n",
            "        [3.8779e+01, 5.6295e+01, 6.6964e+01, 8.4723e+01],\n",
            "        [4.9041e+01, 4.1018e+01, 7.7204e+01, 6.9464e+01],\n",
            "        [3.8870e+01, 1.6904e+02, 6.7012e+01, 1.9745e+02],\n",
            "        [1.0546e+02, 5.1227e+01, 1.3358e+02, 7.9619e+01],\n",
            "        [3.3699e+01, 1.4851e+02, 6.1865e+01, 1.7693e+02],\n",
            "        [1.2598e+02, 4.0993e+01, 1.5410e+02, 6.9394e+01],\n",
            "        [5.9395e+01, 1.2287e+02, 8.7485e+01, 1.5121e+02],\n",
            "        [2.8702e+01, 4.1004e+01, 5.6827e+01, 6.9404e+01],\n",
            "        [4.9080e+01, 1.2795e+02, 7.7245e+01, 1.5636e+02],\n",
            "        [1.3221e+01, 1.3819e+02, 4.1399e+01, 1.6660e+02],\n",
            "        [5.9275e+01, 2.1501e+02, 8.7461e+01, 2.4343e+02],\n",
            "        [8.5087e+01, 9.2270e+01, 1.1314e+02, 1.2062e+02],\n",
            "        [1.4140e+02, 1.2293e+02, 1.6945e+02, 1.5126e+02],\n",
            "        [9.5240e+01, 1.0757e+02, 1.2332e+02, 1.3593e+02],\n",
            "        [2.3473e+01, 1.4332e+02, 5.1637e+01, 1.7173e+02],\n",
            "        [7.4759e+01, 1.1775e+02, 1.0284e+02, 1.4610e+02],\n",
            "        [4.9193e+01, 1.8953e+02, 7.7246e+01, 2.1789e+02],\n",
            "        [3.8953e+01, 4.6132e+01, 6.7027e+01, 7.4484e+01],\n",
            "        [1.2621e+02, 1.5375e+02, 1.5418e+02, 1.8203e+02],\n",
            "        [1.5656e+02, 1.4847e+02, 1.8474e+02, 1.7690e+02],\n",
            "        [1.7195e+02, 7.6865e+01, 2.0012e+02, 1.0531e+02],\n",
            "        [1.4652e+02, 3.5932e+01, 1.7458e+02, 6.4282e+01],\n",
            "        [4.9162e+01, 2.0991e+02, 7.7242e+01, 2.3825e+02],\n",
            "        [1.7191e+02, 1.8946e+02, 2.0011e+02, 2.1792e+02],\n",
            "        [3.8788e+01, 1.5877e+02, 6.6975e+01, 1.8721e+02],\n",
            "        [1.6173e+02, 1.0758e+02, 1.8989e+02, 1.3603e+02],\n",
            "        [1.5165e+02, 1.1785e+02, 1.7970e+02, 1.4621e+02],\n",
            "        [1.1563e+02, 2.0482e+02, 1.4380e+02, 2.3325e+02],\n",
            "        [1.3317e+01, 1.2802e+02, 4.1411e+01, 1.5638e+02],\n",
            "        [1.4135e+02, 1.1272e+02, 1.6947e+02, 1.4114e+02],\n",
            "        [8.2127e+00, 1.0762e+02, 3.6291e+01, 1.3600e+02],\n",
            "        [1.0539e+02, 1.0759e+02, 1.3355e+02, 1.3603e+02],\n",
            "        [2.8530e+01, 6.1411e+01, 5.6739e+01, 8.9866e+01],\n",
            "        [3.8720e+01, 2.2003e+02, 6.6963e+01, 2.4848e+02],\n",
            "        [1.7191e+02, 9.7287e+01, 2.0011e+02, 1.2573e+02],\n",
            "        [1.1049e+02, 1.2797e+02, 1.3866e+02, 1.5640e+02],\n",
            "        [1.0535e+02, 5.0630e+00, 1.3356e+02, 3.3504e+01],\n",
            "        [1.2583e+02, 2.1503e+02, 1.5403e+02, 2.4347e+02],\n",
            "        [5.9263e+01, 1.9462e+02, 8.7440e+01, 2.2308e+02],\n",
            "        [9.5091e+01, 8.7115e+01, 1.2328e+02, 1.1558e+02],\n",
            "        [1.5138e+02, 5.6322e+01, 1.7959e+02, 8.4784e+01],\n",
            "        [1.5140e+02, 1.6382e+02, 1.7959e+02, 1.9227e+02],\n",
            "        [8.4971e+01, 5.1239e+01, 1.1313e+02, 7.9673e+01],\n",
            "        [1.3113e+02, 5.1224e+01, 1.5921e+02, 7.9581e+01],\n",
            "        [1.8733e+02, 1.7394e-02, 2.1551e+02, 2.8429e+01],\n",
            "        [2.8652e+01, 1.7411e+02, 5.6803e+01, 2.0253e+02],\n",
            "        [3.3775e+01, 1.1778e+02, 6.1923e+01, 1.4619e+02],\n",
            "        [1.8370e+01, 5.1181e+01, 4.6549e+01, 7.9620e+01],\n",
            "        [1.5154e+02, 1.3827e+02, 1.7965e+02, 1.6663e+02],\n",
            "        [3.9000e+01, 1.7931e+02, 6.7057e+01, 2.0766e+02],\n",
            "        [9.0145e+01, 6.1504e+01, 1.1823e+02, 8.9874e+01],\n",
            "        [1.7701e+02, 1.9969e+02, 2.0522e+02, 2.2816e+02],\n",
            "        [7.4908e+01, 9.7370e+01, 1.0294e+02, 1.2570e+02],\n",
            "        [9.5226e+01, 1.1778e+02, 1.2333e+02, 1.4614e+02],\n",
            "        [1.3108e+02, 1.4343e+02, 1.5922e+02, 1.7185e+02],\n",
            "        [9.0022e+01, 1.3309e+02, 1.1821e+02, 1.6153e+02],\n",
            "        [1.2069e+02, 6.1361e+01, 1.4890e+02, 8.9804e+01],\n",
            "        [1.3606e+02, 2.2012e+02, 1.6428e+02, 2.4858e+02],\n",
            "        [1.4131e+02, 1.3313e+02, 1.6942e+02, 1.6150e+02],\n",
            "        [1.8215e+02, 8.7064e+01, 2.1033e+02, 1.1551e+02],\n",
            "        [6.3812e+01, 1.0177e+02, 1.1632e+02, 1.5370e+02],\n",
            "        [6.4665e+01, 1.0250e+02, 9.2699e+01, 1.3085e+02],\n",
            "        [4.8923e+01, 5.1181e+01, 7.7155e+01, 7.9652e+01],\n",
            "        [1.3096e+02, 1.3306e+02, 1.5916e+02, 1.6149e+02],\n",
            "        [7.9810e+01, 6.6525e+01, 1.0799e+02, 9.4961e+01],\n",
            "        [7.4144e+01, 9.1852e+01, 1.2655e+02, 1.4386e+02],\n",
            "        [1.2579e+02, 5.1324e+00, 1.5400e+02, 3.3594e+01],\n",
            "        [2.8748e+01, 1.9457e+02, 5.6825e+01, 2.2291e+02],\n",
            "        [1.4126e+02, 5.6322e+01, 1.6939e+02, 8.4716e+01],\n",
            "        [4.9163e+01, 1.2285e+02, 7.7267e+01, 1.5121e+02],\n",
            "        [1.7191e+02, 1.7923e+02, 2.0011e+02, 2.0770e+02],\n",
            "        [5.9228e+01, 1.3305e+02, 8.7449e+01, 1.6150e+02],\n",
            "        [8.0683e+00, 8.7111e+01, 3.6278e+01, 1.1560e+02],\n",
            "        [1.2592e+02, 1.1272e+02, 1.5408e+02, 1.4116e+02],\n",
            "        [1.2581e+02, 2.0485e+02, 1.5401e+02, 2.3332e+02],\n",
            "        [2.8735e+01, 2.0480e+02, 5.6825e+01, 2.3316e+02],\n",
            "        [1.6167e+02, 7.6792e+01, 1.8988e+02, 1.0525e+02],\n",
            "        [1.2072e+02, 1.2792e+02, 1.4890e+02, 1.5635e+02],\n",
            "        [1.3542e+02, 1.3268e+02, 1.8794e+02, 1.8478e+02],\n",
            "        [1.5151e+02, 2.5699e+01, 1.7968e+02, 5.4159e+01],\n",
            "        [2.0770e+02, 5.1125e+00, 2.3592e+02, 3.3571e+01],\n",
            "        [1.4126e+02, 2.5677e+01, 1.6944e+02, 5.4129e+01],\n",
            "        [1.5147e+02, 4.6100e+01, 1.7960e+02, 7.4506e+01],\n",
            "        [1.4643e+02, 1.5365e+02, 1.7450e+02, 1.8202e+02],\n",
            "        [7.9753e+01, 1.3308e+02, 1.0796e+02, 1.6155e+02],\n",
            "        [1.3626e+02, 3.5906e+01, 1.6435e+02, 6.4267e+01],\n",
            "        [2.3548e+01, 1.3315e+02, 5.1657e+01, 1.6153e+02],\n",
            "        [1.0548e+02, 1.1781e+02, 1.3358e+02, 1.4618e+02],\n",
            "        [4.3884e+01, 1.3824e+02, 7.2095e+01, 1.6672e+02],\n",
            "        [1.6171e+02, 1.2805e+02, 1.8985e+02, 1.5646e+02],\n",
            "        [8.4047e+01, 1.0190e+02, 1.3662e+02, 1.5396e+02],\n",
            "        [1.5153e+02, 1.0759e+02, 1.7969e+02, 1.3605e+02],\n",
            "        [4.3848e+01, 1.4851e+02, 7.2071e+01, 1.7699e+02],\n",
            "        [4.4102e+01, 1.1268e+02, 7.2185e+01, 1.4103e+02],\n",
            "        [1.6677e+02, 3.0745e+01, 1.9497e+02, 5.9213e+01],\n",
            "        [9.5179e+01, 9.7363e+01, 1.2329e+02, 1.2577e+02],\n",
            "        [1.2543e+02, 1.2239e+02, 1.7786e+02, 1.7454e+02],\n",
            "        [1.8211e+02, 9.7248e+01, 2.1033e+02, 1.2571e+02],\n",
            "        [2.8680e+01, 5.1211e+01, 5.6796e+01, 7.9594e+01],\n",
            "        [1.6676e+02, 1.9965e+02, 1.9499e+02, 2.2814e+02],\n",
            "        [1.4110e+02, 6.6485e+01, 1.6935e+02, 9.4964e+01],\n",
            "        [1.6673e+02, 1.4845e+02, 1.9496e+02, 1.7693e+02],\n",
            "        [9.0049e+01, 7.1723e+01, 1.1819e+02, 1.0013e+02],\n",
            "        [2.1287e+02, 9.7276e+01, 2.4108e+02, 1.2574e+02],\n",
            "        [1.1045e+02, 6.1364e+01, 1.3865e+02, 8.9811e+01],\n",
            "        [1.3108e+02, 1.2288e+02, 1.5919e+02, 1.5126e+02],\n",
            "        [1.7698e+02, 2.0990e+02, 2.0522e+02, 2.3839e+02],\n",
            "        [1.8271e+01, 6.1387e+01, 4.6509e+01, 8.9861e+01],\n",
            "        [1.8289e+01, 1.0755e+02, 4.6491e+01, 1.3603e+02],\n",
            "        [1.5663e+02, 3.5887e+01, 1.8475e+02, 6.4289e+01],\n",
            "        [1.4134e+02, 1.4343e+02, 1.6943e+02, 1.7181e+02],\n",
            "        [4.3463e+01, 1.0181e+02, 9.5960e+01, 1.5385e+02],\n",
            "        [1.2514e+02, 1.4271e+02, 1.7770e+02, 1.9482e+02],\n",
            "        [1.4629e+02, 2.2011e+02, 1.7453e+02, 2.4860e+02],\n",
            "        [2.8732e+01, 1.8435e+02, 5.6821e+01, 2.1272e+02],\n",
            "        [1.2070e+02, 1.9461e+02, 1.4891e+02, 2.2309e+02],\n",
            "        [1.0016e+02, 1.3821e+02, 1.2839e+02, 1.6668e+02],\n",
            "        [2.8660e+01, 2.1502e+02, 5.6797e+01, 2.4341e+02],\n",
            "        [7.4729e+01, 8.7054e+01, 1.0290e+02, 1.1550e+02],\n",
            "        [5.3920e+01, 9.1711e+01, 1.0628e+02, 1.4374e+02],\n",
            "        [9.5259e+01, 5.1281e+01, 1.2336e+02, 7.9666e+01],\n",
            "        [5.3226e+01, 1.1180e+02, 1.0597e+02, 1.6392e+02],\n",
            "        [1.7185e+02, 1.0751e+02, 2.0008e+02, 1.3600e+02],\n",
            "        [1.4546e+02, 1.2257e+02, 1.9806e+02, 1.7482e+02],\n",
            "        [1.8208e+02, 1.8947e+02, 2.1032e+02, 2.1797e+02],\n",
            "        [2.9501e+00, 1.2792e+02, 3.1162e+01, 1.5636e+02],\n",
            "        [1.6165e+02, 8.6983e+01, 1.8988e+02, 1.1545e+02],\n",
            "        [1.2087e+02, 1.4854e+02, 1.4900e+02, 1.7696e+02],\n",
            "        [1.6173e+02, 1.1782e+02, 1.8986e+02, 1.4625e+02],\n",
            "        [1.3556e+02, 1.1234e+02, 1.8803e+02, 1.6457e+02],\n",
            "        [1.1566e+02, 4.0987e+01, 1.4384e+02, 6.9442e+01],\n",
            "        [4.8922e+01, 2.1998e+02, 7.7201e+01, 2.4845e+02],\n",
            "        [9.5136e+01, 4.1033e+01, 1.2334e+02, 6.9507e+01],\n",
            "        [7.3523e+01, 1.1174e+02, 1.2631e+02, 1.6387e+02],\n",
            "        [3.2964e+01, 1.1201e+02, 8.5611e+01, 1.6420e+02],\n",
            "        [2.8534e+01, 1.5868e+02, 5.6750e+01, 1.8713e+02],\n",
            "        [1.3094e+02, 2.5618e+01, 1.5916e+02, 5.4091e+01],\n",
            "        [2.1790e+02, 1.8944e+02, 2.4616e+02, 2.1795e+02],\n",
            "        [1.2576e+02, 1.8430e+02, 1.5400e+02, 2.1279e+02],\n",
            "        [6.9462e+01, 2.1504e+02, 9.7692e+01, 2.4352e+02],\n",
            "        [1.6167e+02, 9.7272e+01, 1.8989e+02, 1.2575e+02],\n",
            "        [1.6170e+02, 1.3826e+02, 1.8985e+02, 1.6668e+02],\n",
            "        [2.0260e+02, 9.7267e+01, 2.3083e+02, 1.2575e+02],\n",
            "        [1.2084e+02, 5.1214e+01, 1.4896e+02, 7.9601e+01],\n",
            "        [1.5136e+02, 6.6522e+01, 1.7960e+02, 9.5007e+01],\n",
            "        [6.9429e+01, 1.3818e+02, 9.7686e+01, 1.6667e+02]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0663, 0.0626, 0.0614, 0.0613, 0.0612, 0.0609, 0.0608, 0.0607, 0.0604,\n",
            "        0.0601, 0.0601, 0.0598, 0.0594, 0.0593, 0.0590, 0.0587, 0.0587, 0.0584,\n",
            "        0.0581, 0.0581, 0.0580, 0.0579, 0.0579, 0.0578, 0.0578, 0.0577, 0.0577,\n",
            "        0.0575, 0.0575, 0.0573, 0.0573, 0.0572, 0.0572, 0.0571, 0.0570, 0.0570,\n",
            "        0.0568, 0.0568, 0.0567, 0.0564, 0.0561, 0.0560, 0.0560, 0.0560, 0.0559,\n",
            "        0.0559, 0.0559, 0.0558, 0.0558, 0.0557, 0.0557, 0.0556, 0.0556, 0.0556,\n",
            "        0.0555, 0.0554, 0.0553, 0.0553, 0.0553, 0.0552, 0.0552, 0.0551, 0.0551,\n",
            "        0.0551, 0.0550, 0.0549, 0.0549, 0.0549, 0.0548, 0.0547, 0.0546, 0.0545,\n",
            "        0.0545, 0.0544, 0.0543, 0.0543, 0.0543, 0.0543, 0.0543, 0.0543, 0.0542,\n",
            "        0.0542, 0.0542, 0.0541, 0.0540, 0.0540, 0.0539, 0.0539, 0.0538, 0.0537,\n",
            "        0.0537, 0.0537, 0.0537, 0.0537, 0.0537, 0.0537, 0.0537, 0.0536, 0.0536,\n",
            "        0.0536, 0.0536, 0.0536, 0.0536, 0.0534, 0.0532, 0.0531, 0.0531, 0.0531,\n",
            "        0.0530, 0.0530, 0.0529, 0.0529, 0.0529, 0.0529, 0.0529, 0.0528, 0.0528,\n",
            "        0.0528, 0.0527, 0.0527, 0.0527, 0.0526, 0.0526, 0.0526, 0.0526, 0.0526,\n",
            "        0.0525, 0.0525, 0.0525, 0.0525, 0.0524, 0.0524, 0.0524, 0.0524, 0.0523,\n",
            "        0.0523, 0.0523, 0.0523, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522,\n",
            "        0.0522, 0.0521, 0.0521, 0.0521, 0.0521, 0.0521, 0.0521, 0.0520, 0.0519,\n",
            "        0.0519, 0.0519, 0.0518, 0.0518, 0.0518, 0.0517, 0.0517, 0.0517, 0.0517,\n",
            "        0.0516, 0.0516, 0.0516, 0.0515, 0.0515, 0.0514, 0.0514, 0.0514, 0.0514,\n",
            "        0.0513, 0.0513, 0.0513, 0.0513, 0.0513, 0.0513, 0.0513, 0.0512, 0.0512,\n",
            "        0.0512, 0.0511, 0.0511, 0.0510, 0.0510, 0.0510, 0.0510, 0.0509, 0.0509,\n",
            "        0.0509, 0.0509, 0.0509, 0.0508, 0.0508, 0.0508, 0.0508, 0.0508, 0.0507,\n",
            "        0.0507, 0.0507, 0.0507, 0.0507, 0.0507, 0.0506, 0.0506, 0.0506, 0.0506,\n",
            "        0.0506, 0.0505, 0.0505, 0.0505, 0.0505, 0.0505, 0.0505, 0.0505, 0.0505,\n",
            "        0.0505, 0.0505, 0.0505, 0.0505, 0.0504, 0.0504, 0.0504, 0.0504, 0.0504,\n",
            "        0.0504, 0.0503, 0.0503, 0.0503, 0.0502, 0.0502, 0.0502, 0.0502, 0.0502,\n",
            "        0.0502, 0.0502, 0.0502, 0.0501, 0.0501, 0.0501, 0.0501, 0.0501, 0.0501,\n",
            "        0.0500], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2,\n",
            "        2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2,\n",
            "        2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1,\n",
            "        1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
            "        2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1,\n",
            "        2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1,\n",
            "        2, 1, 1, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1,\n",
            "        2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1,\n",
            "        2, 1, 2, 2], device='cuda:0')}, {'boxes': tensor([[151.9407, 122.9718, 179.7585, 151.1158],\n",
            "        [157.0382, 112.7619, 184.8685, 140.9226],\n",
            "        [162.0209, 122.9381, 189.9123, 151.1358],\n",
            "        ...,\n",
            "        [186.3657,  19.9309, 239.0032,  71.9507],\n",
            "        [ 63.8919,  30.4436, 116.3283,  82.5722],\n",
            "        [ 23.2442,  91.4901,  75.6038, 143.4932]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0713, 0.0701, 0.0682, 0.0681, 0.0674, 0.0673, 0.0673, 0.0671, 0.0671,\n",
            "        0.0667, 0.0661, 0.0657, 0.0656, 0.0653, 0.0651, 0.0649, 0.0648, 0.0640,\n",
            "        0.0637, 0.0636, 0.0635, 0.0631, 0.0631, 0.0630, 0.0629, 0.0628, 0.0628,\n",
            "        0.0626, 0.0625, 0.0621, 0.0621, 0.0621, 0.0619, 0.0619, 0.0618, 0.0618,\n",
            "        0.0617, 0.0617, 0.0616, 0.0615, 0.0615, 0.0613, 0.0612, 0.0612, 0.0611,\n",
            "        0.0610, 0.0609, 0.0609, 0.0608, 0.0606, 0.0605, 0.0605, 0.0604, 0.0604,\n",
            "        0.0604, 0.0603, 0.0600, 0.0600, 0.0599, 0.0599, 0.0598, 0.0597, 0.0597,\n",
            "        0.0597, 0.0595, 0.0595, 0.0595, 0.0594, 0.0594, 0.0594, 0.0593, 0.0592,\n",
            "        0.0592, 0.0592, 0.0591, 0.0591, 0.0591, 0.0591, 0.0591, 0.0590, 0.0588,\n",
            "        0.0588, 0.0586, 0.0586, 0.0586, 0.0585, 0.0585, 0.0585, 0.0584, 0.0584,\n",
            "        0.0583, 0.0583, 0.0583, 0.0582, 0.0581, 0.0581, 0.0581, 0.0581, 0.0580,\n",
            "        0.0580, 0.0579, 0.0579, 0.0579, 0.0579, 0.0579, 0.0578, 0.0577, 0.0577,\n",
            "        0.0576, 0.0575, 0.0575, 0.0574, 0.0574, 0.0574, 0.0574, 0.0574, 0.0574,\n",
            "        0.0573, 0.0573, 0.0572, 0.0572, 0.0572, 0.0571, 0.0571, 0.0571, 0.0570,\n",
            "        0.0570, 0.0570, 0.0569, 0.0569, 0.0568, 0.0568, 0.0568, 0.0568, 0.0568,\n",
            "        0.0567, 0.0566, 0.0566, 0.0566, 0.0565, 0.0565, 0.0565, 0.0565, 0.0565,\n",
            "        0.0565, 0.0565, 0.0564, 0.0564, 0.0564, 0.0564, 0.0564, 0.0563, 0.0563,\n",
            "        0.0563, 0.0563, 0.0562, 0.0561, 0.0561, 0.0561, 0.0561, 0.0561, 0.0561,\n",
            "        0.0561, 0.0561, 0.0560, 0.0559, 0.0559, 0.0559, 0.0559, 0.0558, 0.0557,\n",
            "        0.0557, 0.0556, 0.0556, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555,\n",
            "        0.0554, 0.0554, 0.0554, 0.0553, 0.0553, 0.0553, 0.0553, 0.0553, 0.0552,\n",
            "        0.0552, 0.0552, 0.0552, 0.0551, 0.0551, 0.0551, 0.0551, 0.0550, 0.0550,\n",
            "        0.0550, 0.0549, 0.0549, 0.0549, 0.0548, 0.0548, 0.0548, 0.0548, 0.0547,\n",
            "        0.0547, 0.0547, 0.0547, 0.0546, 0.0546, 0.0546, 0.0546, 0.0546, 0.0546,\n",
            "        0.0546, 0.0545, 0.0545, 0.0545, 0.0545, 0.0545, 0.0545, 0.0545, 0.0545,\n",
            "        0.0544, 0.0544, 0.0544, 0.0543, 0.0543, 0.0543, 0.0543, 0.0543, 0.0543,\n",
            "        0.0543, 0.0543, 0.0542, 0.0542, 0.0542, 0.0542, 0.0541, 0.0541, 0.0541,\n",
            "        0.0541, 0.0541, 0.0541, 0.0540, 0.0540, 0.0540, 0.0540, 0.0540, 0.0539,\n",
            "        0.0539, 0.0539, 0.0539, 0.0539, 0.0539, 0.0539, 0.0539, 0.0539, 0.0539,\n",
            "        0.0538, 0.0538, 0.0538, 0.0538, 0.0537, 0.0537, 0.0537, 0.0537, 0.0537,\n",
            "        0.0537, 0.0537, 0.0537, 0.0536, 0.0536, 0.0534, 0.0534, 0.0533, 0.0532,\n",
            "        0.0532, 0.0531, 0.0530, 0.0528, 0.0528, 0.0528, 0.0527, 0.0527, 0.0527,\n",
            "        0.0526, 0.0526, 0.0525, 0.0525, 0.0523, 0.0523, 0.0523, 0.0522, 0.0522,\n",
            "        0.0521, 0.0521, 0.0520], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2,\n",
            "        1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2,\n",
            "        1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1,\n",
            "        2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1,\n",
            "        1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2,\n",
            "        1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1,\n",
            "        1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2,\n",
            "        1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1,\n",
            "        2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1,\n",
            "        1, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1], device='cuda:0')}, {'boxes': tensor([[8.7285e+00, 5.1986e+00, 3.6431e+01, 3.3217e+01],\n",
            "        [1.3885e+01, 1.3105e-01, 4.1566e+01, 2.8128e+01],\n",
            "        [9.0601e+01, 1.7930e+02, 1.1834e+02, 2.0737e+02],\n",
            "        ...,\n",
            "        [6.5625e+01, 3.0584e+01, 1.1713e+02, 8.1774e+01],\n",
            "        [1.3585e+02, 1.7409e+02, 1.8812e+02, 2.2597e+02],\n",
            "        [9.4051e+01, 4.0992e+01, 1.4663e+02, 9.3086e+01]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0789, 0.0784, 0.0754, 0.0752, 0.0747, 0.0746, 0.0745, 0.0738, 0.0734,\n",
            "        0.0731, 0.0730, 0.0729, 0.0727, 0.0726, 0.0725, 0.0725, 0.0724, 0.0724,\n",
            "        0.0724, 0.0723, 0.0721, 0.0721, 0.0717, 0.0717, 0.0716, 0.0714, 0.0712,\n",
            "        0.0710, 0.0708, 0.0708, 0.0708, 0.0707, 0.0707, 0.0706, 0.0706, 0.0705,\n",
            "        0.0704, 0.0704, 0.0704, 0.0700, 0.0699, 0.0699, 0.0698, 0.0698, 0.0696,\n",
            "        0.0695, 0.0695, 0.0693, 0.0693, 0.0691, 0.0688, 0.0687, 0.0686, 0.0686,\n",
            "        0.0686, 0.0684, 0.0683, 0.0683, 0.0683, 0.0682, 0.0682, 0.0681, 0.0680,\n",
            "        0.0680, 0.0680, 0.0679, 0.0678, 0.0678, 0.0677, 0.0677, 0.0675, 0.0669,\n",
            "        0.0667, 0.0666, 0.0664, 0.0663, 0.0663, 0.0662, 0.0662, 0.0661, 0.0661,\n",
            "        0.0661, 0.0661, 0.0660, 0.0660, 0.0660, 0.0660, 0.0659, 0.0659, 0.0658,\n",
            "        0.0658, 0.0657, 0.0656, 0.0656, 0.0655, 0.0655, 0.0654, 0.0654, 0.0653,\n",
            "        0.0653, 0.0651, 0.0650, 0.0649, 0.0648, 0.0648, 0.0647, 0.0647, 0.0647,\n",
            "        0.0646, 0.0646, 0.0646, 0.0643, 0.0642, 0.0642, 0.0642, 0.0642, 0.0642,\n",
            "        0.0642, 0.0641, 0.0641, 0.0641, 0.0641, 0.0641, 0.0640, 0.0637, 0.0637,\n",
            "        0.0636, 0.0636, 0.0635, 0.0634, 0.0634, 0.0633, 0.0632, 0.0632, 0.0631,\n",
            "        0.0631, 0.0631, 0.0630, 0.0629, 0.0628, 0.0628, 0.0628, 0.0627, 0.0627,\n",
            "        0.0627, 0.0626, 0.0626, 0.0626, 0.0625, 0.0625, 0.0624, 0.0623, 0.0623,\n",
            "        0.0623, 0.0622, 0.0622, 0.0622, 0.0621, 0.0621, 0.0621, 0.0621, 0.0620,\n",
            "        0.0620, 0.0619, 0.0619, 0.0619, 0.0619, 0.0619, 0.0619, 0.0618, 0.0618,\n",
            "        0.0617, 0.0616, 0.0616, 0.0616, 0.0616, 0.0616, 0.0615, 0.0614, 0.0613,\n",
            "        0.0612, 0.0610, 0.0610, 0.0609, 0.0609, 0.0609, 0.0609, 0.0609, 0.0608,\n",
            "        0.0608, 0.0607, 0.0607, 0.0606, 0.0605, 0.0605, 0.0604, 0.0604, 0.0603,\n",
            "        0.0602, 0.0602, 0.0601, 0.0601, 0.0601, 0.0601, 0.0599, 0.0599, 0.0599,\n",
            "        0.0598, 0.0598, 0.0597, 0.0597, 0.0597, 0.0596, 0.0595, 0.0595, 0.0593,\n",
            "        0.0593, 0.0593, 0.0593, 0.0593, 0.0593, 0.0592, 0.0592, 0.0591, 0.0591,\n",
            "        0.0590, 0.0590, 0.0590, 0.0590, 0.0589, 0.0589, 0.0588, 0.0587, 0.0586,\n",
            "        0.0586, 0.0586, 0.0585, 0.0585, 0.0584, 0.0584, 0.0584, 0.0584, 0.0583,\n",
            "        0.0582, 0.0582, 0.0582, 0.0581, 0.0581, 0.0579, 0.0579, 0.0578, 0.0577,\n",
            "        0.0577, 0.0577, 0.0577, 0.0575, 0.0575, 0.0575, 0.0575, 0.0574, 0.0574,\n",
            "        0.0574, 0.0573, 0.0573, 0.0573, 0.0573, 0.0572, 0.0571, 0.0571, 0.0571,\n",
            "        0.0570, 0.0570, 0.0569, 0.0569, 0.0569, 0.0568, 0.0568, 0.0568, 0.0568,\n",
            "        0.0564, 0.0564, 0.0560, 0.0560, 0.0560, 0.0559, 0.0558, 0.0557, 0.0554,\n",
            "        0.0551, 0.0551, 0.0549, 0.0549, 0.0549, 0.0549, 0.0544, 0.0544, 0.0544,\n",
            "        0.0543, 0.0543, 0.0542], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1,\n",
            "        2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2,\n",
            "        2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2,\n",
            "        1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2,\n",
            "        1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1,\n",
            "        2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1,\n",
            "        2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1,\n",
            "        1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1,\n",
            "        2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2,\n",
            "        1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
            "        2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1], device='cuda:0')}]\n",
            "[{'boxes': tensor([[2.1827e+02, 5.1256e+01, 2.4626e+02, 7.9535e+01],\n",
            "        [4.4192e+01, 1.8952e+02, 7.2175e+01, 2.1781e+02],\n",
            "        [4.4167e+01, 1.9975e+02, 7.2163e+01, 2.2805e+02],\n",
            "        [4.4185e+01, 1.7929e+02, 7.2177e+01, 2.0759e+02],\n",
            "        [2.1823e+02, 4.1080e+01, 2.4624e+02, 6.9407e+01],\n",
            "        [4.4100e+01, 2.0997e+02, 7.2139e+01, 2.3830e+02],\n",
            "        [1.2604e+02, 1.9974e+02, 1.5408e+02, 2.2806e+02],\n",
            "        [1.2094e+02, 1.8951e+02, 1.4897e+02, 2.1783e+02],\n",
            "        [1.3114e+02, 2.0997e+02, 1.5919e+02, 2.3830e+02],\n",
            "        [8.2949e+00, 7.1764e+01, 3.6324e+01, 1.0009e+02],\n",
            "        [2.2310e+02, 6.1380e+01, 2.5123e+02, 8.9795e+01],\n",
            "        [4.4131e+01, 1.6907e+02, 7.2174e+01, 1.9741e+02],\n",
            "        [2.1827e+02, 5.1256e+01, 2.4626e+02, 7.9535e+01],\n",
            "        [8.1952e+00, 8.1970e+01, 3.6272e+01, 1.1033e+02],\n",
            "        [4.4192e+01, 1.8952e+02, 7.2175e+01, 2.1781e+02],\n",
            "        [1.3347e+01, 6.1525e+01, 4.1415e+01, 8.9896e+01],\n",
            "        [2.0796e+02, 4.0984e+01, 2.3603e+02, 6.9318e+01],\n",
            "        [1.2088e+02, 1.7930e+02, 1.4896e+02, 2.0768e+02],\n",
            "        [4.4167e+01, 1.9975e+02, 7.2163e+01, 2.2805e+02],\n",
            "        [4.4185e+01, 1.7929e+02, 7.2177e+01, 2.0759e+02],\n",
            "        [2.2751e+02, 5.1063e+01, 2.5600e+02, 7.9786e+01],\n",
            "        [3.8846e+01, 2.2009e+02, 6.7007e+01, 2.4849e+02],\n",
            "        [5.4179e+01, 1.9460e+02, 8.2295e+01, 2.2299e+02],\n",
            "        [1.3103e+02, 1.8953e+02, 1.5914e+02, 2.1794e+02],\n",
            "        [3.3855e+01, 2.0993e+02, 6.1956e+01, 2.3831e+02],\n",
            "        [1.3609e+02, 2.2009e+02, 1.6426e+02, 2.4849e+02],\n",
            "        [1.3615e+02, 1.9977e+02, 1.6426e+02, 2.2818e+02],\n",
            "        [5.4169e+01, 1.8437e+02, 8.2292e+01, 2.1277e+02],\n",
            "        [3.3857e+01, 1.9967e+02, 6.1957e+01, 2.2804e+02],\n",
            "        [4.4100e+01, 2.0997e+02, 7.2139e+01, 2.3830e+02],\n",
            "        [2.1823e+02, 4.1080e+01, 2.4624e+02, 6.9407e+01],\n",
            "        [1.2604e+02, 1.9974e+02, 1.5408e+02, 2.2806e+02],\n",
            "        [3.3857e+01, 1.8941e+02, 6.1957e+01, 2.1779e+02],\n",
            "        [1.3291e+01, 5.1287e+01, 4.1411e+01, 7.9695e+01],\n",
            "        [1.1570e+02, 1.9962e+02, 1.4383e+02, 2.2800e+02],\n",
            "        [2.1296e+02, 6.1352e+01, 2.4110e+02, 8.9736e+01],\n",
            "        [1.4124e+02, 2.0999e+02, 1.6937e+02, 2.3841e+02],\n",
            "        [2.0789e+02, 5.1123e+01, 2.3601e+02, 7.9491e+01],\n",
            "        [1.2094e+02, 1.8951e+02, 1.4897e+02, 2.1783e+02],\n",
            "        [5.4146e+01, 2.0481e+02, 8.2291e+01, 2.3322e+02],\n",
            "        [1.3114e+02, 2.0997e+02, 1.5919e+02, 2.3830e+02],\n",
            "        [2.1299e+02, 3.0848e+01, 2.4111e+02, 5.9269e+01],\n",
            "        [2.1813e+02, 6.1433e+01, 2.4621e+02, 8.9779e+01],\n",
            "        [8.0641e+00, 9.2184e+01, 3.6220e+01, 1.2061e+02],\n",
            "        [1.1058e+02, 1.7921e+02, 1.3871e+02, 2.0760e+02],\n",
            "        [8.2949e+00, 7.1764e+01, 3.6324e+01, 1.0009e+02],\n",
            "        [5.4150e+01, 1.7414e+02, 8.2293e+01, 2.0256e+02],\n",
            "        [4.4007e+01, 1.5882e+02, 7.2147e+01, 1.8725e+02],\n",
            "        [1.2078e+02, 2.0983e+02, 1.4894e+02, 2.3822e+02],\n",
            "        [1.8318e+01, 7.1690e+01, 4.6465e+01, 1.0010e+02],\n",
            "        [1.1053e+02, 1.6901e+02, 1.3868e+02, 1.9742e+02],\n",
            "        [1.1059e+02, 1.8940e+02, 1.3872e+02, 2.1779e+02],\n",
            "        [4.4131e+01, 1.6907e+02, 7.2174e+01, 1.9741e+02],\n",
            "        [1.3233e+01, 4.1027e+01, 4.1396e+01, 6.9460e+01],\n",
            "        [3.3843e+01, 1.7917e+02, 6.1956e+01, 2.0756e+02],\n",
            "        [9.5158e+01, 1.5362e+02, 1.2331e+02, 1.8203e+02],\n",
            "        [8.1952e+00, 8.1970e+01, 3.6272e+01, 1.1033e+02],\n",
            "        [1.0537e+02, 1.5877e+02, 1.3354e+02, 1.8721e+02],\n",
            "        [2.0796e+02, 4.0984e+01, 2.3603e+02, 6.9318e+01],\n",
            "        [8.4911e+01, 1.4848e+02, 1.1309e+02, 1.7691e+02],\n",
            "        [1.0031e+02, 2.7721e-02, 1.2847e+02, 2.8437e+01],\n",
            "        [4.8914e+01, 2.2006e+02, 7.7163e+01, 2.4853e+02],\n",
            "        [1.3347e+01, 6.1525e+01, 4.1415e+01, 8.9896e+01],\n",
            "        [1.3193e+01, 3.0779e+01, 4.1389e+01, 5.9240e+01],\n",
            "        [1.1576e+02, 1.7928e+02, 1.4385e+02, 2.0764e+02],\n",
            "        [2.2288e+02, 7.1574e+01, 2.5117e+02, 1.0011e+02],\n",
            "        [2.0269e+02, 3.0731e+01, 2.3087e+02, 5.9166e+01],\n",
            "        [3.8846e+01, 2.2009e+02, 6.7007e+01, 2.4849e+02],\n",
            "        [1.2073e+02, 1.6906e+02, 1.4892e+02, 1.9754e+02],\n",
            "        [1.3093e+02, 1.7928e+02, 1.5912e+02, 2.0776e+02],\n",
            "        [1.3609e+02, 2.2009e+02, 1.6426e+02, 2.4849e+02],\n",
            "        [5.4117e+01, 1.6390e+02, 8.2305e+01, 1.9237e+02],\n",
            "        [2.3412e+01, 6.1457e+01, 5.1604e+01, 8.9913e+01],\n",
            "        [2.2747e+02, 5.6153e+01, 2.5600e+02, 8.4861e+01],\n",
            "        [1.2577e+02, 2.1997e+02, 1.5402e+02, 2.4842e+02],\n",
            "        [3.3855e+01, 2.0993e+02, 6.1956e+01, 2.3831e+02],\n",
            "        [5.4179e+01, 1.9460e+02, 8.2295e+01, 2.2299e+02],\n",
            "        [1.8282e+01, 5.1234e+00, 4.6495e+01, 3.3581e+01],\n",
            "        [3.3857e+01, 1.9967e+02, 6.1957e+01, 2.2804e+02],\n",
            "        [1.3103e+02, 1.8953e+02, 1.5914e+02, 2.1794e+02],\n",
            "        [7.9517e+00, 1.0239e+02, 3.6189e+01, 1.3087e+02],\n",
            "        [2.0774e+02, 1.9968e+02, 2.3596e+02, 2.2814e+02],\n",
            "        [1.1570e+02, 1.9962e+02, 1.4383e+02, 2.2800e+02],\n",
            "        [2.0789e+02, 5.1123e+01, 2.3601e+02, 7.9491e+01],\n",
            "        [1.3615e+02, 1.9977e+02, 1.6426e+02, 2.2818e+02],\n",
            "        [5.4169e+01, 1.8437e+02, 8.2292e+01, 2.1277e+02],\n",
            "        [2.2747e+02, 4.0905e+01, 2.5600e+02, 6.9741e+01],\n",
            "        [1.1048e+02, 8.6792e-04, 1.3868e+02, 2.8438e+01],\n",
            "        [1.3155e+01, 2.0527e+01, 4.1383e+01, 4.9019e+01],\n",
            "        [1.4617e+02, 2.2010e+02, 1.7444e+02, 2.4860e+02],\n",
            "        [3.3857e+01, 1.8941e+02, 6.1957e+01, 2.1779e+02],\n",
            "        [1.3291e+01, 5.1287e+01, 4.1411e+01, 7.9695e+01],\n",
            "        [9.5101e+01, 1.4345e+02, 1.2331e+02, 1.7194e+02],\n",
            "        [3.3767e+01, 1.6891e+02, 6.1931e+01, 1.9735e+02],\n",
            "        [8.9938e+01, 5.0402e+00, 1.1818e+02, 3.3513e+01],\n",
            "        [8.4855e+01, 1.3831e+02, 1.1308e+02, 1.6680e+02],\n",
            "        [4.3866e+01, 1.4855e+02, 7.2103e+01, 1.7705e+02],\n",
            "        [1.4124e+02, 2.0999e+02, 1.6937e+02, 2.3841e+02],\n",
            "        [5.4146e+01, 2.0481e+02, 8.2291e+01, 2.3322e+02],\n",
            "        [2.3372e+01, 5.1224e+01, 5.1595e+01, 7.9709e+01],\n",
            "        [1.2592e+02, 1.7930e+02, 1.5404e+02, 2.0772e+02],\n",
            "        [8.0641e+00, 9.2184e+01, 3.6220e+01, 1.2061e+02],\n",
            "        [9.5088e+01, 1.6375e+02, 1.2331e+02, 1.9220e+02],\n",
            "        [1.2078e+02, 2.0983e+02, 1.4894e+02, 2.3822e+02],\n",
            "        [2.8528e+01, 2.2002e+02, 5.6792e+01, 2.4851e+02],\n",
            "        [1.8187e+01, 8.1875e+01, 4.6425e+01, 1.1035e+02],\n",
            "        [1.0013e+02, 1.0176e+01, 1.2839e+02, 3.8678e+01],\n",
            "        [1.9234e+02, 1.8943e+02, 2.2058e+02, 2.1791e+02],\n",
            "        [2.1299e+02, 3.0848e+01, 2.4111e+02, 5.9269e+01]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0639, 0.0637, 0.0632, 0.0627, 0.0613, 0.0612, 0.0609, 0.0606, 0.0602,\n",
            "        0.0599, 0.0598, 0.0595, 0.0584, 0.0583, 0.0581, 0.0578, 0.0578, 0.0578,\n",
            "        0.0577, 0.0572, 0.0570, 0.0567, 0.0565, 0.0564, 0.0564, 0.0564, 0.0562,\n",
            "        0.0561, 0.0561, 0.0560, 0.0557, 0.0556, 0.0556, 0.0556, 0.0556, 0.0556,\n",
            "        0.0555, 0.0555, 0.0553, 0.0553, 0.0551, 0.0550, 0.0550, 0.0550, 0.0549,\n",
            "        0.0548, 0.0547, 0.0547, 0.0546, 0.0545, 0.0544, 0.0542, 0.0542, 0.0541,\n",
            "        0.0541, 0.0539, 0.0535, 0.0532, 0.0530, 0.0530, 0.0529, 0.0528, 0.0528,\n",
            "        0.0527, 0.0527, 0.0527, 0.0525, 0.0523, 0.0522, 0.0520, 0.0520, 0.0519,\n",
            "        0.0519, 0.0518, 0.0518, 0.0517, 0.0516, 0.0516, 0.0515, 0.0514, 0.0514,\n",
            "        0.0514, 0.0513, 0.0512, 0.0512, 0.0512, 0.0512, 0.0512, 0.0511, 0.0511,\n",
            "        0.0511, 0.0509, 0.0509, 0.0508, 0.0507, 0.0507, 0.0507, 0.0507, 0.0506,\n",
            "        0.0506, 0.0506, 0.0505, 0.0505, 0.0504, 0.0504, 0.0503, 0.0502, 0.0501,\n",
            "        0.0501], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2,\n",
            "        2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2,\n",
            "        2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2,\n",
            "        2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 1], device='cuda:0')}, {'boxes': tensor([[7.4857e+01, 2.1508e+02, 1.0289e+02, 2.4340e+02],\n",
            "        [7.4856e+01, 2.0489e+02, 1.0290e+02, 2.3324e+02],\n",
            "        [1.1575e+02, 2.5660e+01, 1.4384e+02, 5.4037e+01],\n",
            "        [2.0283e+02, 2.5660e+01, 2.3089e+02, 5.4007e+01],\n",
            "        [8.4991e+01, 2.0996e+02, 1.1308e+02, 2.3834e+02],\n",
            "        [7.9917e+01, 1.9462e+02, 1.0799e+02, 2.2299e+02],\n",
            "        [2.1300e+02, 2.5630e+01, 2.4109e+02, 5.4000e+01],\n",
            "        [9.0125e+01, 1.8949e+02, 1.1822e+02, 2.1786e+02],\n",
            "        [1.9254e+02, 3.0734e+01, 2.2064e+02, 5.9094e+01],\n",
            "        [6.4565e+01, 2.0994e+02, 9.2663e+01, 2.3830e+02],\n",
            "        [6.9671e+01, 1.9461e+02, 9.7762e+01, 2.2299e+02],\n",
            "        [9.0101e+01, 1.9971e+02, 1.1821e+02, 2.2809e+02],\n",
            "        [7.9888e+01, 1.8437e+02, 1.0799e+02, 2.1275e+02],\n",
            "        [2.8711e+01, 1.8435e+02, 5.6799e+01, 2.1271e+02],\n",
            "        [7.4857e+01, 2.1508e+02, 1.0289e+02, 2.4340e+02],\n",
            "        [3.8951e+01, 1.8435e+02, 6.7027e+01, 2.1269e+02],\n",
            "        [4.4016e+01, 3.5897e+01, 7.2142e+01, 6.4304e+01],\n",
            "        [1.5148e+02, 5.1248e+00, 1.7963e+02, 3.3527e+01],\n",
            "        [1.0033e+02, 1.8947e+02, 1.2846e+02, 2.1787e+02],\n",
            "        [1.2589e+02, 2.5629e+01, 1.5403e+02, 5.4042e+01],\n",
            "        [1.8229e+02, 3.0746e+01, 2.1040e+02, 5.9129e+01],\n",
            "        [4.9169e+01, 1.8436e+02, 7.7256e+01, 2.1272e+02],\n",
            "        [1.1562e+02, 3.5828e+01, 1.4378e+02, 6.4245e+01],\n",
            "        [8.4833e+01, 2.2009e+02, 1.1303e+02, 2.4852e+02],\n",
            "        [1.8396e+01, 1.8945e+02, 4.6542e+01, 2.1786e+02],\n",
            "        [9.0087e+01, 1.7927e+02, 1.1822e+02, 2.0768e+02],\n",
            "        [5.9383e+01, 1.8946e+02, 8.7495e+01, 2.1784e+02],\n",
            "        [3.3805e+01, 1.7415e+02, 6.1915e+01, 2.0253e+02],\n",
            "        [6.4418e+01, 2.2004e+02, 9.2619e+01, 2.4845e+02],\n",
            "        [6.9649e+01, 1.8436e+02, 9.7761e+01, 2.1275e+02],\n",
            "        [7.4856e+01, 2.0489e+02, 1.0290e+02, 2.3324e+02],\n",
            "        [1.0025e+02, 1.9969e+02, 1.2842e+02, 2.2811e+02],\n",
            "        [2.1808e+02, 1.5450e+01, 2.4622e+02, 4.3890e+01],\n",
            "        [1.2082e+02, 1.5438e+01, 1.4896e+02, 4.3866e+01],\n",
            "        [1.4127e+02, 5.1179e+00, 1.6943e+02, 3.3534e+01],\n",
            "        [1.1051e+02, 1.8436e+02, 1.3867e+02, 2.1279e+02],\n",
            "        [1.4122e+02, 1.0756e+02, 1.6939e+02, 1.3601e+02],\n",
            "        [5.9327e+01, 1.9964e+02, 8.7495e+01, 2.2805e+02],\n",
            "        [4.4017e+01, 1.7416e+02, 7.2141e+01, 2.0256e+02],\n",
            "        [4.8978e+01, 4.6035e+01, 7.7192e+01, 7.4482e+01],\n",
            "        [1.8410e+01, 1.7924e+02, 4.6564e+01, 2.0766e+02],\n",
            "        [1.0032e+02, 1.7925e+02, 1.2847e+02, 2.0768e+02],\n",
            "        [7.9813e+01, 1.7414e+02, 1.0798e+02, 2.0257e+02],\n",
            "        [1.9254e+02, 2.0567e+01, 2.2067e+02, 4.8984e+01],\n",
            "        [1.3101e+02, 1.5384e+01, 1.5917e+02, 4.3824e+01],\n",
            "        [9.5094e+01, 2.0991e+02, 1.2329e+02, 2.3836e+02],\n",
            "        [1.7196e+02, 3.5843e+01, 2.0014e+02, 6.4275e+01],\n",
            "        [2.1285e+02, 1.4339e+02, 2.4107e+02, 1.7186e+02],\n",
            "        [3.3752e+01, 3.5840e+01, 6.1917e+01, 6.4265e+01],\n",
            "        [7.4344e+01, 2.2484e+02, 1.0277e+02, 2.5339e+02],\n",
            "        [1.1575e+02, 2.5660e+01, 1.4384e+02, 5.4037e+01],\n",
            "        [1.0540e+02, 3.0685e+01, 1.3359e+02, 5.9128e+01],\n",
            "        [2.0788e+02, 1.5435e+01, 2.3602e+02, 4.3868e+01],\n",
            "        [2.8555e+01, 1.9451e+02, 5.6746e+01, 2.2294e+02],\n",
            "        [2.0257e+02, 3.5760e+01, 2.3079e+02, 6.4201e+01],\n",
            "        [2.0793e+02, 2.5646e+01, 2.3600e+02, 5.3998e+01],\n",
            "        [8.4991e+01, 2.0996e+02, 1.1308e+02, 2.3834e+02],\n",
            "        [7.9917e+01, 1.9462e+02, 1.0799e+02, 2.2299e+02],\n",
            "        [5.9365e+01, 1.7925e+02, 8.7499e+01, 2.0766e+02],\n",
            "        [1.2577e+02, 3.5813e+01, 1.5399e+02, 6.4272e+01],\n",
            "        [1.4118e+02, 1.5339e+01, 1.6938e+02, 4.3798e+01],\n",
            "        [1.1041e+02, 1.9456e+02, 1.3863e+02, 2.2303e+02],\n",
            "        [1.9765e+02, 3.0725e+01, 2.2574e+02, 5.9085e+01],\n",
            "        [4.9030e+01, 1.9449e+02, 7.7214e+01, 2.2290e+02],\n",
            "        [5.4115e+01, 3.5894e+01, 8.2323e+01, 6.4381e+01],\n",
            "        [2.1280e+02, 1.5359e+02, 2.4105e+02, 1.8208e+02],\n",
            "        [2.2289e+02, 2.5528e+01, 2.5117e+02, 5.4065e+01],\n",
            "        [1.3601e+02, 1.1772e+02, 1.6424e+02, 1.4620e+02],\n",
            "        [6.4547e+01, 2.1502e+02, 9.2663e+01, 2.4339e+02],\n",
            "        [9.0119e+01, 1.9460e+02, 1.1822e+02, 2.2297e+02],\n",
            "        [1.3100e+02, 1.0753e+02, 1.5919e+02, 1.3597e+02],\n",
            "        [8.5001e+01, 1.8438e+02, 1.1310e+02, 2.1276e+02],\n",
            "        [6.9671e+01, 1.9461e+02, 9.7762e+01, 2.2299e+02],\n",
            "        [1.6158e+02, 5.1096e+00, 1.8981e+02, 3.3579e+01],\n",
            "        [1.8742e+02, 3.0742e+01, 2.1552e+02, 5.9109e+01],\n",
            "        [3.8719e+01, 4.5965e+01, 6.6960e+01, 7.4418e+01],\n",
            "        [6.4544e+01, 2.0483e+02, 9.2652e+01, 2.3320e+02],\n",
            "        [1.1053e+02, 1.5402e+01, 1.3873e+02, 4.3871e+01],\n",
            "        [3.8772e+01, 1.9447e+02, 6.6973e+01, 2.2289e+02],\n",
            "        [1.5136e+02, 1.5324e+01, 1.7959e+02, 4.3808e+01],\n",
            "        [2.8711e+01, 1.8435e+02, 5.6799e+01, 2.1271e+02],\n",
            "        [3.3686e+01, 1.6388e+02, 6.1883e+01, 1.9235e+02],\n",
            "        [1.8246e+01, 1.9964e+02, 4.6485e+01, 2.2811e+02],\n",
            "        [6.9566e+01, 1.7411e+02, 9.7743e+01, 2.0255e+02],\n",
            "        [1.5148e+02, 5.1248e+00, 1.7963e+02, 3.3527e+01],\n",
            "        [1.3602e+02, 2.5576e+01, 1.6424e+02, 5.4056e+01],\n",
            "        [5.9283e+01, 3.4778e-02, 8.7502e+01, 2.8500e+01],\n",
            "        [2.1809e+02, 2.0548e+01, 2.4621e+02, 4.8962e+01],\n",
            "        [4.3973e+01, 4.0963e+01, 7.2117e+01, 6.9366e+01],\n",
            "        [3.8951e+01, 1.8435e+02, 6.7027e+01, 2.1269e+02],\n",
            "        [2.1284e+02, 1.3316e+02, 2.4107e+02, 1.6166e+02],\n",
            "        [2.3463e+01, 1.6898e+02, 5.1666e+01, 1.9745e+02],\n",
            "        [1.8207e+02, 4.0875e+01, 2.1032e+02, 6.9349e+01],\n",
            "        [1.6166e+02, 4.0951e+01, 1.8988e+02, 6.9421e+01],\n",
            "        [1.1562e+02, 3.5828e+01, 1.4378e+02, 6.4245e+01],\n",
            "        [4.3929e+01, 2.5663e+01, 7.2140e+01, 5.4151e+01],\n",
            "        [1.2589e+02, 2.5629e+01, 1.5403e+02, 5.4042e+01],\n",
            "        [1.0033e+02, 1.8947e+02, 1.2846e+02, 2.1787e+02],\n",
            "        [1.7194e+02, 2.5617e+01, 2.0015e+02, 5.4082e+01],\n",
            "        [8.4833e+01, 2.2009e+02, 1.1303e+02, 2.4852e+02],\n",
            "        [1.2063e+02, 1.7924e+02, 1.4888e+02, 2.0775e+02]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0604, 0.0589, 0.0569, 0.0569, 0.0568, 0.0568, 0.0562, 0.0561, 0.0561,\n",
            "        0.0560, 0.0558, 0.0557, 0.0554, 0.0554, 0.0552, 0.0551, 0.0550, 0.0550,\n",
            "        0.0548, 0.0548, 0.0546, 0.0545, 0.0544, 0.0543, 0.0542, 0.0542, 0.0540,\n",
            "        0.0538, 0.0538, 0.0537, 0.0537, 0.0536, 0.0536, 0.0536, 0.0532, 0.0532,\n",
            "        0.0531, 0.0528, 0.0528, 0.0527, 0.0527, 0.0526, 0.0525, 0.0525, 0.0525,\n",
            "        0.0525, 0.0524, 0.0524, 0.0522, 0.0522, 0.0521, 0.0521, 0.0520, 0.0520,\n",
            "        0.0520, 0.0520, 0.0519, 0.0519, 0.0519, 0.0518, 0.0518, 0.0517, 0.0517,\n",
            "        0.0517, 0.0516, 0.0515, 0.0515, 0.0515, 0.0513, 0.0513, 0.0511, 0.0510,\n",
            "        0.0510, 0.0510, 0.0509, 0.0509, 0.0508, 0.0508, 0.0508, 0.0508, 0.0508,\n",
            "        0.0508, 0.0507, 0.0507, 0.0506, 0.0506, 0.0506, 0.0506, 0.0506, 0.0505,\n",
            "        0.0505, 0.0504, 0.0503, 0.0503, 0.0502, 0.0502, 0.0502, 0.0501, 0.0500,\n",
            "        0.0500, 0.0500], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 1,\n",
            "        1, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2,\n",
            "        1, 1, 2, 1, 2], device='cuda:0')}, {'boxes': tensor([[1.3886e+01, 5.1896e+00, 4.1546e+01, 3.3162e+01],\n",
            "        [9.5859e+01, 1.2037e-01, 1.2350e+02, 2.8080e+01],\n",
            "        [1.9065e+01, 1.3553e-01, 4.6705e+01, 2.8097e+01],\n",
            "        ...,\n",
            "        [7.4804e+01, 1.2204e+02, 1.2690e+02, 1.7354e+02],\n",
            "        [1.2699e+02, 1.1263e+02, 1.7841e+02, 1.6349e+02],\n",
            "        [1.6805e+02, 1.2246e+02, 2.1949e+02, 1.7324e+02]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0809, 0.0805, 0.0802, 0.0800, 0.0780, 0.0778, 0.0765, 0.0765, 0.0764,\n",
            "        0.0750, 0.0747, 0.0746, 0.0744, 0.0743, 0.0742, 0.0740, 0.0738, 0.0737,\n",
            "        0.0735, 0.0735, 0.0734, 0.0733, 0.0731, 0.0731, 0.0729, 0.0727, 0.0726,\n",
            "        0.0726, 0.0725, 0.0724, 0.0723, 0.0721, 0.0720, 0.0719, 0.0717, 0.0716,\n",
            "        0.0712, 0.0710, 0.0707, 0.0705, 0.0703, 0.0702, 0.0701, 0.0701, 0.0701,\n",
            "        0.0700, 0.0698, 0.0698, 0.0697, 0.0696, 0.0696, 0.0696, 0.0696, 0.0695,\n",
            "        0.0695, 0.0692, 0.0692, 0.0691, 0.0690, 0.0689, 0.0689, 0.0688, 0.0688,\n",
            "        0.0687, 0.0687, 0.0686, 0.0685, 0.0684, 0.0681, 0.0680, 0.0677, 0.0677,\n",
            "        0.0677, 0.0677, 0.0677, 0.0676, 0.0676, 0.0675, 0.0675, 0.0675, 0.0674,\n",
            "        0.0674, 0.0674, 0.0672, 0.0672, 0.0671, 0.0671, 0.0670, 0.0669, 0.0669,\n",
            "        0.0669, 0.0668, 0.0668, 0.0667, 0.0667, 0.0667, 0.0666, 0.0665, 0.0665,\n",
            "        0.0664, 0.0664, 0.0663, 0.0662, 0.0661, 0.0660, 0.0659, 0.0659, 0.0658,\n",
            "        0.0658, 0.0657, 0.0657, 0.0656, 0.0655, 0.0655, 0.0655, 0.0655, 0.0654,\n",
            "        0.0654, 0.0653, 0.0653, 0.0653, 0.0653, 0.0652, 0.0652, 0.0651, 0.0649,\n",
            "        0.0648, 0.0647, 0.0646, 0.0646, 0.0645, 0.0645, 0.0644, 0.0643, 0.0643,\n",
            "        0.0643, 0.0641, 0.0641, 0.0641, 0.0640, 0.0640, 0.0640, 0.0640, 0.0639,\n",
            "        0.0639, 0.0638, 0.0638, 0.0637, 0.0637, 0.0636, 0.0636, 0.0635, 0.0634,\n",
            "        0.0634, 0.0634, 0.0633, 0.0633, 0.0633, 0.0633, 0.0633, 0.0633, 0.0632,\n",
            "        0.0632, 0.0631, 0.0631, 0.0630, 0.0630, 0.0629, 0.0629, 0.0629, 0.0629,\n",
            "        0.0629, 0.0628, 0.0628, 0.0628, 0.0627, 0.0627, 0.0627, 0.0627, 0.0627,\n",
            "        0.0626, 0.0626, 0.0626, 0.0626, 0.0626, 0.0625, 0.0625, 0.0625, 0.0624,\n",
            "        0.0623, 0.0623, 0.0623, 0.0623, 0.0622, 0.0622, 0.0621, 0.0621, 0.0621,\n",
            "        0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0620, 0.0619, 0.0619, 0.0618,\n",
            "        0.0618, 0.0616, 0.0616, 0.0614, 0.0614, 0.0614, 0.0614, 0.0614, 0.0614,\n",
            "        0.0614, 0.0614, 0.0613, 0.0613, 0.0613, 0.0613, 0.0613, 0.0612, 0.0612,\n",
            "        0.0611, 0.0611, 0.0611, 0.0610, 0.0609, 0.0609, 0.0609, 0.0608, 0.0608,\n",
            "        0.0608, 0.0607, 0.0607, 0.0606, 0.0606, 0.0606, 0.0605, 0.0605, 0.0605,\n",
            "        0.0604, 0.0604, 0.0604, 0.0603, 0.0603, 0.0603, 0.0602, 0.0602, 0.0602,\n",
            "        0.0601, 0.0601, 0.0601, 0.0601, 0.0601, 0.0601, 0.0601, 0.0600, 0.0600,\n",
            "        0.0599, 0.0599, 0.0599, 0.0598, 0.0596, 0.0596, 0.0596, 0.0595, 0.0594,\n",
            "        0.0591, 0.0591, 0.0590, 0.0590, 0.0588, 0.0588, 0.0585, 0.0584, 0.0582,\n",
            "        0.0581, 0.0581, 0.0581, 0.0580, 0.0578, 0.0575, 0.0575, 0.0574, 0.0574,\n",
            "        0.0574, 0.0573, 0.0572, 0.0571, 0.0570, 0.0568, 0.0568, 0.0568, 0.0568,\n",
            "        0.0566, 0.0564, 0.0561], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
            "        1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1,\n",
            "        2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2,\n",
            "        2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2,\n",
            "        2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2,\n",
            "        1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1,\n",
            "        2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1,\n",
            "        1, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1,\n",
            "        2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2,\n",
            "        2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2], device='cuda:0')}, {'boxes': tensor([[ 54.5882,  82.0042,  82.4543, 110.1917],\n",
            "        [ 59.7172,  71.7789,  87.5814,  99.9683],\n",
            "        [ 44.3701,  87.1358,  72.2355, 115.3244],\n",
            "        ...,\n",
            "        [ 32.7781, 142.6856,  85.4355, 194.6463],\n",
            "        [167.3250,   0.3460, 219.3178,  52.0571],\n",
            "        [125.9834,  92.0499, 178.1257, 143.9490]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0684, 0.0684, 0.0679, 0.0674, 0.0667, 0.0661, 0.0660, 0.0658, 0.0656,\n",
            "        0.0655, 0.0655, 0.0655, 0.0654, 0.0653, 0.0652, 0.0648, 0.0648, 0.0648,\n",
            "        0.0644, 0.0644, 0.0643, 0.0640, 0.0640, 0.0638, 0.0638, 0.0636, 0.0634,\n",
            "        0.0634, 0.0633, 0.0631, 0.0631, 0.0630, 0.0630, 0.0630, 0.0628, 0.0627,\n",
            "        0.0625, 0.0624, 0.0624, 0.0623, 0.0622, 0.0622, 0.0622, 0.0621, 0.0621,\n",
            "        0.0621, 0.0620, 0.0620, 0.0619, 0.0618, 0.0618, 0.0617, 0.0617, 0.0617,\n",
            "        0.0615, 0.0615, 0.0614, 0.0614, 0.0612, 0.0612, 0.0611, 0.0609, 0.0609,\n",
            "        0.0609, 0.0608, 0.0608, 0.0608, 0.0608, 0.0608, 0.0607, 0.0606, 0.0606,\n",
            "        0.0605, 0.0604, 0.0603, 0.0603, 0.0602, 0.0602, 0.0602, 0.0602, 0.0601,\n",
            "        0.0600, 0.0599, 0.0599, 0.0599, 0.0599, 0.0598, 0.0598, 0.0597, 0.0597,\n",
            "        0.0597, 0.0597, 0.0597, 0.0596, 0.0596, 0.0596, 0.0595, 0.0595, 0.0595,\n",
            "        0.0594, 0.0593, 0.0593, 0.0592, 0.0592, 0.0592, 0.0592, 0.0592, 0.0592,\n",
            "        0.0591, 0.0591, 0.0591, 0.0591, 0.0591, 0.0590, 0.0589, 0.0588, 0.0588,\n",
            "        0.0587, 0.0587, 0.0587, 0.0586, 0.0586, 0.0586, 0.0586, 0.0585, 0.0585,\n",
            "        0.0585, 0.0585, 0.0584, 0.0584, 0.0583, 0.0583, 0.0583, 0.0583, 0.0582,\n",
            "        0.0582, 0.0581, 0.0581, 0.0581, 0.0581, 0.0580, 0.0580, 0.0580, 0.0580,\n",
            "        0.0579, 0.0579, 0.0579, 0.0579, 0.0579, 0.0579, 0.0578, 0.0578, 0.0577,\n",
            "        0.0576, 0.0576, 0.0576, 0.0575, 0.0575, 0.0574, 0.0574, 0.0573, 0.0572,\n",
            "        0.0572, 0.0572, 0.0572, 0.0572, 0.0572, 0.0572, 0.0571, 0.0571, 0.0571,\n",
            "        0.0571, 0.0571, 0.0571, 0.0571, 0.0571, 0.0571, 0.0570, 0.0570, 0.0569,\n",
            "        0.0567, 0.0566, 0.0566, 0.0565, 0.0565, 0.0565, 0.0565, 0.0565, 0.0564,\n",
            "        0.0564, 0.0564, 0.0564, 0.0563, 0.0563, 0.0562, 0.0562, 0.0562, 0.0561,\n",
            "        0.0561, 0.0561, 0.0561, 0.0560, 0.0560, 0.0560, 0.0560, 0.0559, 0.0559,\n",
            "        0.0559, 0.0559, 0.0559, 0.0558, 0.0558, 0.0558, 0.0558, 0.0557, 0.0557,\n",
            "        0.0557, 0.0557, 0.0557, 0.0557, 0.0557, 0.0556, 0.0556, 0.0556, 0.0556,\n",
            "        0.0556, 0.0556, 0.0555, 0.0555, 0.0555, 0.0555, 0.0554, 0.0554, 0.0553,\n",
            "        0.0553, 0.0553, 0.0553, 0.0553, 0.0553, 0.0552, 0.0552, 0.0552, 0.0552,\n",
            "        0.0551, 0.0551, 0.0551, 0.0551, 0.0551, 0.0551, 0.0551, 0.0551, 0.0551,\n",
            "        0.0550, 0.0550, 0.0550, 0.0550, 0.0550, 0.0550, 0.0550, 0.0550, 0.0549,\n",
            "        0.0549, 0.0549, 0.0549, 0.0549, 0.0548, 0.0548, 0.0548, 0.0548, 0.0547,\n",
            "        0.0547, 0.0546, 0.0544, 0.0544, 0.0544, 0.0543, 0.0543, 0.0541, 0.0541,\n",
            "        0.0539, 0.0537, 0.0536, 0.0536, 0.0534, 0.0534, 0.0533, 0.0533, 0.0531,\n",
            "        0.0531, 0.0530, 0.0529, 0.0529, 0.0528, 0.0528, 0.0527, 0.0527, 0.0527,\n",
            "        0.0526, 0.0525, 0.0525], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2,\n",
            "        2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
            "        2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2,\n",
            "        1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2,\n",
            "        1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1,\n",
            "        1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2,\n",
            "        1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2,\n",
            "        2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2,\n",
            "        2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1], device='cuda:0')}]\n",
            "[{'boxes': tensor([[1.0550e+02, 2.0529e+01, 1.3358e+02, 4.8891e+01],\n",
            "        [1.0550e+02, 1.0329e+01, 1.3359e+02, 3.8711e+01],\n",
            "        [1.0542e+02, 3.0741e+01, 1.3356e+02, 5.9141e+01],\n",
            "        [4.4013e+01, 4.6141e+01, 7.2137e+01, 7.4540e+01],\n",
            "        [9.5235e+01, 2.0482e+01, 1.2336e+02, 4.8872e+01],\n",
            "        [1.1559e+02, 2.0516e+01, 1.4376e+02, 4.8955e+01],\n",
            "        [2.1800e+02, 1.0256e+01, 2.4618e+02, 3.8707e+01],\n",
            "        [5.9335e+01, 2.1506e+02, 8.7504e+01, 2.4349e+02],\n",
            "        [3.3750e+01, 5.1196e+01, 6.1903e+01, 7.9609e+01],\n",
            "        [9.5182e+01, 3.0712e+01, 1.2335e+02, 5.9135e+01],\n",
            "        [9.5244e+01, 1.0267e+01, 1.2338e+02, 3.8669e+01],\n",
            "        [1.0027e+02, 4.0964e+01, 1.2844e+02, 6.9401e+01],\n",
            "        [1.0550e+02, 2.0529e+01, 1.3358e+02, 4.8891e+01],\n",
            "        [1.1556e+02, 3.0731e+01, 1.4376e+02, 5.9187e+01],\n",
            "        [4.3896e+01, 5.6275e+01, 7.2093e+01, 8.4710e+01],\n",
            "        [9.0022e+01, 5.1202e+01, 1.1820e+02, 7.9652e+01],\n",
            "        [5.4165e+01, 5.1206e+01, 8.2342e+01, 7.9639e+01],\n",
            "        [3.3740e+01, 4.0992e+01, 6.1910e+01, 6.9427e+01],\n",
            "        [1.1044e+02, 4.0961e+01, 1.3865e+02, 6.9425e+01],\n",
            "        [1.0023e+02, 5.1189e+01, 1.2843e+02, 7.9654e+01],\n",
            "        [7.9784e+01, 5.1209e+01, 1.0797e+02, 7.9663e+01],\n",
            "        [9.0038e+01, 4.0971e+01, 1.1823e+02, 6.9429e+01],\n",
            "        [1.0550e+02, 1.0329e+01, 1.3359e+02, 3.8711e+01],\n",
            "        [1.0542e+02, 3.0741e+01, 1.3356e+02, 5.9141e+01],\n",
            "        [1.1555e+02, 1.0307e+01, 1.4375e+02, 3.8787e+01],\n",
            "        [6.9456e+01, 2.1505e+02, 9.7687e+01, 2.4353e+02],\n",
            "        [4.3896e+01, 3.5926e+01, 7.2106e+01, 6.4414e+01],\n",
            "        [2.1790e+02, 2.0457e+01, 2.4615e+02, 4.8962e+01],\n",
            "        [6.4400e+01, 2.0485e+02, 9.2603e+01, 2.3332e+02],\n",
            "        [8.0532e+00, 1.3825e+02, 3.6272e+01, 1.6672e+02],\n",
            "        [1.1041e+02, 5.1189e+01, 1.3865e+02, 7.9681e+01],\n",
            "        [2.0777e+02, 1.0206e+01, 2.3598e+02, 3.8676e+01],\n",
            "        [4.9046e+01, 2.1500e+02, 7.7275e+01, 2.4348e+02],\n",
            "        [4.3990e+01, 5.1216e+01, 7.2122e+01, 7.9611e+01],\n",
            "        [6.9526e+01, 5.1195e+01, 9.7729e+01, 7.9663e+01],\n",
            "        [2.2300e+02, 5.6802e-02, 2.5127e+02, 2.8624e+01],\n",
            "        [9.5235e+01, 2.0482e+01, 1.2336e+02, 4.8872e+01],\n",
            "        [1.2066e+02, 7.1675e+01, 1.4890e+02, 1.0017e+02],\n",
            "        [1.0529e+02, 6.1408e+01, 1.3354e+02, 8.9905e+01],\n",
            "        [1.1554e+02, 6.1432e+01, 1.4379e+02, 8.9931e+01],\n",
            "        [9.5033e+01, 6.1380e+01, 1.2329e+02, 8.9873e+01]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0584, 0.0569, 0.0563, 0.0554, 0.0550, 0.0541, 0.0540, 0.0539, 0.0539,\n",
            "        0.0538, 0.0537, 0.0537, 0.0535, 0.0531, 0.0529, 0.0527, 0.0526, 0.0526,\n",
            "        0.0525, 0.0521, 0.0521, 0.0520, 0.0519, 0.0517, 0.0517, 0.0516, 0.0513,\n",
            "        0.0513, 0.0513, 0.0512, 0.0508, 0.0508, 0.0507, 0.0507, 0.0505, 0.0505,\n",
            "        0.0505, 0.0504, 0.0502, 0.0500, 0.0500], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2], device='cuda:0')}, {'boxes': tensor([[172.7753, 210.0467, 200.2929, 237.9262],\n",
            "        [167.5934, 215.0863, 195.1664, 242.9741],\n",
            "        [182.8496, 210.0142, 210.4623, 237.9731],\n",
            "        ...,\n",
            "        [127.0348,   0.5945, 178.6026,  51.7628],\n",
            "        [127.0663, 163.1967, 178.6039, 214.3679],\n",
            "        [157.9949, 154.0957, 209.1461, 204.9105]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0864, 0.0856, 0.0831, 0.0798, 0.0796, 0.0796, 0.0785, 0.0776, 0.0775,\n",
            "        0.0774, 0.0774, 0.0766, 0.0763, 0.0762, 0.0759, 0.0758, 0.0758, 0.0758,\n",
            "        0.0753, 0.0753, 0.0753, 0.0749, 0.0748, 0.0748, 0.0748, 0.0747, 0.0746,\n",
            "        0.0746, 0.0743, 0.0742, 0.0740, 0.0740, 0.0740, 0.0740, 0.0740, 0.0739,\n",
            "        0.0737, 0.0735, 0.0735, 0.0734, 0.0731, 0.0730, 0.0729, 0.0728, 0.0728,\n",
            "        0.0727, 0.0726, 0.0726, 0.0726, 0.0725, 0.0725, 0.0724, 0.0724, 0.0723,\n",
            "        0.0723, 0.0721, 0.0721, 0.0721, 0.0720, 0.0718, 0.0716, 0.0716, 0.0716,\n",
            "        0.0715, 0.0715, 0.0715, 0.0714, 0.0712, 0.0710, 0.0709, 0.0708, 0.0705,\n",
            "        0.0704, 0.0704, 0.0703, 0.0703, 0.0703, 0.0701, 0.0701, 0.0701, 0.0700,\n",
            "        0.0699, 0.0697, 0.0697, 0.0697, 0.0697, 0.0697, 0.0696, 0.0695, 0.0695,\n",
            "        0.0694, 0.0694, 0.0694, 0.0693, 0.0693, 0.0693, 0.0692, 0.0692, 0.0691,\n",
            "        0.0690, 0.0689, 0.0689, 0.0687, 0.0686, 0.0686, 0.0684, 0.0684, 0.0683,\n",
            "        0.0683, 0.0683, 0.0682, 0.0682, 0.0681, 0.0680, 0.0679, 0.0678, 0.0677,\n",
            "        0.0677, 0.0677, 0.0677, 0.0676, 0.0676, 0.0675, 0.0674, 0.0674, 0.0674,\n",
            "        0.0672, 0.0672, 0.0671, 0.0671, 0.0670, 0.0670, 0.0670, 0.0669, 0.0669,\n",
            "        0.0669, 0.0669, 0.0669, 0.0668, 0.0668, 0.0668, 0.0667, 0.0667, 0.0665,\n",
            "        0.0664, 0.0663, 0.0663, 0.0663, 0.0663, 0.0662, 0.0662, 0.0662, 0.0661,\n",
            "        0.0661, 0.0659, 0.0658, 0.0658, 0.0658, 0.0657, 0.0656, 0.0656, 0.0656,\n",
            "        0.0656, 0.0656, 0.0656, 0.0655, 0.0654, 0.0654, 0.0654, 0.0653, 0.0653,\n",
            "        0.0653, 0.0652, 0.0651, 0.0651, 0.0650, 0.0650, 0.0649, 0.0649, 0.0649,\n",
            "        0.0649, 0.0649, 0.0647, 0.0647, 0.0646, 0.0646, 0.0645, 0.0642, 0.0642,\n",
            "        0.0642, 0.0641, 0.0640, 0.0640, 0.0640, 0.0639, 0.0639, 0.0638, 0.0637,\n",
            "        0.0637, 0.0637, 0.0636, 0.0636, 0.0636, 0.0635, 0.0635, 0.0635, 0.0635,\n",
            "        0.0635, 0.0634, 0.0634, 0.0634, 0.0634, 0.0633, 0.0633, 0.0633, 0.0632,\n",
            "        0.0631, 0.0631, 0.0630, 0.0630, 0.0629, 0.0629, 0.0629, 0.0629, 0.0629,\n",
            "        0.0628, 0.0628, 0.0628, 0.0628, 0.0627, 0.0627, 0.0626, 0.0626, 0.0626,\n",
            "        0.0626, 0.0626, 0.0626, 0.0625, 0.0625, 0.0625, 0.0624, 0.0624, 0.0624,\n",
            "        0.0623, 0.0623, 0.0622, 0.0622, 0.0622, 0.0621, 0.0620, 0.0619, 0.0619,\n",
            "        0.0619, 0.0619, 0.0619, 0.0618, 0.0618, 0.0618, 0.0618, 0.0617, 0.0617,\n",
            "        0.0617, 0.0616, 0.0616, 0.0615, 0.0614, 0.0614, 0.0614, 0.0613, 0.0613,\n",
            "        0.0612, 0.0612, 0.0611, 0.0611, 0.0611, 0.0611, 0.0611, 0.0610, 0.0610,\n",
            "        0.0610, 0.0610, 0.0610, 0.0609, 0.0608, 0.0607, 0.0606, 0.0606, 0.0603,\n",
            "        0.0601, 0.0599, 0.0599, 0.0597, 0.0592, 0.0591, 0.0591, 0.0590, 0.0588,\n",
            "        0.0587, 0.0587, 0.0586], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2,\n",
            "        2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2,\n",
            "        1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1,\n",
            "        1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2,\n",
            "        1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1,\n",
            "        1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2,\n",
            "        2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2,\n",
            "        1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1,\n",
            "        1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1,\n",
            "        1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1,\n",
            "        1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2], device='cuda:0')}, {'boxes': tensor([[2.1348e+02, 1.1860e-01, 2.4124e+02, 2.8180e+01],\n",
            "        [1.3660e+02, 2.1001e+02, 1.6440e+02, 2.3813e+02],\n",
            "        [1.3148e+02, 1.9979e+02, 1.5928e+02, 2.2792e+02],\n",
            "        ...,\n",
            "        [9.5492e+01, 1.8330e+02, 1.4760e+02, 2.3476e+02],\n",
            "        [1.7737e+02, 1.2286e+02, 2.2928e+02, 1.7448e+02],\n",
            "        [1.7721e+02, 1.6347e+02, 2.2925e+02, 2.1509e+02]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0725, 0.0723, 0.0717, 0.0716, 0.0706, 0.0701, 0.0696, 0.0693, 0.0693,\n",
            "        0.0690, 0.0689, 0.0688, 0.0688, 0.0686, 0.0685, 0.0680, 0.0676, 0.0676,\n",
            "        0.0674, 0.0673, 0.0672, 0.0672, 0.0671, 0.0671, 0.0671, 0.0670, 0.0669,\n",
            "        0.0666, 0.0666, 0.0661, 0.0659, 0.0658, 0.0658, 0.0657, 0.0657, 0.0656,\n",
            "        0.0655, 0.0655, 0.0655, 0.0655, 0.0654, 0.0654, 0.0654, 0.0653, 0.0652,\n",
            "        0.0651, 0.0651, 0.0650, 0.0650, 0.0650, 0.0649, 0.0648, 0.0648, 0.0647,\n",
            "        0.0647, 0.0645, 0.0645, 0.0644, 0.0643, 0.0642, 0.0642, 0.0642, 0.0641,\n",
            "        0.0641, 0.0641, 0.0640, 0.0640, 0.0639, 0.0639, 0.0637, 0.0637, 0.0637,\n",
            "        0.0636, 0.0636, 0.0635, 0.0634, 0.0634, 0.0634, 0.0633, 0.0633, 0.0632,\n",
            "        0.0632, 0.0632, 0.0632, 0.0632, 0.0631, 0.0631, 0.0631, 0.0631, 0.0630,\n",
            "        0.0630, 0.0630, 0.0630, 0.0628, 0.0627, 0.0627, 0.0627, 0.0627, 0.0627,\n",
            "        0.0627, 0.0626, 0.0626, 0.0626, 0.0626, 0.0625, 0.0625, 0.0625, 0.0625,\n",
            "        0.0624, 0.0624, 0.0623, 0.0623, 0.0623, 0.0623, 0.0623, 0.0622, 0.0621,\n",
            "        0.0620, 0.0620, 0.0620, 0.0619, 0.0619, 0.0619, 0.0619, 0.0618, 0.0618,\n",
            "        0.0618, 0.0618, 0.0618, 0.0617, 0.0617, 0.0616, 0.0616, 0.0615, 0.0615,\n",
            "        0.0615, 0.0614, 0.0614, 0.0613, 0.0613, 0.0612, 0.0612, 0.0612, 0.0612,\n",
            "        0.0612, 0.0611, 0.0611, 0.0611, 0.0611, 0.0611, 0.0611, 0.0610, 0.0610,\n",
            "        0.0610, 0.0610, 0.0610, 0.0610, 0.0610, 0.0609, 0.0609, 0.0609, 0.0609,\n",
            "        0.0608, 0.0608, 0.0608, 0.0608, 0.0608, 0.0608, 0.0608, 0.0608, 0.0607,\n",
            "        0.0607, 0.0607, 0.0606, 0.0606, 0.0606, 0.0606, 0.0605, 0.0605, 0.0605,\n",
            "        0.0604, 0.0604, 0.0604, 0.0603, 0.0603, 0.0602, 0.0602, 0.0602, 0.0601,\n",
            "        0.0601, 0.0601, 0.0601, 0.0600, 0.0600, 0.0600, 0.0600, 0.0600, 0.0600,\n",
            "        0.0599, 0.0599, 0.0599, 0.0599, 0.0599, 0.0598, 0.0598, 0.0598, 0.0598,\n",
            "        0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0596, 0.0596, 0.0596,\n",
            "        0.0596, 0.0596, 0.0596, 0.0596, 0.0596, 0.0596, 0.0596, 0.0595, 0.0595,\n",
            "        0.0594, 0.0594, 0.0593, 0.0593, 0.0593, 0.0593, 0.0593, 0.0592, 0.0592,\n",
            "        0.0592, 0.0592, 0.0592, 0.0592, 0.0592, 0.0592, 0.0592, 0.0592, 0.0592,\n",
            "        0.0591, 0.0591, 0.0591, 0.0591, 0.0591, 0.0591, 0.0591, 0.0591, 0.0590,\n",
            "        0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0589, 0.0589, 0.0589, 0.0589,\n",
            "        0.0589, 0.0589, 0.0589, 0.0588, 0.0586, 0.0586, 0.0585, 0.0584, 0.0584,\n",
            "        0.0583, 0.0583, 0.0583, 0.0582, 0.0582, 0.0581, 0.0581, 0.0581, 0.0580,\n",
            "        0.0579, 0.0579, 0.0579, 0.0578, 0.0578, 0.0578, 0.0577, 0.0577, 0.0577,\n",
            "        0.0576, 0.0576, 0.0576, 0.0576, 0.0575, 0.0574, 0.0571, 0.0571, 0.0567,\n",
            "        0.0567, 0.0566, 0.0564], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,\n",
            "        2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1,\n",
            "        2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2,\n",
            "        2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2,\n",
            "        2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')}, {'boxes': tensor([[2.0302e+02, 8.1997e+01, 2.3093e+02, 1.1022e+02],\n",
            "        [2.0808e+02, 9.2209e+01, 2.3602e+02, 1.2045e+02],\n",
            "        [2.0300e+02, 7.1809e+01, 2.3094e+02, 1.0007e+02],\n",
            "        [2.1312e+02, 8.2011e+01, 2.4109e+02, 1.1030e+02],\n",
            "        [2.1819e+02, 9.7330e+01, 2.4621e+02, 1.2563e+02],\n",
            "        [1.9780e+02, 9.2181e+01, 2.2579e+02, 1.2046e+02],\n",
            "        [2.0302e+02, 8.1997e+01, 2.3093e+02, 1.1022e+02],\n",
            "        [9.0179e+01, 6.1479e+01, 1.1823e+02, 8.9808e+01],\n",
            "        [2.0795e+02, 1.0239e+02, 2.3600e+02, 1.3070e+02],\n",
            "        [1.9270e+02, 8.1962e+01, 2.2070e+02, 1.1024e+02],\n",
            "        [2.1304e+02, 7.1780e+01, 2.4107e+02, 1.0013e+02],\n",
            "        [2.0808e+02, 9.2209e+01, 2.3602e+02, 1.2045e+02],\n",
            "        [1.9767e+02, 1.0238e+02, 2.2576e+02, 1.3074e+02],\n",
            "        [2.0300e+02, 7.1809e+01, 2.3094e+02, 1.0007e+02],\n",
            "        [2.1312e+02, 8.2011e+01, 2.4109e+02, 1.1030e+02],\n",
            "        [7.9939e+01, 5.6352e+01, 1.0802e+02, 8.4707e+01],\n",
            "        [2.1819e+02, 9.7330e+01, 2.4621e+02, 1.2563e+02],\n",
            "        [9.0192e+01, 5.1325e+01, 1.1826e+02, 7.9710e+01],\n",
            "        [2.1803e+02, 1.0749e+02, 2.4617e+02, 1.3588e+02],\n",
            "        [1.9780e+02, 9.2181e+01, 2.2579e+02, 1.2046e+02],\n",
            "        [1.8746e+02, 9.2161e+01, 2.1554e+02, 1.2053e+02],\n",
            "        [1.9265e+02, 7.1744e+01, 2.2070e+02, 1.0008e+02],\n",
            "        [2.0795e+02, 6.1573e+01, 2.3603e+02, 8.9956e+01],\n",
            "        [1.3275e+01, 2.2015e+02, 4.1431e+01, 2.4854e+02],\n",
            "        [2.0795e+02, 1.0239e+02, 2.3600e+02, 1.3070e+02],\n",
            "        [9.0179e+01, 6.1479e+01, 1.1823e+02, 8.9808e+01],\n",
            "        [1.8735e+02, 1.0237e+02, 2.1550e+02, 1.3079e+02],\n",
            "        [1.0022e+02, 6.1472e+01, 1.2838e+02, 8.9906e+01],\n",
            "        [1.9270e+02, 8.1962e+01, 2.2070e+02, 1.1024e+02],\n",
            "        [8.9978e+01, 7.1633e+01, 1.1817e+02, 1.0005e+02],\n",
            "        [2.2300e+02, 8.7080e+01, 2.5120e+02, 1.1558e+02],\n",
            "        [2.1304e+02, 7.1780e+01, 2.4107e+02, 1.0013e+02],\n",
            "        [2.3489e+01, 1.0253e+01, 5.1651e+01, 3.8677e+01],\n",
            "        [2.8563e+01, 2.0498e+01, 5.6747e+01, 4.8944e+01],\n",
            "        [7.9768e+01, 6.6456e+01, 1.0796e+02, 9.4874e+01],\n",
            "        [1.9767e+02, 1.0238e+02, 2.2576e+02, 1.3074e+02],\n",
            "        [3.3686e+01, 1.0264e+01, 6.1867e+01, 3.8708e+01],\n",
            "        [2.1797e+02, 6.1508e+01, 2.4615e+02, 8.9980e+01],\n",
            "        [1.3247e+01, 2.1000e+02, 4.1423e+01, 2.3845e+02],\n",
            "        [1.0026e+02, 5.1283e+01, 1.2843e+02, 7.9745e+01],\n",
            "        [1.3213e+01, 5.1090e+00, 4.1409e+01, 3.3551e+01],\n",
            "        [1.4121e+02, 3.5874e+01, 1.6939e+02, 6.4326e+01],\n",
            "        [2.3373e+01, 2.2013e+02, 5.1601e+01, 2.4859e+02],\n",
            "        [2.2737e+02, 1.0221e+02, 2.5600e+02, 1.3099e+02],\n",
            "        [2.1803e+02, 1.0749e+02, 2.4617e+02, 1.3588e+02],\n",
            "        [7.9939e+01, 5.6352e+01, 1.0802e+02, 8.4707e+01],\n",
            "        [1.9768e+02, 6.1533e+01, 2.2581e+02, 8.9958e+01],\n",
            "        [1.7709e+02, 9.2136e+01, 2.0527e+02, 1.2058e+02],\n",
            "        [1.9746e+02, 1.1257e+02, 2.2569e+02, 1.4104e+02],\n",
            "        [2.8512e+01, 3.0715e+01, 5.6737e+01, 5.9187e+01],\n",
            "        [1.8746e+02, 9.2161e+01, 2.1554e+02, 1.2053e+02],\n",
            "        [1.8289e+01, 2.0436e+01, 4.6512e+01, 4.8901e+01],\n",
            "        [2.0770e+02, 1.1254e+02, 2.3593e+02, 1.4099e+02],\n",
            "        [1.0010e+02, 7.1660e+01, 1.2835e+02, 1.0015e+02],\n",
            "        [1.8228e+02, 8.1908e+01, 2.1043e+02, 1.1033e+02],\n",
            "        [9.0192e+01, 5.1325e+01, 1.1826e+02, 7.9710e+01],\n",
            "        [1.9265e+02, 7.1744e+01, 2.2070e+02, 1.0008e+02],\n",
            "        [1.2580e+02, 1.4337e+02, 1.5402e+02, 1.7183e+02],\n",
            "        [1.8328e+01, 1.6385e+02, 4.6525e+01, 1.9231e+02],\n",
            "        [1.3275e+01, 2.2015e+02, 4.1431e+01, 2.4854e+02],\n",
            "        [1.3097e+02, 3.5836e+01, 1.5918e+02, 6.4295e+01],\n",
            "        [1.8666e+02, 7.1262e+01, 2.3917e+02, 1.2333e+02],\n",
            "        [7.9839e+01, 4.6168e+01, 1.0802e+02, 7.4636e+01],\n",
            "        [8.0586e+00, 1.6895e+02, 3.6282e+01, 1.9742e+02],\n",
            "        [2.0795e+02, 6.1573e+01, 2.3603e+02, 8.9956e+01],\n",
            "        [1.3088e+02, 1.5360e+02, 1.5912e+02, 1.8208e+02],\n",
            "        [1.8719e+02, 1.1257e+02, 2.1545e+02, 1.4106e+02],\n",
            "        [3.8710e+01, 2.0490e+01, 6.6952e+01, 4.8988e+01],\n",
            "        [2.1797e+02, 5.1277e+01, 2.4619e+02, 7.9772e+01],\n",
            "        [1.7699e+02, 1.0232e+02, 2.0523e+02, 1.3079e+02],\n",
            "        [2.8501e+01, 1.6386e+02, 5.6731e+01, 1.9234e+02],\n",
            "        [1.8735e+02, 1.0237e+02, 2.1550e+02, 1.3079e+02],\n",
            "        [4.3860e+01, 5.1253e+00, 7.2096e+01, 3.3611e+01],\n",
            "        [2.3473e+01, 9.6281e-02, 5.1682e+01, 2.8568e+01],\n",
            "        [2.3393e+01, 2.0999e+02, 5.1619e+01, 2.3849e+02],\n",
            "        [1.4108e+02, 4.6026e+01, 1.6934e+02, 7.4514e+01],\n",
            "        [8.9978e+01, 7.1633e+01, 1.1817e+02, 1.0005e+02],\n",
            "        [1.0022e+02, 6.1472e+01, 1.2838e+02, 8.9906e+01],\n",
            "        [6.9506e+01, 5.6239e+01, 9.7737e+01, 8.4707e+01]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0662, 0.0649, 0.0632, 0.0630, 0.0622, 0.0617, 0.0604, 0.0599, 0.0598,\n",
            "        0.0598, 0.0595, 0.0593, 0.0575, 0.0574, 0.0573, 0.0569, 0.0567, 0.0566,\n",
            "        0.0565, 0.0565, 0.0563, 0.0563, 0.0559, 0.0557, 0.0550, 0.0549, 0.0547,\n",
            "        0.0547, 0.0547, 0.0543, 0.0542, 0.0541, 0.0537, 0.0533, 0.0532, 0.0529,\n",
            "        0.0528, 0.0528, 0.0527, 0.0525, 0.0524, 0.0524, 0.0523, 0.0523, 0.0522,\n",
            "        0.0521, 0.0520, 0.0518, 0.0518, 0.0518, 0.0517, 0.0516, 0.0515, 0.0515,\n",
            "        0.0514, 0.0514, 0.0513, 0.0513, 0.0512, 0.0510, 0.0510, 0.0509, 0.0508,\n",
            "        0.0508, 0.0508, 0.0508, 0.0506, 0.0506, 0.0505, 0.0505, 0.0504, 0.0504,\n",
            "        0.0503, 0.0503, 0.0503, 0.0502, 0.0502, 0.0501, 0.0501],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2,\n",
            "        1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2,\n",
            "        2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1,\n",
            "        2, 2, 2, 2, 1, 1, 2], device='cuda:0')}]\n",
            "[{'boxes': tensor([[136.0893,  61.4406, 164.2692,  89.8745],\n",
            "        [125.8298,  56.3132, 154.0407,  84.7689],\n",
            "        [146.2797,  61.4631, 174.4923,  89.9348],\n",
            "        [136.0793,  51.2838, 164.2842,  79.7677]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0530, 0.0515, 0.0512, 0.0507], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2], device='cuda:0')}, {'boxes': tensor([[202.9961,   5.1971, 230.9264,  33.4288],\n",
            "        [156.8337, 215.0857, 184.8224, 243.3655],\n",
            "        [207.9720,  15.3809, 235.9837,  43.6706],\n",
            "        ...,\n",
            "        [104.8854,  91.6722, 157.3534, 143.8210],\n",
            "        [135.3542, 102.1633, 187.8922, 154.4646],\n",
            "        [104.6567, 111.8117, 157.2628, 163.9386]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0651, 0.0624, 0.0624, 0.0616, 0.0613, 0.0613, 0.0612, 0.0612, 0.0611,\n",
            "        0.0604, 0.0601, 0.0601, 0.0599, 0.0598, 0.0597, 0.0596, 0.0595, 0.0594,\n",
            "        0.0594, 0.0593, 0.0591, 0.0591, 0.0591, 0.0590, 0.0589, 0.0588, 0.0588,\n",
            "        0.0586, 0.0586, 0.0582, 0.0582, 0.0582, 0.0581, 0.0581, 0.0580, 0.0577,\n",
            "        0.0575, 0.0574, 0.0573, 0.0573, 0.0572, 0.0570, 0.0569, 0.0566, 0.0565,\n",
            "        0.0564, 0.0564, 0.0563, 0.0563, 0.0563, 0.0563, 0.0562, 0.0562, 0.0562,\n",
            "        0.0561, 0.0560, 0.0559, 0.0559, 0.0559, 0.0559, 0.0559, 0.0559, 0.0558,\n",
            "        0.0558, 0.0558, 0.0557, 0.0557, 0.0557, 0.0557, 0.0556, 0.0556, 0.0555,\n",
            "        0.0555, 0.0554, 0.0554, 0.0553, 0.0553, 0.0552, 0.0551, 0.0551, 0.0551,\n",
            "        0.0550, 0.0550, 0.0549, 0.0548, 0.0548, 0.0547, 0.0547, 0.0546, 0.0546,\n",
            "        0.0546, 0.0546, 0.0546, 0.0546, 0.0545, 0.0545, 0.0545, 0.0545, 0.0545,\n",
            "        0.0542, 0.0542, 0.0542, 0.0542, 0.0541, 0.0541, 0.0541, 0.0541, 0.0540,\n",
            "        0.0540, 0.0540, 0.0540, 0.0539, 0.0539, 0.0539, 0.0538, 0.0538, 0.0538,\n",
            "        0.0538, 0.0538, 0.0538, 0.0537, 0.0537, 0.0537, 0.0536, 0.0536, 0.0535,\n",
            "        0.0535, 0.0535, 0.0534, 0.0533, 0.0533, 0.0533, 0.0533, 0.0533, 0.0532,\n",
            "        0.0532, 0.0531, 0.0530, 0.0530, 0.0530, 0.0529, 0.0529, 0.0529, 0.0529,\n",
            "        0.0529, 0.0528, 0.0528, 0.0528, 0.0528, 0.0528, 0.0527, 0.0527, 0.0527,\n",
            "        0.0527, 0.0526, 0.0525, 0.0525, 0.0525, 0.0525, 0.0525, 0.0525, 0.0524,\n",
            "        0.0523, 0.0523, 0.0523, 0.0523, 0.0523, 0.0522, 0.0522, 0.0521, 0.0521,\n",
            "        0.0521, 0.0521, 0.0521, 0.0520, 0.0520, 0.0520, 0.0520, 0.0520, 0.0520,\n",
            "        0.0519, 0.0519, 0.0519, 0.0519, 0.0519, 0.0519, 0.0519, 0.0518, 0.0518,\n",
            "        0.0517, 0.0517, 0.0517, 0.0517, 0.0516, 0.0516, 0.0515, 0.0515, 0.0515,\n",
            "        0.0515, 0.0515, 0.0514, 0.0514, 0.0514, 0.0514, 0.0514, 0.0514, 0.0513,\n",
            "        0.0513, 0.0513, 0.0513, 0.0512, 0.0512, 0.0512, 0.0512, 0.0512, 0.0512,\n",
            "        0.0512, 0.0512, 0.0512, 0.0512, 0.0511, 0.0511, 0.0511, 0.0511, 0.0511,\n",
            "        0.0511, 0.0511, 0.0511, 0.0511, 0.0511, 0.0510, 0.0510, 0.0510, 0.0510,\n",
            "        0.0510, 0.0509, 0.0509, 0.0509, 0.0509, 0.0509, 0.0509, 0.0509, 0.0509,\n",
            "        0.0509, 0.0509, 0.0508, 0.0507, 0.0507, 0.0507, 0.0507, 0.0507, 0.0506,\n",
            "        0.0506, 0.0506, 0.0506, 0.0506, 0.0505, 0.0505, 0.0505, 0.0504, 0.0502,\n",
            "        0.0502, 0.0501, 0.0501, 0.0500, 0.0500, 0.0500], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2,\n",
            "        1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2,\n",
            "        1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2,\n",
            "        1, 1, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1,\n",
            "        1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2,\n",
            "        2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 2,\n",
            "        2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1], device='cuda:0')}, {'boxes': tensor([[7.9979e+01, 1.5879e+02, 1.0802e+02, 1.8712e+02],\n",
            "        [9.0104e+01, 1.5878e+02, 1.1820e+02, 1.8717e+02],\n",
            "        [7.9828e+01, 1.6893e+02, 1.0796e+02, 1.9731e+02],\n",
            "        [1.0543e+02, 8.7074e+01, 1.3357e+02, 1.1547e+02],\n",
            "        [8.4989e+01, 1.4859e+02, 1.1311e+02, 1.7701e+02],\n",
            "        [9.0012e+01, 1.6893e+02, 1.1817e+02, 1.9733e+02],\n",
            "        [6.9629e+01, 1.6383e+02, 9.7766e+01, 1.9223e+02],\n",
            "        [1.1050e+02, 9.7286e+01, 1.3867e+02, 1.2570e+02],\n",
            "        [7.9979e+01, 1.5879e+02, 1.0802e+02, 1.8712e+02],\n",
            "        [1.0031e+02, 7.6856e+01, 1.2845e+02, 1.0528e+02],\n",
            "        [1.1562e+02, 8.7097e+01, 1.4378e+02, 1.1554e+02],\n",
            "        [7.4752e+01, 1.4854e+02, 1.0290e+02, 1.7697e+02],\n",
            "        [9.0086e+01, 1.6387e+02, 1.1819e+02, 1.9224e+02],\n",
            "        [8.4886e+01, 0.0000e+00, 1.1308e+02, 2.8412e+01],\n",
            "        [1.1048e+02, 7.6886e+01, 1.3867e+02, 1.0537e+02],\n",
            "        [1.7192e+02, 4.6660e-02, 2.0013e+02, 2.8506e+01],\n",
            "        [1.2070e+02, 9.7283e+01, 1.4889e+02, 1.2573e+02],\n",
            "        [7.9828e+01, 1.6893e+02, 1.0796e+02, 1.9731e+02],\n",
            "        [1.0017e+02, 1.6387e+02, 1.2839e+02, 1.9235e+02],\n",
            "        [1.0543e+02, 8.7074e+01, 1.3357e+02, 1.1547e+02],\n",
            "        [9.5084e+01, 8.6934e+01, 1.2331e+02, 1.1539e+02],\n",
            "        [9.0077e+01, 1.5369e+02, 1.1820e+02, 1.8211e+02],\n",
            "        [1.0019e+02, 9.7194e+01, 1.2843e+02, 1.2567e+02],\n",
            "        [6.9455e+01, 1.7401e+02, 9.7703e+01, 2.0249e+02],\n",
            "        [8.9981e+01, 7.6749e+01, 1.1820e+02, 1.0521e+02],\n",
            "        [4.8960e+01, 2.1502e+02, 7.7215e+01, 2.4352e+02]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0590, 0.0571, 0.0558, 0.0555, 0.0548, 0.0547, 0.0543, 0.0541, 0.0539,\n",
            "        0.0538, 0.0532, 0.0524, 0.0522, 0.0520, 0.0517, 0.0516, 0.0516, 0.0515,\n",
            "        0.0512, 0.0509, 0.0507, 0.0505, 0.0504, 0.0503, 0.0503, 0.0501],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2,\n",
            "        2, 2], device='cuda:0')}, {'boxes': tensor([[  8.2788, 220.1631,  36.3221, 248.4616],\n",
            "        [126.0746, 128.0675, 154.0932, 156.3727],\n",
            "        [100.4230, 107.5766, 128.4748, 135.9144],\n",
            "        [115.8097, 128.0341, 143.8563, 156.3549],\n",
            "        [110.6487, 117.8047, 138.7147, 146.1483],\n",
            "        [131.1208, 174.1221, 159.1981, 202.4741],\n",
            "        [136.1740, 128.0560, 164.2694, 156.4375],\n",
            "        [120.9141, 117.8419, 148.9717, 146.1886],\n",
            "        [100.4150,  97.3445, 128.4836, 125.6972],\n",
            "        [105.5115,  87.0977, 133.5843, 115.4456],\n",
            "        [100.3764, 117.7663, 128.4635, 146.1219],\n",
            "        [125.9525, 138.2423, 154.0454, 166.5965],\n",
            "        [  8.1134,   5.1619,  36.2464,  33.5586],\n",
            "        [110.6080, 107.5795, 138.6933, 135.9503],\n",
            "        [ 90.1586, 107.5507, 118.2458, 135.9084],\n",
            "        [131.1186, 117.8584, 159.2035, 146.2419],\n",
            "        [105.5123,  76.8755, 133.5945, 105.2410],\n",
            "        [115.7130, 138.2362, 143.8246, 166.6094],\n",
            "        [141.2712, 174.1200, 169.3894, 202.5114],\n",
            "        [110.5718,  97.3303, 138.6776, 125.7154],\n",
            "        [  8.2788, 220.1631,  36.3221, 248.4616],\n",
            "        [105.4653, 127.9773, 133.5903, 156.3593],\n",
            "        [ 90.1368,  97.3111, 118.2481, 125.6917],\n",
            "        [ 95.2721,  87.0711, 123.3694, 115.4381],\n",
            "        [115.6403,  81.9764, 143.7764, 110.3949],\n",
            "        [126.0746, 128.0675, 154.0932, 156.3727],\n",
            "        [ 18.3534, 220.1687,  46.5051, 248.5661],\n",
            "        [ 90.1020, 117.7404, 118.2236, 146.1242],\n",
            "        [  8.2074, 210.0847,  36.3144, 238.5081],\n",
            "        [131.0865, 163.9159, 159.2011, 192.3170],\n",
            "        [120.8165, 174.0731, 148.9587, 202.4713],\n",
            "        [  8.0472,  15.3720,  36.2414,  43.8170],\n",
            "        [136.0447, 138.2416, 164.2174, 166.6669],\n",
            "        [ 95.2474,  76.8267, 123.3614, 105.2079],\n",
            "        [130.9384, 184.2785, 159.1364, 212.7141],\n",
            "        [ 79.7857, 209.9453, 107.9674, 238.3876],\n",
            "        [100.4230, 107.5766, 128.4748, 135.9144],\n",
            "        [120.7997, 107.5761, 148.9353, 135.9897],\n",
            "        [115.8097, 128.0341, 143.8563, 156.3549],\n",
            "        [141.2415, 163.9407, 169.4027, 192.3952],\n",
            "        [115.6192,  71.7517, 143.7890, 100.2093],\n",
            "        [120.7958, 163.8688, 148.9535, 192.2912],\n",
            "        [105.5120, 117.7849, 133.5878, 146.1334],\n",
            "        [131.1208, 174.1221, 159.1981, 202.4741],\n",
            "        [115.7841, 117.8240, 143.8438, 146.1657],\n",
            "        [100.4150,  97.3445, 128.4836, 125.6972],\n",
            "        [136.1740, 128.0560, 164.2694, 156.4375],\n",
            "        [125.9525, 138.2423, 154.0454, 166.5965],\n",
            "        [105.4258,  66.6208, 133.5810,  95.0529],\n",
            "        [120.7208, 148.4644, 148.9088, 176.9062],\n",
            "        [105.5115,  87.0977, 133.5843, 115.4456],\n",
            "        [141.1976, 117.8232, 169.3782, 146.2856],\n",
            "        [120.6860,  92.1842, 148.8787, 120.6334],\n",
            "        [ 84.9410,  87.0286, 113.1095, 115.4561],\n",
            "        [  8.1134,   5.1619,  36.2464,  33.5586],\n",
            "        [ 79.8203, 112.6261, 107.9957, 141.0587],\n",
            "        [126.0294, 117.8554, 154.0939, 146.2157],\n",
            "        [105.3450, 138.1624, 133.5566, 166.6078],\n",
            "        [110.6080, 107.5795, 138.6933, 135.9503],\n",
            "        [ 49.0403,  76.7911,  77.2369, 105.2408],\n",
            "        [ 90.1586, 107.5507, 118.2458, 135.9084],\n",
            "        [ 94.6399,  91.6354, 147.0486, 143.6496],\n",
            "        [ 84.9265,  76.7907, 113.0985, 105.2212],\n",
            "        [ 95.2416, 117.7499, 123.3434, 146.1169],\n",
            "        [115.7130, 138.2362, 143.8246, 166.6094],\n",
            "        [130.9917, 107.5749, 159.1682, 136.0193],\n",
            "        [ 89.9413, 204.8344, 118.1553, 233.3190],\n",
            "        [104.7153, 101.9498, 157.2048, 154.0302],\n",
            "        [120.6808, 184.2477, 148.9138, 212.7159],\n",
            "        [ 59.2873,  71.6842,  87.4786, 100.1350],\n",
            "        [ 95.1760,  66.5862, 123.3422,  95.0202],\n",
            "        [141.2712, 174.1200, 169.3894, 202.5114],\n",
            "        [ 79.7961, 102.3739, 107.9939, 130.8238],\n",
            "        [141.0796, 184.2607, 169.3305, 212.7395],\n",
            "        [ 69.5233,  71.6829,  97.7190, 100.1391],\n",
            "        [105.5123,  76.8755, 133.5945, 105.2410],\n",
            "        [110.5718,  97.3303, 138.6776, 125.7154],\n",
            "        [ 95.0927, 127.8985, 123.3058, 156.3405],\n",
            "        [130.9079, 148.4643, 159.1239, 176.9278],\n",
            "        [ 43.9125,  66.5787,  72.1176,  95.0387],\n",
            "        [ 84.4409,  81.3259, 136.8635, 133.3968],\n",
            "        [  7.9861,  25.5761,  36.2440,  54.0748],\n",
            "        [ 38.7674,  76.7815,  66.9949, 105.2534],\n",
            "        [105.4653, 127.9773, 133.5903, 156.3593],\n",
            "        [ 74.6197,  81.8870, 102.8363, 110.3534],\n",
            "        [ 84.8954,  66.5704, 113.0846,  95.0215],\n",
            "        [104.6482,  81.8076, 157.1456, 134.0869],\n",
            "        [ 94.5456,  71.4475, 147.0038, 123.6866],\n",
            "        [ 79.6044, 220.0530, 107.9140, 248.5676],\n",
            "        [ 79.7839, 199.7386, 107.9894, 228.2160],\n",
            "        [110.4134, 148.4185, 138.6587, 176.8989],\n",
            "        [ 59.2240,  81.8733,  87.4563, 110.3510],\n",
            "        [ 95.2721,  87.0711, 123.3694, 115.4381],\n",
            "        [ 90.1368,  97.3111, 118.2481, 125.6917],\n",
            "        [222.9039, 107.4906, 251.2084, 136.0584],\n",
            "        [115.6330,  87.0838, 143.7701, 115.4923],\n",
            "        [ 89.8743, 215.0080, 118.1421, 243.5149],\n",
            "        [114.5132, 112.2901, 167.2324, 164.6009],\n",
            "        [ 79.7262, 122.8189, 107.9516, 151.2844],\n",
            "        [222.8953, 117.7238, 251.2061, 146.2940]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0608, 0.0601, 0.0584, 0.0584, 0.0575, 0.0573, 0.0573, 0.0573, 0.0573,\n",
            "        0.0571, 0.0569, 0.0569, 0.0567, 0.0565, 0.0564, 0.0561, 0.0560, 0.0560,\n",
            "        0.0559, 0.0557, 0.0555, 0.0551, 0.0551, 0.0551, 0.0550, 0.0548, 0.0548,\n",
            "        0.0546, 0.0545, 0.0542, 0.0542, 0.0541, 0.0541, 0.0537, 0.0535, 0.0535,\n",
            "        0.0534, 0.0534, 0.0534, 0.0530, 0.0529, 0.0528, 0.0526, 0.0524, 0.0524,\n",
            "        0.0524, 0.0524, 0.0524, 0.0523, 0.0523, 0.0523, 0.0522, 0.0521, 0.0521,\n",
            "        0.0519, 0.0519, 0.0518, 0.0517, 0.0517, 0.0517, 0.0516, 0.0516, 0.0516,\n",
            "        0.0515, 0.0515, 0.0514, 0.0514, 0.0514, 0.0513, 0.0513, 0.0513, 0.0513,\n",
            "        0.0512, 0.0512, 0.0512, 0.0512, 0.0511, 0.0510, 0.0510, 0.0509, 0.0508,\n",
            "        0.0508, 0.0508, 0.0507, 0.0507, 0.0506, 0.0506, 0.0505, 0.0505, 0.0505,\n",
            "        0.0505, 0.0505, 0.0505, 0.0504, 0.0504, 0.0504, 0.0503, 0.0503, 0.0500,\n",
            "        0.0500], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
            "        2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1,\n",
            "        2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1,\n",
            "        2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 1,\n",
            "        2, 1, 2, 2], device='cuda:0')}]\n",
            "[{'boxes': tensor([[156.8039,  81.9786, 184.8155, 110.2825],\n",
            "        [120.9588, 199.7451, 148.9715, 228.0524],\n",
            "        [110.7169, 199.7320, 138.7414, 228.0445],\n",
            "        [120.9217, 209.9589, 148.9641, 238.2853],\n",
            "        [202.8593, 112.6773, 230.8889, 140.9874],\n",
            "        [115.8421, 189.5198, 143.8641, 217.8388],\n",
            "        [146.5421,  76.8501, 174.5868, 105.1763],\n",
            "        [131.1326, 199.7383, 159.1844, 228.0798],\n",
            "        [156.8001,  71.7754, 184.8275, 100.1031],\n",
            "        [166.9383,  81.9749, 195.0028, 110.3313],\n",
            "        [156.7190,  92.1867, 184.7870, 120.5317],\n",
            "        [110.6647, 209.9396, 138.7288, 238.2786],\n",
            "        [126.0418, 189.5199, 154.0829, 217.8632],\n",
            "        [213.0368, 112.6967, 241.0971, 141.0427],\n",
            "        [131.1191, 209.9546, 159.1859, 238.2993],\n",
            "        [105.5710, 189.4949, 133.6196, 217.8299],\n",
            "        [146.4939,  87.0549, 174.5697, 115.4038],\n",
            "        [202.8614, 102.4951, 230.9036, 130.8373],\n",
            "        [136.2493, 153.6453, 164.3177, 181.9991],\n",
            "        [192.5994, 107.5578, 220.6593, 135.8953],\n",
            "        [166.9015,  92.1888, 194.9990, 120.5601],\n",
            "        [100.4093, 199.6968, 128.4906, 228.0533],\n",
            "        [125.9891, 158.7466, 154.0748, 187.1125],\n",
            "        [141.3251, 163.8688, 169.4208, 192.2395],\n",
            "        [146.4460, 153.6526, 174.5381, 182.0287],\n",
            "        [141.3548, 143.4221, 169.4370, 171.7918],\n",
            "        [166.9184,  71.7745, 195.0116, 100.1680],\n",
            "        [110.6458, 179.2561, 138.7248, 207.6194],\n",
            "        [120.8832, 179.2661, 148.9630, 207.6342],\n",
            "        [146.4883,  66.6388, 174.5719,  95.0068],\n",
            "        [141.3251, 209.9538, 169.4251, 238.3272],\n",
            "        [156.6551, 102.4176, 184.7758, 130.8111],\n",
            "        [115.7408, 158.7517, 143.8350, 187.1277],\n",
            "        [126.0083, 148.5305, 154.0934, 176.9030],\n",
            "        [136.1937, 189.4967, 164.2923, 217.8857],\n",
            "        [100.3772, 179.2375, 128.4775, 207.6154],\n",
            "        [131.0738, 168.9853, 159.1828, 197.3683],\n",
            "        [151.5249, 163.8743, 179.6453, 192.2694],\n",
            "        [105.4842, 168.9957, 133.5874, 197.3788],\n",
            "        [192.5101, 117.7342, 220.6271, 146.1105],\n",
            "        [212.9974, 102.4918, 241.0950, 130.8913],\n",
            "        [131.0849, 179.2545, 159.1855, 207.6403],\n",
            "        [ 95.2578, 189.4600, 123.3662, 217.8426],\n",
            "        [120.8362, 168.9874, 148.9455, 197.3733],\n",
            "        [141.3027, 199.7271, 169.4100, 228.1154],\n",
            "        [156.8039,  81.9786, 184.8155, 110.2825],\n",
            "        [100.3453, 209.8950, 128.4768, 238.2866],\n",
            "        [212.9278, 122.8620, 241.0646, 151.2505],\n",
            "        [146.4136,  97.2727, 174.5481, 125.6732],\n",
            "        [120.9588, 199.7451, 148.9715, 228.0524],\n",
            "        [120.7364, 220.0695, 148.9193, 248.4832],\n",
            "        [166.8791, 102.4171, 195.0102, 130.8189],\n",
            "        [141.2809, 174.0974, 169.4095, 202.4968],\n",
            "        [105.4934, 158.7629, 133.5989, 187.1519],\n",
            "        [146.4348, 133.1753, 174.5504, 161.5730],\n",
            "        [151.5022, 143.4105, 179.6352, 171.8247],\n",
            "        [ 95.2213, 168.9838, 123.3476, 197.3822],\n",
            "        [151.5286, 215.0459, 179.6661, 243.4459],\n",
            "        [182.2856, 107.5262, 210.4032, 135.9125],\n",
            "        [156.6376, 112.6645, 184.7764, 141.0748],\n",
            "        [110.7169, 199.7320, 138.7414, 228.0445],\n",
            "        [202.6932, 122.8236, 230.8409, 151.2161],\n",
            "        [130.9723, 220.0677, 159.1606, 248.4875],\n",
            "        [120.9217, 209.9589, 148.9641, 238.2853],\n",
            "        [131.0097,   5.1123, 159.1624,  33.5118],\n",
            "        [202.8593, 112.6773, 230.8889, 140.9874],\n",
            "        [166.8703, 112.6562, 195.0133, 141.0700],\n",
            "        [156.6296, 122.9101, 184.7725, 151.3222],\n",
            "        [151.4795, 174.0836, 179.6354, 202.5047],\n",
            "        [115.8421, 189.5198, 143.8641, 217.8388],\n",
            "        [177.1085,  97.3012, 205.2518, 125.7114],\n",
            "        [115.6285, 163.5676, 167.7947, 215.4094],\n",
            "        [151.5218, 204.8408, 179.6557, 233.2525],\n",
            "        [115.7266, 148.5285, 143.8504, 176.9352],\n",
            "        [141.2090, 220.0684, 169.4054, 248.4951],\n",
            "        [110.4585, 220.0391, 138.6774, 248.4744],\n",
            "        [192.5370,  97.3502, 220.6510, 125.7467],\n",
            "        [156.5887, 133.1533, 184.7473, 161.5848],\n",
            "        [156.7190,  92.1867, 184.7870, 120.5317],\n",
            "        [161.7325, 215.0405, 189.8957, 243.4644],\n",
            "        [146.5274,  81.9522, 174.5805, 110.2832],\n",
            "        [ 95.2178, 158.7565, 123.3569, 187.1715],\n",
            "        [110.6647, 209.9396, 138.7288, 238.2786],\n",
            "        [131.1326, 199.7383, 159.1844, 228.0798],\n",
            "        [182.2211, 117.7276, 210.3788, 146.1440],\n",
            "        [166.9383,  81.9749, 195.0028, 110.3313],\n",
            "        [105.2745, 173.5141, 157.5437, 225.3377],\n",
            "        [ 90.0721, 179.1993, 118.2288, 207.6220],\n",
            "        [151.6820,  71.7646, 179.7115, 100.0884],\n",
            "        [ 90.0675, 199.6604, 118.2324, 228.0856],\n",
            "        [125.5614, 173.6660, 177.8892, 225.5593],\n",
            "        [131.0838, 138.2895, 159.2133, 166.7006],\n",
            "        [156.5729, 153.6502, 184.7395, 182.0926],\n",
            "        [126.0418, 189.5199, 154.0829, 217.8632],\n",
            "        [146.3662, 107.5131, 174.5365, 135.9467],\n",
            "        [146.3974, 122.9072, 174.5525, 151.3318],\n",
            "        [213.0368, 112.6967, 241.0971, 141.0427],\n",
            "        [130.9657,  30.7574, 159.1471,  59.2075],\n",
            "        [131.1191, 209.9546, 159.1859, 238.2993],\n",
            "        [161.6873, 168.9808, 189.8662, 197.4258],\n",
            "        [146.3554, 184.3326, 174.5183, 212.7666],\n",
            "        [125.6868, 153.3876, 177.9294, 205.3282],\n",
            "        [166.8175, 122.8772, 194.9922, 151.3135],\n",
            "        [136.1566,  76.7747, 164.3251, 105.2022],\n",
            "        [105.5710, 189.4949, 133.6196, 217.8299],\n",
            "        [177.0354,  87.0793, 205.2073, 115.5185],\n",
            "        [130.9817,  20.5167, 159.1601,  48.9639],\n",
            "        [161.8803,  71.7802, 189.9278, 100.1312],\n",
            "        [136.1298,  66.5544, 164.3087,  94.9883],\n",
            "        [161.7250, 204.8333, 189.8869, 233.2674],\n",
            "        [136.2493, 153.6453, 164.3177, 181.9991],\n",
            "        [141.1539,   5.1288, 169.3582,  33.5752],\n",
            "        [202.8614, 102.4951, 230.9036, 130.8373],\n",
            "        [120.7467,   5.0698, 148.9321,  33.4949],\n",
            "        [105.4366, 153.3033, 157.6148, 205.2338],\n",
            "        [130.9290,  40.9764, 159.1328,  69.4397],\n",
            "        [135.6665, 163.6093, 188.0315, 215.6429],\n",
            "        [192.5994, 107.5578, 220.6593, 135.8953],\n",
            "        [166.9015,  92.1888, 194.9990, 120.5601],\n",
            "        [151.4769, 194.5833, 179.6442, 223.0242],\n",
            "        [136.1331,  87.0017, 164.3179, 115.4452],\n",
            "        [100.4093, 199.6968, 128.4906, 228.0533],\n",
            "        [171.9401, 209.9324, 200.1240, 238.3795],\n",
            "        [114.9330, 183.3346, 167.5862, 235.2858],\n",
            "        [141.2102,  56.3804, 169.3969,  84.8365],\n",
            "        [156.6564,  61.5383, 184.7972,  89.9735],\n",
            "        [ 95.1040, 163.3364, 147.3452, 215.2582],\n",
            "        [141.3251, 163.8688, 169.4208, 192.2395],\n",
            "        [125.9891, 158.7466, 154.0748, 187.1125],\n",
            "        [161.6511, 179.1946, 189.8602, 207.6618],\n",
            "        [ 84.9146, 168.9384, 113.1011, 197.3848],\n",
            "        [146.4527,  92.1608, 174.5583, 120.5354],\n",
            "        [115.5846, 143.1048, 167.8111, 195.0970],\n",
            "        [146.4460, 153.6526, 174.5381, 182.0287],\n",
            "        [222.9140, 117.7323, 251.1793, 146.2782],\n",
            "        [135.5989, 143.1709, 188.0047, 195.2738],\n",
            "        [141.3548, 143.4221, 169.4370, 171.7918],\n",
            "        [ 90.0023, 209.8634, 118.2173, 238.3271],\n",
            "        [156.0762,  81.6223, 208.4895, 133.6245],\n",
            "        [ 84.9014, 189.4130, 113.1051, 217.8719],\n",
            "        [110.6458, 179.2561, 138.7248, 207.6194],\n",
            "        [105.4306, 148.5211, 133.6025, 176.9713],\n",
            "        [120.8832, 179.2661, 148.9630, 207.6342],\n",
            "        [ 84.9054, 158.7156, 113.1000, 187.1700],\n",
            "        [141.3513,  71.7166, 169.4529, 100.0882],\n",
            "        [141.3251, 209.9538, 169.4251, 238.3272],\n",
            "        [156.6551, 102.4176, 184.7758, 130.8111],\n",
            "        [161.6750, 194.5762, 189.8737, 223.0410],\n",
            "        [115.7408, 158.7517, 143.8350, 187.1277],\n",
            "        [192.5101, 117.7342, 220.6271, 146.1105],\n",
            "        [166.2165,  91.6916, 218.7099, 143.6722],\n",
            "        [131.0738, 168.9853, 159.1828, 197.3683],\n",
            "        [120.7361,  30.6943, 148.9396,  59.1523],\n",
            "        [100.3772, 179.2375, 128.4775, 207.6154],\n",
            "        [130.9029,  51.1782, 159.1340,  79.6560],\n",
            "        [136.1316, 128.0214, 164.3177, 156.4764],\n",
            "        [126.0083, 148.5305, 154.0934, 176.9030],\n",
            "        [145.8777,  71.3663, 198.2814, 123.4238],\n",
            "        [207.8355,  92.2504, 235.9975, 120.7056],\n",
            "        [136.1937, 189.4967, 164.2923, 217.8857],\n",
            "        [105.4842, 168.9957, 133.5874, 197.3788],\n",
            "        [151.5249, 163.8743, 179.6453, 192.2694],\n",
            "        [125.6218, 132.8636, 177.9532, 184.9724],\n",
            "        [145.8180,  91.6171, 198.3256, 143.7177],\n",
            "        [182.1317, 209.9197, 210.3505, 238.3949],\n",
            "        [212.9278, 122.8620, 241.0646, 151.2505],\n",
            "        [120.7364, 220.0695, 148.9193, 248.4832],\n",
            "        [222.9556,   5.0947, 251.2271,  33.6265],\n",
            "        [176.9518,  76.8499, 205.1726, 105.3445],\n",
            "        [171.9050, 199.7023, 200.1118, 228.1747],\n",
            "        [120.8362, 168.9874, 148.9455, 197.3733],\n",
            "        [100.3453, 209.8950, 128.4768, 238.2866],\n",
            "        [135.1023, 183.4153, 187.8980, 235.5505],\n",
            "        [ 95.2578, 189.4600, 123.3662, 217.8426],\n",
            "        [131.0849, 179.2545, 159.1855, 207.6403],\n",
            "        [136.0689,  97.2227, 164.2948, 125.7006],\n",
            "        [145.5355, 173.6693, 198.1278, 225.8620],\n",
            "        [141.3027, 199.7271, 169.4100, 228.1154],\n",
            "        [155.8297, 101.8260, 208.4615, 153.9581],\n",
            "        [212.9974, 102.4918, 241.0950, 130.8913],\n",
            "        [120.7302,  20.4628, 148.9414,  48.9312],\n",
            "        [166.8791, 102.4171, 195.0102, 130.8189],\n",
            "        [171.8232, 220.0570, 200.0955, 248.5542],\n",
            "        [145.5186, 153.4169, 198.0753, 205.6813],\n",
            "        [141.0992,  15.3776, 169.3426,  43.8756],\n",
            "        [141.2809, 174.0974, 169.4095, 202.4968],\n",
            "        [100.1307, 219.9926, 128.4210, 248.4862],\n",
            "        [202.6932, 122.8236, 230.8409, 151.2161],\n",
            "        [ 95.2213, 168.9838, 123.3476, 197.3822],\n",
            "        [151.5022, 143.4105, 179.6352, 171.8247],\n",
            "        [105.4934, 158.7629, 133.5989, 187.1519],\n",
            "        [146.4348, 133.1753, 174.5504, 161.5730],\n",
            "        [166.8039,  61.5406, 195.0039,  90.0351],\n",
            "        [161.5810, 143.3728, 189.8253, 171.8768],\n",
            "        [151.5286, 215.0459, 179.6661, 243.4459],\n",
            "        [135.5835, 122.5674, 188.0826, 174.8257],\n",
            "        [130.9723, 220.0677, 159.1606, 248.4875],\n",
            "        [ 94.3710, 182.9940, 147.1650, 235.0788],\n",
            "        [120.7665, 138.2718, 148.9638, 166.7423],\n",
            "        [156.6376, 112.6645, 184.7764, 141.0748],\n",
            "        [182.2856, 107.5262, 210.4032, 135.9125],\n",
            "        [222.9164, 158.6852, 251.2114, 187.2407],\n",
            "        [166.7046, 133.0928, 194.9534, 161.5919],\n",
            "        [171.8309, 174.0825, 200.0803, 202.5871],\n",
            "        [145.6046, 112.1797, 198.2420, 164.4723],\n",
            "        [131.0097,   5.1123, 159.1624,  33.5118],\n",
            "        [145.4569, 132.8657, 198.0961, 185.2182],\n",
            "        [176.1049, 101.6537, 228.8080, 153.7666],\n",
            "        [151.4795, 174.0836, 179.6354, 202.5047],\n",
            "        [222.8926,  15.3008, 251.2023,  43.8621],\n",
            "        [120.6708,  40.8858, 148.9129,  69.3684],\n",
            "        [146.3836, 102.3904, 174.5401, 130.8113],\n",
            "        [166.8703, 112.6562, 195.0133, 141.0700],\n",
            "        [ 79.7211, 179.1443, 107.9658, 207.6383],\n",
            "        [156.6296, 122.9101, 184.7725, 151.3222],\n",
            "        [ 84.4247, 173.0730, 136.9918, 225.1913],\n",
            "        [222.8801, 107.5285, 251.1778, 136.1161],\n",
            "        [110.4585, 220.0391, 138.6774, 248.4744],\n",
            "        [176.4497,  81.7252, 228.9164, 133.9108],\n",
            "        [ 94.9845, 143.0044, 147.3160, 195.1802],\n",
            "        [ 84.6079, 153.0279, 137.0122, 205.1808],\n",
            "        [135.6023,  81.2083, 188.1346, 133.4003],\n",
            "        [166.7250, 158.7559, 194.9676, 187.2640],\n",
            "        [166.1373,  71.6371, 218.6175, 123.9179]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0612, 0.0610, 0.0603, 0.0601, 0.0599, 0.0597, 0.0592, 0.0592, 0.0592,\n",
            "        0.0592, 0.0591, 0.0591, 0.0590, 0.0588, 0.0586, 0.0585, 0.0583, 0.0582,\n",
            "        0.0580, 0.0579, 0.0577, 0.0576, 0.0573, 0.0573, 0.0572, 0.0570, 0.0569,\n",
            "        0.0569, 0.0568, 0.0567, 0.0566, 0.0564, 0.0564, 0.0564, 0.0564, 0.0563,\n",
            "        0.0563, 0.0562, 0.0562, 0.0561, 0.0561, 0.0561, 0.0560, 0.0560, 0.0560,\n",
            "        0.0559, 0.0558, 0.0558, 0.0557, 0.0557, 0.0557, 0.0557, 0.0555, 0.0555,\n",
            "        0.0555, 0.0554, 0.0554, 0.0554, 0.0552, 0.0552, 0.0551, 0.0550, 0.0550,\n",
            "        0.0549, 0.0549, 0.0549, 0.0548, 0.0548, 0.0548, 0.0544, 0.0544, 0.0543,\n",
            "        0.0543, 0.0543, 0.0543, 0.0542, 0.0542, 0.0542, 0.0542, 0.0542, 0.0542,\n",
            "        0.0541, 0.0541, 0.0541, 0.0541, 0.0540, 0.0539, 0.0539, 0.0539, 0.0539,\n",
            "        0.0539, 0.0539, 0.0538, 0.0538, 0.0538, 0.0537, 0.0537, 0.0537, 0.0537,\n",
            "        0.0536, 0.0536, 0.0536, 0.0535, 0.0535, 0.0534, 0.0534, 0.0533, 0.0533,\n",
            "        0.0532, 0.0532, 0.0531, 0.0531, 0.0531, 0.0530, 0.0530, 0.0530, 0.0529,\n",
            "        0.0529, 0.0529, 0.0529, 0.0528, 0.0528, 0.0527, 0.0527, 0.0527, 0.0526,\n",
            "        0.0526, 0.0525, 0.0525, 0.0524, 0.0524, 0.0524, 0.0524, 0.0524, 0.0523,\n",
            "        0.0522, 0.0522, 0.0521, 0.0521, 0.0520, 0.0520, 0.0518, 0.0518, 0.0518,\n",
            "        0.0518, 0.0518, 0.0518, 0.0517, 0.0517, 0.0517, 0.0517, 0.0516, 0.0516,\n",
            "        0.0516, 0.0516, 0.0516, 0.0516, 0.0515, 0.0515, 0.0515, 0.0515, 0.0515,\n",
            "        0.0515, 0.0514, 0.0514, 0.0514, 0.0514, 0.0514, 0.0514, 0.0513, 0.0513,\n",
            "        0.0513, 0.0513, 0.0513, 0.0513, 0.0512, 0.0512, 0.0512, 0.0512, 0.0512,\n",
            "        0.0511, 0.0510, 0.0510, 0.0510, 0.0510, 0.0510, 0.0508, 0.0508, 0.0508,\n",
            "        0.0508, 0.0508, 0.0508, 0.0507, 0.0507, 0.0507, 0.0507, 0.0507, 0.0507,\n",
            "        0.0507, 0.0506, 0.0506, 0.0506, 0.0506, 0.0505, 0.0505, 0.0505, 0.0505,\n",
            "        0.0504, 0.0503, 0.0503, 0.0503, 0.0503, 0.0502, 0.0502, 0.0502, 0.0502,\n",
            "        0.0501, 0.0501, 0.0501, 0.0501, 0.0501, 0.0501, 0.0500, 0.0500],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
            "        2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1,\n",
            "        2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2,\n",
            "        1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2,\n",
            "        2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2,\n",
            "        1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2,\n",
            "        2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1,\n",
            "        2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1,\n",
            "        2, 1, 1, 1, 1, 1, 2, 1], device='cuda:0')}, {'boxes': tensor([[5.4669e+01, 5.1676e+00, 8.2471e+01, 3.3264e+01],\n",
            "        [6.4783e+01, 5.1918e+00, 9.2639e+01, 3.3349e+01],\n",
            "        [5.9639e+01, 1.5389e+01, 8.7550e+01, 4.3589e+01],\n",
            "        [4.4430e+01, 9.4562e-02, 7.2289e+01, 2.8241e+01],\n",
            "        [4.9416e+01, 1.0246e+01, 7.7330e+01, 3.8430e+01],\n",
            "        [5.4669e+01, 5.1676e+00, 8.2471e+01, 3.3264e+01],\n",
            "        [6.9782e+01, 1.5405e+01, 9.7738e+01, 4.3654e+01],\n",
            "        [6.4783e+01, 5.1918e+00, 9.2639e+01, 3.3349e+01],\n",
            "        [5.9639e+01, 1.5389e+01, 8.7550e+01, 4.3589e+01],\n",
            "        [4.9416e+01, 1.0246e+01, 7.7330e+01, 3.8430e+01],\n",
            "        [3.9085e+01, 5.0809e+00, 6.7091e+01, 3.3331e+01],\n",
            "        [4.4430e+01, 9.4562e-02, 7.2289e+01, 2.8241e+01],\n",
            "        [6.4541e+01, 2.5568e+01, 9.2606e+01, 5.3888e+01],\n",
            "        [5.9603e+01, 0.0000e+00, 8.7674e+01, 2.3762e+01],\n",
            "        [6.9782e+01, 1.5405e+01, 9.7738e+01, 4.3654e+01],\n",
            "        [4.9232e+01, 2.0448e+01, 7.7293e+01, 4.8765e+01],\n",
            "        [7.4738e+01, 5.2043e+00, 1.0280e+02, 3.3543e+01],\n",
            "        [1.7720e+02, 1.1780e+02, 2.0527e+02, 1.4615e+02],\n",
            "        [7.4724e+01, 2.5573e+01, 1.0282e+02, 5.3922e+01],\n",
            "        [7.9857e+01, 1.5410e+01, 1.0795e+02, 4.3776e+01],\n",
            "        [3.9085e+01, 5.0809e+00, 6.7091e+01, 3.3331e+01],\n",
            "        [1.7205e+02, 1.0759e+02, 2.0015e+02, 1.3597e+02],\n",
            "        [1.6690e+02, 8.1980e+01, 1.9502e+02, 1.1038e+02],\n",
            "        [1.8729e+02, 1.2291e+02, 2.1544e+02, 1.5133e+02],\n",
            "        [1.6686e+02, 9.2207e+01, 1.9499e+02, 1.2062e+02],\n",
            "        [6.4541e+01, 2.5568e+01, 9.2606e+01, 5.3888e+01],\n",
            "        [3.8908e+01, 1.5286e+01, 6.7047e+01, 4.3675e+01],\n",
            "        [4.4124e+01, 1.5320e+01, 7.2182e+01, 4.3633e+01],\n",
            "        [1.7704e+02, 1.2795e+02, 2.0522e+02, 1.5637e+02],\n",
            "        [1.7200e+02, 7.1762e+01, 2.0014e+02, 1.0019e+02],\n",
            "        [1.6174e+02, 1.0241e+02, 1.8989e+02, 1.3082e+02],\n",
            "        [8.4897e+01, 2.5585e+01, 1.1306e+02, 5.3999e+01],\n",
            "        [1.7707e+02, 1.5877e+02, 2.0524e+02, 1.8720e+02],\n",
            "        [1.7720e+02, 1.1780e+02, 2.0527e+02, 1.4615e+02],\n",
            "        [1.8729e+02, 1.1274e+02, 2.1546e+02, 1.4120e+02],\n",
            "        [7.4738e+01, 5.2043e+00, 1.0280e+02, 3.3543e+01],\n",
            "        [5.4287e+01, 2.5555e+01, 8.2385e+01, 5.3901e+01],\n",
            "        [7.4724e+01, 2.5573e+01, 1.0282e+02, 5.3922e+01],\n",
            "        [1.6683e+02, 1.1767e+02, 1.9501e+02, 1.4608e+02],\n",
            "        [5.4151e+01, 3.0635e+01, 8.2347e+01, 5.9064e+01],\n",
            "        [1.5657e+02, 1.8433e+02, 1.8476e+02, 2.1278e+02],\n",
            "        [5.9603e+01, 0.0000e+00, 8.7674e+01, 2.3762e+01],\n",
            "        [1.7191e+02, 1.6895e+02, 2.0010e+02, 1.9740e+02],\n",
            "        [1.6169e+02, 1.7410e+02, 1.8988e+02, 2.0255e+02],\n",
            "        [1.6166e+02, 1.9457e+02, 1.8987e+02, 2.2303e+02],\n",
            "        [2.1797e+02, 5.1355e+00, 2.4618e+02, 3.3603e+01],\n",
            "        [1.7696e+02, 8.1936e+01, 2.0517e+02, 1.1041e+02],\n",
            "        [1.6678e+02, 2.0481e+02, 1.9499e+02, 2.3328e+02],\n",
            "        [1.7187e+02, 2.1501e+02, 2.0011e+02, 2.4349e+02],\n",
            "        [7.9857e+01, 1.5410e+01, 1.0795e+02, 4.3776e+01],\n",
            "        [2.3400e+01, 2.1500e+02, 5.1632e+01, 2.4348e+02],\n",
            "        [1.5661e+02, 9.2149e+01, 1.8479e+02, 1.2060e+02],\n",
            "        [6.4433e+01, 1.7410e+02, 9.2613e+01, 2.0254e+02],\n",
            "        [6.9473e+01, 0.0000e+00, 9.7767e+01, 2.3957e+01],\n",
            "        [1.5145e+02, 1.7409e+02, 1.7966e+02, 2.0256e+02],\n",
            "        [4.3857e+01, 1.5873e+02, 7.2095e+01, 1.8722e+02],\n",
            "        [2.0779e+02, 5.1093e+00, 2.3599e+02, 3.3567e+01],\n",
            "        [1.5141e+02, 1.9451e+02, 1.7964e+02, 2.2300e+02],\n",
            "        [1.8713e+02, 1.3311e+02, 2.1540e+02, 1.6161e+02],\n",
            "        [9.5050e+01, 2.5595e+01, 1.2328e+02, 5.4081e+01],\n",
            "        [1.6674e+02, 1.8434e+02, 1.9497e+02, 2.1283e+02],\n",
            "        [1.8216e+02, 1.2800e+02, 2.1033e+02, 1.5641e+02],\n",
            "        [1.6690e+02, 8.1980e+01, 1.9502e+02, 1.1038e+02],\n",
            "        [8.9945e+01, 1.4338e+02, 1.1817e+02, 1.7186e+02],\n",
            "        [2.1281e+02, 1.5332e+01, 2.4105e+02, 4.3822e+01],\n",
            "        [1.6685e+02, 1.5873e+02, 1.9504e+02, 1.8719e+02],\n",
            "        [9.0008e+01, 1.5398e+01, 1.1820e+02, 4.3863e+01],\n",
            "        [1.7205e+02, 1.0759e+02, 2.0015e+02, 1.3597e+02],\n",
            "        [7.4618e+01, 1.7410e+02, 1.0282e+02, 2.0257e+02],\n",
            "        [3.3597e+01, 2.1500e+02, 6.1856e+01, 2.4350e+02],\n",
            "        [1.4630e+02, 1.8429e+02, 1.7453e+02, 2.1278e+02],\n",
            "        [1.8205e+02, 1.6893e+02, 2.1030e+02, 1.9742e+02],\n",
            "        [1.7702e+02, 1.4853e+02, 2.0525e+02, 1.7703e+02],\n",
            "        [5.4125e+01, 1.6896e+02, 8.2349e+01, 1.9743e+02],\n",
            "        [1.8732e+02, 1.1783e+02, 2.1545e+02, 1.4625e+02],\n",
            "        [1.7699e+02, 9.7330e+01, 2.0521e+02, 1.2582e+02],\n",
            "        [1.6686e+02, 9.2207e+01, 1.9499e+02, 1.2062e+02],\n",
            "        [3.8777e+01, 2.5524e+01, 6.7012e+01, 5.4004e+01],\n",
            "        [1.5651e+02, 2.0474e+02, 1.8475e+02, 2.3324e+02],\n",
            "        [8.9913e+01, 1.5360e+02, 1.1816e+02, 1.8209e+02],\n",
            "        [2.3401e+01, 2.0484e+02, 5.1634e+01, 2.3333e+02],\n",
            "        [1.3162e+01, 2.1499e+02, 4.1413e+01, 2.4349e+02],\n",
            "        [1.8202e+02, 7.1709e+01, 2.1028e+02, 1.0023e+02],\n",
            "        [2.1787e+02, 2.5617e+01, 2.4615e+02, 5.4142e+01],\n",
            "        [1.8714e+02, 1.5874e+02, 2.1541e+02, 1.8727e+02],\n",
            "        [1.7183e+02, 1.9460e+02, 2.0008e+02, 2.2311e+02]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0730, 0.0703, 0.0676, 0.0675, 0.0671, 0.0665, 0.0652, 0.0638, 0.0618,\n",
            "        0.0616, 0.0615, 0.0613, 0.0598, 0.0596, 0.0594, 0.0592, 0.0589, 0.0586,\n",
            "        0.0578, 0.0571, 0.0567, 0.0558, 0.0558, 0.0557, 0.0552, 0.0551, 0.0549,\n",
            "        0.0546, 0.0543, 0.0543, 0.0542, 0.0542, 0.0541, 0.0536, 0.0535, 0.0534,\n",
            "        0.0532, 0.0532, 0.0532, 0.0531, 0.0530, 0.0530, 0.0527, 0.0525, 0.0525,\n",
            "        0.0525, 0.0525, 0.0524, 0.0521, 0.0519, 0.0519, 0.0518, 0.0517, 0.0517,\n",
            "        0.0516, 0.0514, 0.0514, 0.0513, 0.0512, 0.0512, 0.0512, 0.0512, 0.0511,\n",
            "        0.0511, 0.0510, 0.0510, 0.0510, 0.0510, 0.0509, 0.0509, 0.0509, 0.0509,\n",
            "        0.0508, 0.0508, 0.0507, 0.0507, 0.0507, 0.0507, 0.0505, 0.0504, 0.0503,\n",
            "        0.0503, 0.0502, 0.0501, 0.0500, 0.0500], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
            "        2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2,\n",
            "        2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
            "        2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')}, {'boxes': tensor([[1.1593e+02, 1.6391e+02, 1.4387e+02, 1.9215e+02],\n",
            "        [1.2621e+02, 9.2015e-02, 1.5414e+02, 2.8310e+01],\n",
            "        [1.1084e+02, 1.5370e+02, 1.3877e+02, 1.8194e+02],\n",
            "        ...,\n",
            "        [7.4571e+01, 1.6310e+02, 1.2681e+02, 2.1485e+02],\n",
            "        [4.4113e+01, 1.0143e+01, 9.6183e+01, 6.1918e+01],\n",
            "        [1.4584e+02, 1.7335e+02, 1.9826e+02, 2.2512e+02]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0645, 0.0641, 0.0633, 0.0632, 0.0632, 0.0631, 0.0628, 0.0626, 0.0626,\n",
            "        0.0625, 0.0623, 0.0623, 0.0621, 0.0621, 0.0619, 0.0619, 0.0619, 0.0618,\n",
            "        0.0618, 0.0617, 0.0615, 0.0615, 0.0614, 0.0613, 0.0612, 0.0612, 0.0610,\n",
            "        0.0609, 0.0608, 0.0607, 0.0607, 0.0607, 0.0607, 0.0606, 0.0606, 0.0605,\n",
            "        0.0605, 0.0604, 0.0604, 0.0604, 0.0603, 0.0603, 0.0602, 0.0602, 0.0602,\n",
            "        0.0600, 0.0600, 0.0599, 0.0599, 0.0599, 0.0599, 0.0599, 0.0598, 0.0598,\n",
            "        0.0598, 0.0598, 0.0598, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0596,\n",
            "        0.0596, 0.0596, 0.0595, 0.0595, 0.0595, 0.0595, 0.0594, 0.0593, 0.0593,\n",
            "        0.0593, 0.0593, 0.0593, 0.0593, 0.0593, 0.0592, 0.0592, 0.0591, 0.0591,\n",
            "        0.0591, 0.0591, 0.0591, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590,\n",
            "        0.0589, 0.0589, 0.0589, 0.0589, 0.0589, 0.0589, 0.0589, 0.0588, 0.0588,\n",
            "        0.0587, 0.0587, 0.0586, 0.0586, 0.0586, 0.0586, 0.0585, 0.0585, 0.0585,\n",
            "        0.0585, 0.0585, 0.0585, 0.0585, 0.0584, 0.0584, 0.0583, 0.0583, 0.0583,\n",
            "        0.0582, 0.0582, 0.0582, 0.0582, 0.0581, 0.0581, 0.0580, 0.0580, 0.0580,\n",
            "        0.0580, 0.0580, 0.0580, 0.0580, 0.0580, 0.0580, 0.0579, 0.0579, 0.0579,\n",
            "        0.0578, 0.0578, 0.0578, 0.0578, 0.0578, 0.0578, 0.0578, 0.0578, 0.0578,\n",
            "        0.0578, 0.0577, 0.0577, 0.0577, 0.0577, 0.0577, 0.0576, 0.0576, 0.0575,\n",
            "        0.0575, 0.0575, 0.0575, 0.0575, 0.0575, 0.0575, 0.0574, 0.0574, 0.0574,\n",
            "        0.0574, 0.0573, 0.0573, 0.0573, 0.0573, 0.0573, 0.0573, 0.0573, 0.0573,\n",
            "        0.0573, 0.0572, 0.0572, 0.0572, 0.0571, 0.0571, 0.0571, 0.0571, 0.0571,\n",
            "        0.0571, 0.0571, 0.0570, 0.0570, 0.0570, 0.0570, 0.0570, 0.0570, 0.0570,\n",
            "        0.0569, 0.0569, 0.0568, 0.0568, 0.0567, 0.0567, 0.0567, 0.0567, 0.0567,\n",
            "        0.0567, 0.0567, 0.0567, 0.0566, 0.0566, 0.0566, 0.0566, 0.0566, 0.0566,\n",
            "        0.0565, 0.0565, 0.0565, 0.0565, 0.0565, 0.0565, 0.0565, 0.0565, 0.0564,\n",
            "        0.0564, 0.0564, 0.0564, 0.0564, 0.0564, 0.0564, 0.0564, 0.0563, 0.0563,\n",
            "        0.0563, 0.0563, 0.0562, 0.0562, 0.0562, 0.0562, 0.0562, 0.0562, 0.0562,\n",
            "        0.0561, 0.0561, 0.0561, 0.0561, 0.0561, 0.0561, 0.0561, 0.0561, 0.0560,\n",
            "        0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0559, 0.0558,\n",
            "        0.0558, 0.0558, 0.0558, 0.0558, 0.0558, 0.0558, 0.0558, 0.0558, 0.0558,\n",
            "        0.0558, 0.0557, 0.0557, 0.0557, 0.0557, 0.0557, 0.0557, 0.0556, 0.0556,\n",
            "        0.0556, 0.0556, 0.0554, 0.0554, 0.0553, 0.0553, 0.0553, 0.0552, 0.0551,\n",
            "        0.0550, 0.0549, 0.0549, 0.0549, 0.0548, 0.0548, 0.0548, 0.0547, 0.0546,\n",
            "        0.0546, 0.0546, 0.0546, 0.0544, 0.0543, 0.0543, 0.0542, 0.0541, 0.0540,\n",
            "        0.0540, 0.0540, 0.0540], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2,\n",
            "        2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2,\n",
            "        2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1,\n",
            "        1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1,\n",
            "        1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1,\n",
            "        2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1,\n",
            "        2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')}, {'boxes': tensor([[ 28.8951,  71.7564,  56.8347, 100.0013],\n",
            "        [ 28.8970,  61.5461,  56.8507,  89.8017],\n",
            "        [ 23.6844,  81.9492,  51.6882, 110.2365],\n",
            "        ...,\n",
            "        [176.1706,  91.3916, 228.8724, 143.6303],\n",
            "        [ 84.1037, 142.8035, 136.7159, 195.0665],\n",
            "        [ 53.6996,  30.4371, 106.1101,  82.6094]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0646, 0.0636, 0.0613, 0.0610, 0.0609, 0.0597, 0.0596, 0.0595, 0.0595,\n",
            "        0.0594, 0.0594, 0.0592, 0.0589, 0.0589, 0.0589, 0.0588, 0.0582, 0.0581,\n",
            "        0.0581, 0.0580, 0.0580, 0.0579, 0.0575, 0.0575, 0.0573, 0.0573, 0.0573,\n",
            "        0.0573, 0.0572, 0.0572, 0.0571, 0.0571, 0.0571, 0.0570, 0.0570, 0.0570,\n",
            "        0.0569, 0.0569, 0.0569, 0.0569, 0.0568, 0.0567, 0.0564, 0.0563, 0.0563,\n",
            "        0.0563, 0.0563, 0.0562, 0.0562, 0.0562, 0.0562, 0.0561, 0.0561, 0.0560,\n",
            "        0.0560, 0.0558, 0.0558, 0.0558, 0.0557, 0.0556, 0.0556, 0.0556, 0.0556,\n",
            "        0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0554, 0.0554, 0.0552,\n",
            "        0.0552, 0.0552, 0.0552, 0.0552, 0.0551, 0.0551, 0.0551, 0.0548, 0.0548,\n",
            "        0.0548, 0.0548, 0.0547, 0.0547, 0.0546, 0.0546, 0.0546, 0.0545, 0.0545,\n",
            "        0.0545, 0.0545, 0.0545, 0.0544, 0.0544, 0.0544, 0.0544, 0.0543, 0.0543,\n",
            "        0.0543, 0.0542, 0.0542, 0.0542, 0.0542, 0.0542, 0.0541, 0.0541, 0.0541,\n",
            "        0.0541, 0.0540, 0.0539, 0.0539, 0.0539, 0.0538, 0.0538, 0.0538, 0.0538,\n",
            "        0.0538, 0.0537, 0.0537, 0.0536, 0.0535, 0.0535, 0.0535, 0.0534, 0.0534,\n",
            "        0.0534, 0.0534, 0.0533, 0.0533, 0.0533, 0.0533, 0.0532, 0.0532, 0.0531,\n",
            "        0.0531, 0.0531, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0529, 0.0529,\n",
            "        0.0529, 0.0529, 0.0529, 0.0528, 0.0528, 0.0528, 0.0528, 0.0528, 0.0528,\n",
            "        0.0528, 0.0528, 0.0527, 0.0527, 0.0527, 0.0527, 0.0527, 0.0526, 0.0526,\n",
            "        0.0526, 0.0525, 0.0525, 0.0525, 0.0525, 0.0525, 0.0525, 0.0524, 0.0524,\n",
            "        0.0524, 0.0524, 0.0524, 0.0524, 0.0524, 0.0524, 0.0524, 0.0524, 0.0524,\n",
            "        0.0523, 0.0523, 0.0523, 0.0523, 0.0523, 0.0523, 0.0523, 0.0522, 0.0522,\n",
            "        0.0522, 0.0522, 0.0521, 0.0521, 0.0521, 0.0521, 0.0521, 0.0521, 0.0521,\n",
            "        0.0521, 0.0521, 0.0521, 0.0520, 0.0520, 0.0520, 0.0520, 0.0520, 0.0520,\n",
            "        0.0520, 0.0520, 0.0519, 0.0519, 0.0519, 0.0519, 0.0519, 0.0518, 0.0518,\n",
            "        0.0518, 0.0518, 0.0518, 0.0518, 0.0517, 0.0517, 0.0517, 0.0517, 0.0517,\n",
            "        0.0517, 0.0516, 0.0516, 0.0516, 0.0516, 0.0516, 0.0516, 0.0516, 0.0516,\n",
            "        0.0516, 0.0516, 0.0515, 0.0515, 0.0515, 0.0515, 0.0515, 0.0515, 0.0515,\n",
            "        0.0515, 0.0515, 0.0515, 0.0514, 0.0514, 0.0514, 0.0514, 0.0513, 0.0513,\n",
            "        0.0513, 0.0513, 0.0513, 0.0513, 0.0513, 0.0513, 0.0513, 0.0513, 0.0513,\n",
            "        0.0513, 0.0512, 0.0512, 0.0512, 0.0512, 0.0511, 0.0510, 0.0510, 0.0509,\n",
            "        0.0509, 0.0508, 0.0508, 0.0508, 0.0507, 0.0506, 0.0506, 0.0506, 0.0504,\n",
            "        0.0504, 0.0502, 0.0501, 0.0501, 0.0501, 0.0501, 0.0500, 0.0500],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2,\n",
            "        2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1,\n",
            "        2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1,\n",
            "        1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1,\n",
            "        2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 2,\n",
            "        2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2,\n",
            "        2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "       device='cuda:0')}]\n",
            "[{'boxes': tensor([[1.3344e+01, 6.6613e+01, 4.1428e+01, 9.4980e+01],\n",
            "        [1.3341e+01, 5.6381e+01, 4.1443e+01, 8.4767e+01],\n",
            "        [1.3270e+01, 7.6820e+01, 4.1396e+01, 1.0521e+02],\n",
            "        [3.3764e+01, 4.1000e+01, 6.1891e+01, 6.9397e+01],\n",
            "        [2.3500e+01, 6.1481e+01, 5.1634e+01, 8.9895e+01],\n",
            "        [8.2004e+00, 1.2293e+02, 3.6318e+01, 1.5133e+02],\n",
            "        [2.3530e+01, 5.1242e+01, 5.1658e+01, 7.9644e+01],\n",
            "        [5.4213e+01, 1.3828e+02, 8.2363e+01, 1.6669e+02],\n",
            "        [2.3456e+01, 7.1697e+01, 5.1612e+01, 1.0012e+02],\n",
            "        [3.3757e+01, 3.0773e+01, 6.1901e+01, 5.9190e+01],\n",
            "        [1.8380e+01, 1.2290e+02, 4.6520e+01, 1.5131e+02],\n",
            "        [2.3528e+01, 4.0987e+01, 5.1671e+01, 6.9398e+01],\n",
            "        [4.9109e+01, 1.2804e+02, 7.7257e+01, 1.5646e+02],\n",
            "        [3.3695e+01, 5.1210e+01, 6.1862e+01, 7.9637e+01],\n",
            "        [4.3957e+01, 3.5871e+01, 7.2115e+01, 6.4299e+01],\n",
            "        [5.4157e+01, 1.4850e+02, 8.2344e+01, 1.7694e+02],\n",
            "        [1.3255e+01, 1.1269e+02, 4.1405e+01, 1.4111e+02],\n",
            "        [5.4209e+01, 2.0995e+02, 8.2372e+01, 2.3837e+02],\n",
            "        [4.3950e+01, 1.3823e+02, 7.2127e+01, 1.6666e+02],\n",
            "        [5.9322e+01, 1.2804e+02, 8.7484e+01, 1.5647e+02],\n",
            "        [2.3499e+01, 2.9319e-02, 5.1664e+01, 2.8443e+01],\n",
            "        [1.3283e+01, 4.6108e+01, 4.1438e+01, 7.4536e+01],\n",
            "        [8.0631e+00, 1.3308e+02, 3.6260e+01, 1.6152e+02],\n",
            "        [3.8845e+01, 1.2799e+02, 6.7015e+01, 1.5643e+02],\n",
            "        [1.3344e+01, 6.6613e+01, 4.1428e+01, 9.4980e+01],\n",
            "        [6.4395e+01, 2.1504e+02, 9.2590e+01, 2.4349e+02],\n",
            "        [1.3200e+01, 8.7050e+01, 4.1385e+01, 1.1549e+02],\n",
            "        [4.3943e+01, 2.5644e+01, 7.2121e+01, 5.4094e+01],\n",
            "        [1.3203e+01, 1.0244e+02, 4.1387e+01, 1.3089e+02],\n",
            "        [3.3625e+01, 5.1030e+00, 6.1845e+01, 3.3556e+01],\n",
            "        [2.8588e+01, 1.2288e+02, 5.6763e+01, 1.5132e+02],\n",
            "        [6.4393e+01, 1.3824e+02, 9.2580e+01, 1.6669e+02],\n",
            "        [5.4172e+01, 1.1779e+02, 8.2355e+01, 1.4624e+02],\n",
            "        [4.3889e+01, 4.6074e+01, 7.2086e+01, 7.4525e+01],\n",
            "        [1.2583e+02, 2.1501e+02, 1.5404e+02, 2.4347e+02],\n",
            "        [4.3912e+01, 1.4845e+02, 7.2129e+01, 1.7691e+02],\n",
            "        [1.3275e+01, 2.1902e-02, 4.1447e+01, 2.8437e+01],\n",
            "        [2.3411e+01, 8.1901e+01, 5.1611e+01, 1.1035e+02],\n",
            "        [1.1562e+02, 2.0992e+02, 1.4381e+02, 2.3837e+02],\n",
            "        [2.3484e+01, 3.0729e+01, 5.1668e+01, 5.9176e+01],\n",
            "        [2.1288e+02, 1.6384e+02, 2.4108e+02, 1.9229e+02],\n",
            "        [3.3682e+01, 2.0510e+01, 6.1886e+01, 4.8978e+01],\n",
            "        [2.3443e+01, 1.1267e+02, 5.1634e+01, 1.4113e+02],\n",
            "        [6.4396e+01, 2.0484e+02, 9.2591e+01, 2.3331e+02],\n",
            "        [4.3950e+01, 1.1777e+02, 7.2135e+01, 1.4622e+02],\n",
            "        [4.9022e+01, 9.2175e+01, 7.7227e+01, 1.2064e+02],\n",
            "        [4.3932e+01, 2.0989e+02, 7.2136e+01, 2.3834e+02],\n",
            "        [4.8989e+01, 1.5871e+02, 7.7213e+01, 1.8718e+02],\n",
            "        [1.0021e+02, 1.5360e+02, 1.2843e+02, 1.8206e+02],\n",
            "        [1.8296e+01, 1.8432e+02, 4.6511e+01, 2.1279e+02],\n",
            "        [2.1795e+02, 1.5363e+02, 2.4617e+02, 1.8212e+02],\n",
            "        [5.4077e+01, 2.2005e+02, 8.2339e+01, 2.4852e+02],\n",
            "        [2.1793e+02, 1.7410e+02, 2.4616e+02, 2.0258e+02],\n",
            "        [4.9014e+01, 1.0241e+02, 7.7225e+01, 1.3087e+02],\n",
            "        [6.9492e+01, 1.2802e+02, 9.7698e+01, 1.5649e+02],\n",
            "        [3.3619e+01, 6.1432e+01, 6.1840e+01, 8.9911e+01],\n",
            "        [1.3270e+01, 7.6820e+01, 4.1396e+01, 1.0521e+02],\n",
            "        [1.2583e+02, 2.0482e+02, 1.5404e+02, 2.3329e+02],\n",
            "        [2.0264e+02, 1.6383e+02, 2.3084e+02, 1.9230e+02],\n",
            "        [1.3341e+01, 5.6381e+01, 4.1443e+01, 8.4767e+01],\n",
            "        [5.4168e+01, 1.9973e+02, 8.2368e+01, 2.2820e+02],\n",
            "        [8.9956e+01, 1.4846e+02, 1.1818e+02, 1.7693e+02],\n",
            "        [1.8256e+01, 1.3306e+02, 4.6477e+01, 1.6151e+02],\n",
            "        [1.1042e+02, 1.5873e+02, 1.3865e+02, 1.8721e+02],\n",
            "        [1.3602e+02, 2.1502e+02, 1.6426e+02, 2.4350e+02],\n",
            "        [2.1285e+02, 1.8944e+02, 2.4107e+02, 2.1791e+02],\n",
            "        [1.8274e+01, 1.9455e+02, 4.6500e+01, 2.2303e+02],\n",
            "        [5.4134e+01, 3.0724e+01, 8.2347e+01, 5.9196e+01],\n",
            "        [1.0535e+02, 2.0991e+02, 1.3357e+02, 2.3838e+02],\n",
            "        [2.8499e+01, 1.8432e+02, 5.6731e+01, 2.1281e+02],\n",
            "        [2.3378e+01, 1.0180e+01, 5.1614e+01, 3.8655e+01],\n",
            "        [2.0774e+02, 1.7406e+02, 2.3596e+02, 2.0253e+02],\n",
            "        [3.8778e+01, 8.7026e+01, 6.6998e+01, 1.1550e+02],\n",
            "        [4.3905e+01, 1.9969e+02, 7.2122e+01, 2.2817e+02],\n",
            "        [3.3764e+01, 4.1000e+01, 6.1891e+01, 6.9397e+01],\n",
            "        [6.4348e+01, 1.1780e+02, 9.2571e+01, 1.4628e+02],\n",
            "        [3.3628e+01, 7.6794e+01, 6.1857e+01, 1.0528e+02],\n",
            "        [2.3500e+01, 6.1481e+01, 5.1634e+01, 8.9895e+01],\n",
            "        [2.1282e+02, 1.9967e+02, 2.4106e+02, 2.2816e+02],\n",
            "        [1.9749e+02, 1.7407e+02, 2.2571e+02, 2.0254e+02],\n",
            "        [1.1557e+02, 1.9969e+02, 1.4379e+02, 2.2817e+02],\n",
            "        [2.0776e+02, 1.5360e+02, 2.3597e+02, 1.8208e+02],\n",
            "        [2.8507e+01, 1.3304e+02, 5.6735e+01, 1.6151e+02],\n",
            "        [4.9027e+01, 8.1944e+01, 7.7240e+01, 1.1042e+02],\n",
            "        [2.8496e+01, 1.9454e+02, 5.6736e+01, 2.2303e+02],\n",
            "        [8.2004e+00, 1.2293e+02, 3.6318e+01, 1.5133e+02],\n",
            "        [2.0262e+02, 1.8943e+02, 2.3083e+02, 2.1790e+02],\n",
            "        [7.4598e+01, 1.3821e+02, 1.0282e+02, 1.6669e+02],\n",
            "        [1.1553e+02, 1.6894e+02, 1.4377e+02, 1.9743e+02],\n",
            "        [6.4326e+01, 1.4845e+02, 9.2565e+01, 1.7694e+02],\n",
            "        [1.3210e+01, 3.5832e+01, 4.1420e+01, 6.4301e+01],\n",
            "        [1.0019e+02, 1.6381e+02, 1.2843e+02, 1.9229e+02],\n",
            "        [2.3530e+01, 5.1242e+01, 5.1658e+01, 7.9644e+01],\n",
            "        [2.1793e+02, 1.4339e+02, 2.4618e+02, 1.7190e+02],\n",
            "        [8.4832e+01, 1.3824e+02, 1.1306e+02, 1.6673e+02],\n",
            "        [3.8763e+01, 9.7249e+01, 6.6994e+01, 1.2573e+02],\n",
            "        [5.9202e+01, 1.0756e+02, 8.7438e+01, 1.3605e+02],\n",
            "        [3.3673e+01, 1.1264e+02, 6.1886e+01, 1.4112e+02],\n",
            "        [4.3870e+01, 1.5372e+01, 7.2106e+01, 4.3864e+01]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0573, 0.0558, 0.0555, 0.0551, 0.0551, 0.0549, 0.0548, 0.0545, 0.0542,\n",
            "        0.0541, 0.0537, 0.0537, 0.0537, 0.0535, 0.0535, 0.0535, 0.0534, 0.0534,\n",
            "        0.0532, 0.0530, 0.0530, 0.0527, 0.0525, 0.0525, 0.0525, 0.0525, 0.0525,\n",
            "        0.0523, 0.0521, 0.0521, 0.0521, 0.0521, 0.0521, 0.0520, 0.0519, 0.0518,\n",
            "        0.0518, 0.0518, 0.0517, 0.0517, 0.0516, 0.0516, 0.0515, 0.0515, 0.0514,\n",
            "        0.0514, 0.0514, 0.0514, 0.0514, 0.0513, 0.0513, 0.0512, 0.0512, 0.0512,\n",
            "        0.0511, 0.0511, 0.0511, 0.0510, 0.0510, 0.0509, 0.0509, 0.0509, 0.0509,\n",
            "        0.0509, 0.0509, 0.0508, 0.0508, 0.0508, 0.0508, 0.0507, 0.0507, 0.0507,\n",
            "        0.0506, 0.0506, 0.0506, 0.0505, 0.0505, 0.0505, 0.0504, 0.0504, 0.0504,\n",
            "        0.0504, 0.0504, 0.0503, 0.0503, 0.0503, 0.0503, 0.0502, 0.0502, 0.0502,\n",
            "        0.0502, 0.0502, 0.0502, 0.0502, 0.0501, 0.0501, 0.0501, 0.0500, 0.0500],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
            "        2, 2, 2], device='cuda:0')}, {'boxes': tensor([[ 79.7422, 199.7027, 107.9588, 228.1805]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0509], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2], device='cuda:0')}, {'boxes': tensor([[177.5532,   5.1875, 205.3581,  33.2953],\n",
            "        [ 39.2859, 189.5410,  67.1149, 217.6978],\n",
            "        [187.7034,   5.1951, 215.5514,  33.3433],\n",
            "        ...,\n",
            "        [ 55.0666, 122.6683, 106.7671, 174.0471],\n",
            "        [ 74.4298, 143.0477, 126.5888, 194.5584],\n",
            "        [ 44.3876, 153.3432,  96.3473, 204.8604]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0725, 0.0704, 0.0701, 0.0691, 0.0685, 0.0685, 0.0685, 0.0681, 0.0679,\n",
            "        0.0677, 0.0677, 0.0674, 0.0670, 0.0669, 0.0669, 0.0669, 0.0663, 0.0663,\n",
            "        0.0659, 0.0656, 0.0655, 0.0655, 0.0652, 0.0651, 0.0650, 0.0648, 0.0648,\n",
            "        0.0648, 0.0647, 0.0646, 0.0646, 0.0641, 0.0639, 0.0637, 0.0637, 0.0636,\n",
            "        0.0636, 0.0633, 0.0631, 0.0629, 0.0629, 0.0629, 0.0629, 0.0628, 0.0628,\n",
            "        0.0627, 0.0627, 0.0626, 0.0625, 0.0624, 0.0623, 0.0622, 0.0622, 0.0621,\n",
            "        0.0620, 0.0620, 0.0619, 0.0619, 0.0619, 0.0618, 0.0617, 0.0617, 0.0617,\n",
            "        0.0616, 0.0615, 0.0615, 0.0614, 0.0612, 0.0612, 0.0611, 0.0611, 0.0610,\n",
            "        0.0610, 0.0609, 0.0609, 0.0608, 0.0608, 0.0608, 0.0607, 0.0605, 0.0605,\n",
            "        0.0605, 0.0605, 0.0603, 0.0603, 0.0602, 0.0601, 0.0601, 0.0600, 0.0598,\n",
            "        0.0597, 0.0597, 0.0597, 0.0596, 0.0596, 0.0596, 0.0596, 0.0596, 0.0595,\n",
            "        0.0594, 0.0594, 0.0592, 0.0592, 0.0592, 0.0592, 0.0592, 0.0592, 0.0591,\n",
            "        0.0591, 0.0591, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0589, 0.0589,\n",
            "        0.0589, 0.0588, 0.0587, 0.0586, 0.0585, 0.0583, 0.0582, 0.0582, 0.0581,\n",
            "        0.0581, 0.0581, 0.0581, 0.0580, 0.0580, 0.0580, 0.0579, 0.0579, 0.0578,\n",
            "        0.0578, 0.0578, 0.0577, 0.0577, 0.0576, 0.0576, 0.0576, 0.0576, 0.0576,\n",
            "        0.0575, 0.0575, 0.0575, 0.0574, 0.0574, 0.0574, 0.0574, 0.0574, 0.0573,\n",
            "        0.0573, 0.0572, 0.0572, 0.0572, 0.0572, 0.0572, 0.0571, 0.0571, 0.0570,\n",
            "        0.0570, 0.0569, 0.0569, 0.0568, 0.0568, 0.0567, 0.0567, 0.0567, 0.0566,\n",
            "        0.0566, 0.0566, 0.0566, 0.0566, 0.0565, 0.0565, 0.0565, 0.0564, 0.0564,\n",
            "        0.0564, 0.0564, 0.0563, 0.0563, 0.0563, 0.0563, 0.0563, 0.0562, 0.0562,\n",
            "        0.0562, 0.0562, 0.0562, 0.0562, 0.0562, 0.0562, 0.0561, 0.0561, 0.0561,\n",
            "        0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0559, 0.0558, 0.0558, 0.0558,\n",
            "        0.0557, 0.0557, 0.0557, 0.0556, 0.0556, 0.0555, 0.0555, 0.0555, 0.0555,\n",
            "        0.0554, 0.0553, 0.0553, 0.0552, 0.0552, 0.0552, 0.0552, 0.0551, 0.0551,\n",
            "        0.0551, 0.0551, 0.0551, 0.0549, 0.0548, 0.0548, 0.0548, 0.0548, 0.0548,\n",
            "        0.0547, 0.0547, 0.0547, 0.0546, 0.0546, 0.0546, 0.0545, 0.0545, 0.0545,\n",
            "        0.0545, 0.0545, 0.0545, 0.0544, 0.0544, 0.0544, 0.0543, 0.0543, 0.0543,\n",
            "        0.0543, 0.0543, 0.0543, 0.0543, 0.0542, 0.0542, 0.0542, 0.0542, 0.0542,\n",
            "        0.0542, 0.0541, 0.0541, 0.0541, 0.0541, 0.0540, 0.0540, 0.0540, 0.0540,\n",
            "        0.0540, 0.0540, 0.0538, 0.0535, 0.0534, 0.0533, 0.0532, 0.0532, 0.0530,\n",
            "        0.0530, 0.0529, 0.0528, 0.0527, 0.0525, 0.0525, 0.0525, 0.0525, 0.0524,\n",
            "        0.0523, 0.0522, 0.0519, 0.0519, 0.0518, 0.0517, 0.0517, 0.0516, 0.0516,\n",
            "        0.0516, 0.0516, 0.0515], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1,\n",
            "        2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2,\n",
            "        1, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2,\n",
            "        2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1,\n",
            "        1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1,\n",
            "        1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2,\n",
            "        2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1,\n",
            "        2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2,\n",
            "        1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2,\n",
            "        2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1,\n",
            "        1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1,\n",
            "        1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2], device='cuda:0')}, {'boxes': tensor([[218.4696, 158.8020, 246.2890, 186.9437],\n",
            "        [208.2970, 153.6987, 236.1012, 181.8279],\n",
            "        [218.4680, 148.6228, 246.3069, 176.8083],\n",
            "        [218.3504, 168.9951, 246.2577, 197.1945],\n",
            "        [208.1579, 163.8604, 236.0505, 192.0340],\n",
            "        [197.9565, 153.6631, 225.8385, 181.8447],\n",
            "        [218.4696, 158.8020, 246.2890, 186.9437],\n",
            "        [208.2970, 153.6987, 236.1012, 181.8279],\n",
            "        [227.6104, 158.5732, 256.0000, 187.2217],\n",
            "        [208.2103, 143.5357, 236.1079, 171.7855],\n",
            "        [218.4680, 148.6228, 246.3069, 176.8083],\n",
            "        [218.3504, 168.9951, 246.2577, 197.1945],\n",
            "        [208.1579, 163.8604, 236.0505, 192.0340],\n",
            "        [227.5463, 168.7756, 256.0000, 197.4395],\n",
            "        [227.6180, 148.3747, 256.0000, 177.0729],\n",
            "        [197.9565, 153.6631, 225.8385, 181.8447],\n",
            "        [218.1613, 179.2025, 246.2148, 207.5151],\n",
            "        [192.6364, 158.6815, 220.6545, 186.9486],\n",
            "        [197.9044, 143.5229, 225.8565, 171.8113],\n",
            "        [187.6012, 148.5547, 215.5886, 176.8366],\n",
            "        [202.8431, 168.9153, 230.8899, 197.2025],\n",
            "        [218.2892, 138.4240, 246.2982, 166.7760],\n",
            "        [ 90.1031, 220.1259, 118.2297, 248.4896],\n",
            "        [227.6104, 158.5732, 256.0000, 187.2217],\n",
            "        [208.2103, 143.5357, 236.1079, 171.7855],\n",
            "        [207.9160, 179.1817, 236.0103, 207.5269],\n",
            "        [192.5453, 194.6183, 220.6320, 222.9936],\n",
            "        [182.2801, 199.6998, 210.3826, 228.0713],\n",
            "        [227.5463, 168.7756, 256.0000, 197.4395],\n",
            "        [192.6364, 158.6815, 220.6545, 186.9486],\n",
            "        [218.1613, 179.2025, 246.2148, 207.5151],\n",
            "        [227.4020, 178.9770, 256.0000, 207.6983],\n",
            "        [ 95.2166,  20.5515, 123.3377,  48.9510],\n",
            "        [ 85.0062, 209.9880, 113.1191, 238.3763],\n",
            "        [172.0329, 199.6986, 200.1479, 228.0794],\n",
            "        [227.6180, 148.3747, 256.0000, 177.0729],\n",
            "        [202.8431, 168.9153, 230.8899, 197.2025],\n",
            "        [100.2271, 220.1469, 128.4112, 248.5763],\n",
            "        [202.7463, 189.4806, 230.8684, 217.8923],\n",
            "        [197.9044, 143.5229, 225.8565, 171.8113],\n",
            "        [187.6012, 148.5547, 215.5886, 176.8366],\n",
            "        [227.5461, 138.1915, 256.0000, 167.0229],\n",
            "        [161.7356, 199.6722, 189.8982, 228.0881],\n",
            "        [212.9169, 189.4164, 241.0767, 217.8378],\n",
            "        [ 95.1910, 210.0236, 123.3346, 238.4637],\n",
            "        [177.1689, 148.4807, 205.2973, 176.8713],\n",
            "        [ 90.1031, 220.1259, 118.2297, 248.4896],\n",
            "        [ 74.6507, 204.7903, 102.8349, 233.2205],\n",
            "        [182.1663, 158.5773, 210.3528, 186.9705],\n",
            "        [218.2892, 138.4240, 246.2982, 166.7760],\n",
            "        [182.2924, 189.5235, 210.4227, 217.9505],\n",
            "        [ 79.7284, 220.0106, 107.9668, 248.4498],\n",
            "        [192.3524, 204.7545, 220.5586, 233.1937],\n",
            "        [ 69.5272, 194.5802,  97.7089, 223.0231],\n",
            "        [ 95.0379,  30.6544, 123.2649,  59.1000],\n",
            "        [202.5856, 199.6561, 230.7902, 228.1054],\n",
            "        [196.3951, 143.2364, 248.9806, 195.3658],\n",
            "        [207.9160, 179.1817, 236.0103, 207.5269],\n",
            "        [ 84.9345,  20.4609, 113.1154,  48.8915],\n",
            "        [  8.0162,   5.1520,  36.2260,  33.6123],\n",
            "        [ 59.2803, 189.4340,  87.4779, 217.8838],\n",
            "        [171.8744, 209.8633, 200.1017, 238.3232],\n",
            "        [197.5802, 179.1821, 225.7629, 207.6223],\n",
            "        [192.3878, 168.8225, 220.5967, 197.2466],\n",
            "        [182.2801, 199.6998, 210.3826, 228.0713],\n",
            "        [192.5453, 194.6183, 220.6320, 222.9936],\n",
            "        [ 84.8841, 199.7398, 113.0775, 228.2101],\n",
            "        [227.4020, 178.9770, 256.0000, 207.6983],\n",
            "        [172.0091, 189.5214, 200.1696, 217.9721],\n",
            "        [ 95.1681,  25.6087, 123.3084,  54.0019],\n",
            "        [182.0751, 209.8529, 210.3201, 238.3241],\n",
            "        [161.7183, 189.5093, 189.9072, 217.9774],\n",
            "        [222.8558, 189.3356, 251.1644, 217.8749],\n",
            "        [ 48.9965, 128.0091,  77.2283, 156.4972],\n",
            "        [172.0329, 199.6986, 200.1479, 228.0794],\n",
            "        [187.3981, 138.3461, 215.5491, 166.7940],\n",
            "        [ 85.0062, 209.9880, 113.1191, 238.3763],\n",
            "        [151.4053, 194.5299, 179.6396, 223.0087],\n",
            "        [105.2219,  25.6102, 133.4721,  54.1062],\n",
            "        [186.4329, 162.9575, 239.1906, 215.1757],\n",
            "        [ 69.4841, 184.3669,  97.7057, 212.8587],\n",
            "        [ 59.2429, 179.2313,  87.4735, 207.7264],\n",
            "        [161.6064, 209.8446, 189.8687, 238.3365]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0724, 0.0710, 0.0692, 0.0683, 0.0673, 0.0665, 0.0658, 0.0644, 0.0631,\n",
            "        0.0630, 0.0625, 0.0625, 0.0617, 0.0614, 0.0609, 0.0607, 0.0606, 0.0605,\n",
            "        0.0602, 0.0596, 0.0594, 0.0581, 0.0574, 0.0571, 0.0567, 0.0565, 0.0559,\n",
            "        0.0559, 0.0558, 0.0558, 0.0557, 0.0557, 0.0555, 0.0553, 0.0552, 0.0550,\n",
            "        0.0548, 0.0545, 0.0544, 0.0543, 0.0543, 0.0540, 0.0536, 0.0535, 0.0535,\n",
            "        0.0533, 0.0526, 0.0525, 0.0525, 0.0524, 0.0523, 0.0523, 0.0523, 0.0523,\n",
            "        0.0522, 0.0522, 0.0521, 0.0520, 0.0519, 0.0517, 0.0516, 0.0515, 0.0514,\n",
            "        0.0513, 0.0513, 0.0511, 0.0511, 0.0510, 0.0510, 0.0509, 0.0509, 0.0509,\n",
            "        0.0507, 0.0506, 0.0506, 0.0506, 0.0505, 0.0505, 0.0503, 0.0503, 0.0502,\n",
            "        0.0502, 0.0501], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1,\n",
            "        1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2,\n",
            "        2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2,\n",
            "        2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2], device='cuda:0')}]\n",
            "[{'boxes': tensor([[1.5700e+02, 5.1789e+00, 1.8486e+02, 3.3340e+01],\n",
            "        [6.9925e+01, 1.4343e+02, 9.7804e+01, 1.7162e+02],\n",
            "        [1.4678e+02, 5.2012e+00, 1.7465e+02, 3.3372e+01],\n",
            "        [1.6716e+02, 5.1467e+00, 1.9506e+02, 3.3336e+01],\n",
            "        [5.9697e+01, 1.4342e+02, 8.7589e+01, 1.7161e+02],\n",
            "        [1.7741e+02, 7.9889e-02, 2.0533e+02, 2.8278e+01],\n",
            "        [6.9925e+01, 1.3325e+02, 9.7827e+01, 1.6148e+02],\n",
            "        [1.5172e+02, 1.5371e+01, 1.7968e+02, 4.3614e+01],\n",
            "        [5.9698e+01, 1.3325e+02, 8.7603e+01, 1.6147e+02],\n",
            "        [7.9988e+01, 1.4342e+02, 1.0796e+02, 1.7169e+02],\n",
            "        [1.3644e+02, 5.1726e+00, 1.6439e+02, 3.3398e+01],\n",
            "        [1.5700e+02, 5.1789e+00, 1.8486e+02, 3.3340e+01],\n",
            "        [4.9403e+01, 1.3831e+02, 7.7344e+01, 1.6654e+02],\n",
            "        [6.9755e+01, 1.5359e+02, 9.7747e+01, 1.8185e+02],\n",
            "        [1.4147e+02, 1.5368e+01, 1.6946e+02, 4.3629e+01],\n",
            "        [8.0008e+01, 1.3322e+02, 1.0799e+02, 1.6152e+02],\n",
            "        [6.9925e+01, 1.4343e+02, 9.7804e+01, 1.7162e+02],\n",
            "        [1.6188e+02, 1.5362e+01, 1.8989e+02, 4.3646e+01],\n",
            "        [1.4678e+02, 5.2012e+00, 1.7465e+02, 3.3372e+01],\n",
            "        [1.6716e+02, 5.1467e+00, 1.9506e+02, 3.3336e+01],\n",
            "        [8.3403e+00, 1.9977e+02, 3.6323e+01, 2.2805e+02],\n",
            "        [1.8756e+02, 5.9811e-02, 2.1555e+02, 2.8305e+01],\n",
            "        [5.9697e+01, 1.4342e+02, 8.7589e+01, 1.7161e+02],\n",
            "        [5.9480e+01, 1.5356e+02, 8.7517e+01, 1.8185e+02],\n",
            "        [7.9914e+01, 1.5361e+02, 1.0795e+02, 1.8192e+02],\n",
            "        [4.9254e+01, 1.4845e+02, 7.7293e+01, 1.7675e+02],\n",
            "        [1.7715e+02, 1.0213e+01, 2.0522e+02, 3.8541e+01],\n",
            "        [1.7741e+02, 7.9889e-02, 2.0533e+02, 2.8278e+01],\n",
            "        [1.5172e+02, 1.5371e+01, 1.7968e+02, 4.3614e+01],\n",
            "        [6.9925e+01, 1.3325e+02, 9.7827e+01, 1.6148e+02],\n",
            "        [8.2540e+00, 2.0993e+02, 3.6298e+01, 2.3824e+02],\n",
            "        [3.9038e+01, 1.3827e+02, 6.7073e+01, 1.6658e+02],\n",
            "        [5.9698e+01, 1.3325e+02, 8.7603e+01, 1.6147e+02],\n",
            "        [1.4650e+02, 1.8949e+02, 1.7456e+02, 2.1781e+02],\n",
            "        [4.9327e+01, 1.2812e+02, 7.7336e+01, 1.5643e+02],\n",
            "        [7.9988e+01, 1.4342e+02, 1.0796e+02, 1.7169e+02],\n",
            "        [6.9755e+01, 1.5359e+02, 9.7747e+01, 1.8185e+02],\n",
            "        [1.9771e+02, 4.4060e-02, 2.2576e+02, 2.8347e+01],\n",
            "        [1.3644e+02, 5.1726e+00, 1.6439e+02, 3.3398e+01],\n",
            "        [1.4147e+02, 1.5368e+01, 1.6946e+02, 4.3629e+01],\n",
            "        [4.9403e+01, 1.3831e+02, 7.7344e+01, 1.6654e+02],\n",
            "        [1.2606e+02, 5.1071e+00, 1.5411e+02, 3.3409e+01],\n",
            "        [1.3625e+02, 1.8435e+02, 1.6432e+02, 2.1269e+02],\n",
            "        [1.5669e+02, 1.9460e+02, 1.8477e+02, 2.2295e+02],\n",
            "        [8.2588e+00, 1.8957e+02, 3.6321e+01, 2.1795e+02],\n",
            "        [1.6188e+02, 1.5362e+01, 1.8989e+02, 4.3646e+01],\n",
            "        [1.8427e+01, 2.0484e+02, 4.6508e+01, 2.3320e+02],\n",
            "        [1.3112e+02, 1.5318e+01, 1.5920e+02, 4.3657e+01],\n",
            "        [1.6205e+02, 0.0000e+00, 1.9014e+02, 2.3748e+01],\n",
            "        [8.0008e+01, 1.3322e+02, 1.0799e+02, 1.6152e+02],\n",
            "        [8.3403e+00, 1.9977e+02, 3.6323e+01, 2.2805e+02],\n",
            "        [1.8756e+02, 5.9811e-02, 2.1555e+02, 2.8305e+01],\n",
            "        [7.4876e+01, 1.2301e+02, 1.0292e+02, 1.5138e+02],\n",
            "        [5.9480e+01, 1.5356e+02, 8.7517e+01, 1.8185e+02],\n",
            "        [1.2598e+02, 1.7922e+02, 1.5408e+02, 2.0760e+02],\n",
            "        [7.9914e+01, 1.5361e+02, 1.0795e+02, 1.8192e+02],\n",
            "        [6.4639e+01, 1.2302e+02, 9.2687e+01, 1.5138e+02],\n",
            "        [1.4639e+02, 1.9966e+02, 1.7453e+02, 2.2804e+02],\n",
            "        [8.1542e+00, 5.1479e+00, 3.6294e+01, 3.3533e+01],\n",
            "        [4.9254e+01, 1.4845e+02, 7.7293e+01, 1.7675e+02],\n",
            "        [8.4983e+01, 1.2298e+02, 1.1309e+02, 1.5139e+02],\n",
            "        [1.4645e+02, 1.7930e+02, 1.7455e+02, 2.0769e+02],\n",
            "        [1.1570e+02, 5.0965e+00, 1.4382e+02, 3.3462e+01],\n",
            "        [3.8869e+01, 1.4840e+02, 6.7018e+01, 1.7679e+02],\n",
            "        [1.7715e+02, 1.0213e+01, 2.0522e+02, 3.8541e+01],\n",
            "        [1.8727e+02, 1.0163e+01, 2.1544e+02, 3.8557e+01],\n",
            "        [3.8987e+01, 1.2808e+02, 6.7073e+01, 1.5645e+02],\n",
            "        [1.3620e+02, 1.7417e+02, 1.6431e+02, 2.0257e+02],\n",
            "        [1.4633e+02, 2.5525e+01, 1.7450e+02, 5.3922e+01],\n",
            "        [9.0033e+01, 1.5364e+02, 1.1817e+02, 1.8204e+02],\n",
            "        [1.7190e+02, 2.0459e+01, 2.0007e+02, 4.8881e+01],\n",
            "        [1.8378e+01, 1.9464e+02, 4.6502e+01, 2.2306e+02],\n",
            "        [2.0784e+02, 5.6125e-02, 2.3597e+02, 2.8435e+01],\n",
            "        [1.3615e+02, 1.9451e+02, 1.6430e+02, 2.2291e+02],\n",
            "        [1.5178e+02, 0.0000e+00, 1.7990e+02, 2.3794e+01],\n",
            "        [1.5667e+02, 1.8441e+02, 1.8478e+02, 2.1282e+02],\n",
            "        [1.1567e+02, 1.7919e+02, 1.4382e+02, 2.0760e+02],\n",
            "        [8.9970e+01, 1.3316e+02, 1.1813e+02, 1.6160e+02],\n",
            "        [8.2540e+00, 2.0993e+02, 3.6298e+01, 2.3824e+02],\n",
            "        [2.3482e+01, 2.1503e+02, 5.1637e+01, 2.4342e+02],\n",
            "        [8.9977e+01, 1.4340e+02, 1.1813e+02, 1.7182e+02],\n",
            "        [2.0270e+02, 1.0755e+02, 2.3085e+02, 1.3596e+02],\n",
            "        [1.5655e+02, 2.5522e+01, 1.8472e+02, 5.3923e+01],\n",
            "        [1.6682e+02, 1.9459e+02, 1.9498e+02, 2.2301e+02],\n",
            "        [8.1073e+00, 1.5381e+01, 3.6282e+01, 4.3806e+01],\n",
            "        [3.9038e+01, 1.3827e+02, 6.7073e+01, 1.6658e+02],\n",
            "        [2.0265e+02, 7.6828e+01, 2.3083e+02, 1.0527e+02],\n",
            "        [5.4039e+01, 1.2254e+02, 1.0624e+02, 1.7427e+02],\n",
            "        [8.4861e+01, 1.6378e+02, 1.1305e+02, 1.9220e+02],\n",
            "        [2.8660e+01, 1.3822e+02, 5.6802e+01, 1.6662e+02],\n",
            "        [1.4650e+02, 1.8949e+02, 1.7456e+02, 2.1781e+02],\n",
            "        [1.0538e+02, 1.7406e+02, 1.3356e+02, 2.0249e+02],\n",
            "        [1.5653e+02, 2.0476e+02, 1.8473e+02, 2.3320e+02],\n",
            "        [1.2586e+02, 1.8938e+02, 1.5404e+02, 2.1780e+02],\n",
            "        [1.9753e+02, 6.6606e+01, 2.2571e+02, 9.5054e+01],\n",
            "        [6.3643e+01, 1.3260e+02, 1.1613e+02, 1.8442e+02],\n",
            "        [9.5140e+01, 1.6384e+02, 1.2331e+02, 1.9227e+02],\n",
            "        [2.0777e+02, 8.7067e+01, 2.3595e+02, 1.1551e+02],\n",
            "        [2.0778e+02, 9.7313e+01, 2.3596e+02, 1.2575e+02],\n",
            "        [7.4586e+01, 1.6373e+02, 1.0280e+02, 1.9215e+02],\n",
            "        [1.3608e+02, 2.5528e+01, 1.6427e+02, 5.3959e+01],\n",
            "        [1.9771e+02, 4.4060e-02, 2.2576e+02, 2.8347e+01],\n",
            "        [1.8320e+01, 5.1393e+00, 4.6499e+01, 3.3571e+01],\n",
            "        [8.9994e+01, 9.7304e+01, 1.1818e+02, 1.2574e+02],\n",
            "        [2.1286e+02, 1.1266e+02, 2.4105e+02, 1.4113e+02],\n",
            "        [1.2606e+02, 5.1071e+00, 1.5411e+02, 3.3409e+01],\n",
            "        [4.9327e+01, 1.2812e+02, 7.7336e+01, 1.5643e+02],\n",
            "        [1.3625e+02, 1.8435e+02, 1.6432e+02, 2.1269e+02],\n",
            "        [1.1567e+02, 1.6901e+02, 1.4382e+02, 1.9744e+02],\n",
            "        [1.5669e+02, 1.9460e+02, 1.8477e+02, 2.2295e+02],\n",
            "        [1.3112e+02, 1.5318e+01, 1.5920e+02, 4.3657e+01],\n",
            "        [8.4894e+01, 8.7073e+01, 1.1308e+02, 1.1552e+02],\n",
            "        [1.9245e+02, 1.0751e+02, 2.2062e+02, 1.3595e+02],\n",
            "        [1.2076e+02, 1.5294e+01, 1.4894e+02, 4.3721e+01],\n",
            "        [3.3654e+01, 2.1507e+02, 6.1862e+01, 2.4355e+02],\n",
            "        [2.0261e+02, 1.1772e+02, 2.3082e+02, 1.4616e+02],\n",
            "        [1.8427e+01, 2.0484e+02, 4.6508e+01, 2.3320e+02],\n",
            "        [1.9756e+02, 9.7298e+01, 2.2574e+02, 1.2574e+02],\n",
            "        [1.2591e+02, 1.6902e+02, 1.5407e+02, 1.9746e+02],\n",
            "        [2.8531e+01, 2.0486e+02, 5.6728e+01, 2.3334e+02],\n",
            "        [4.3388e+01, 1.3219e+02, 9.5904e+01, 1.8400e+02],\n",
            "        [8.2588e+00, 1.8957e+02, 3.6321e+01, 2.1795e+02],\n",
            "        [1.0537e+02, 5.0648e+00, 1.3356e+02, 3.3490e+01],\n",
            "        [6.4122e+01, 1.1264e+02, 1.1643e+02, 1.6474e+02],\n",
            "        [1.0538e+02, 1.6389e+02, 1.3356e+02, 1.9234e+02],\n",
            "        [1.8253e+01, 1.5376e+01, 4.6465e+01, 4.3846e+01],\n",
            "        [8.0325e+00, 2.5595e+01, 3.6259e+01, 5.4065e+01],\n",
            "        [7.4645e+01, 8.1923e+01, 1.0284e+02, 1.1038e+02],\n",
            "        [7.3824e+01, 1.2279e+02, 1.2634e+02, 1.7494e+02],\n",
            "        [1.4145e+02, 0.0000e+00, 1.6963e+02, 2.3830e+01],\n",
            "        [1.9752e+02, 8.7024e+01, 2.2573e+02, 1.1549e+02],\n",
            "        [8.9957e+01, 1.0754e+02, 1.1817e+02, 1.3601e+02],\n",
            "        [6.4311e+01, 1.6370e+02, 9.2558e+01, 1.9216e+02],\n",
            "        [1.9744e+02, 1.0115e+01, 2.2566e+02, 3.8549e+01],\n",
            "        [4.8972e+01, 1.5858e+02, 7.7217e+01, 1.8704e+02],\n",
            "        [2.1788e+02, 5.1262e+00, 2.4613e+02, 3.3617e+01],\n",
            "        [8.0085e+00, 2.2001e+02, 3.6255e+01, 2.4846e+02],\n",
            "        [1.9237e+02, 7.6744e+01, 2.2060e+02, 1.0521e+02],\n",
            "        [1.2598e+02, 1.7922e+02, 1.5408e+02, 2.0760e+02],\n",
            "        [1.4639e+02, 1.9966e+02, 1.7453e+02, 2.2804e+02],\n",
            "        [7.4876e+01, 1.2301e+02, 1.0292e+02, 1.5138e+02],\n",
            "        [2.1278e+02, 1.2285e+02, 2.4103e+02, 1.5135e+02],\n",
            "        [1.6670e+02, 2.0475e+02, 1.9495e+02, 2.3323e+02],\n",
            "        [8.1542e+00, 5.1479e+00, 3.6294e+01, 3.3533e+01],\n",
            "        [3.8869e+01, 1.4840e+02, 6.7018e+01, 1.7679e+02],\n",
            "        [1.8725e+02, 6.1425e+01, 2.1548e+02, 8.9904e+01],\n",
            "        [1.0019e+02, 9.7290e+01, 1.2841e+02, 1.2576e+02],\n",
            "        [5.2983e+01, 1.4222e+02, 1.0583e+02, 1.9430e+02],\n",
            "        [1.6682e+02, 1.8438e+02, 1.9501e+02, 2.1285e+02],\n",
            "        [2.8622e+01, 1.2802e+02, 5.6805e+01, 1.5647e+02],\n",
            "        [2.1282e+02, 7.6849e+01, 2.4105e+02, 1.0534e+02],\n",
            "        [1.4624e+02, 2.0986e+02, 1.7449e+02, 2.3835e+02],\n",
            "        [1.5652e+02, 1.0752e+02, 1.8474e+02, 1.3600e+02],\n",
            "        [4.3937e+01, 1.1234e+02, 9.6140e+01, 1.6438e+02],\n",
            "        [1.8727e+02, 1.0163e+01, 2.1544e+02, 3.8557e+01],\n",
            "        [2.1789e+02, 9.2192e+01, 2.4614e+02, 1.2070e+02],\n",
            "        [1.4633e+02, 2.5525e+01, 1.7450e+02, 5.3922e+01],\n",
            "        [1.1570e+02, 5.0965e+00, 1.4382e+02, 3.3462e+01],\n",
            "        [2.8533e+01, 1.4839e+02, 5.6757e+01, 1.7685e+02],\n",
            "        [1.6205e+02, 0.0000e+00, 1.9014e+02, 2.3748e+01],\n",
            "        [2.0765e+02, 1.0120e+01, 2.3590e+02, 3.8574e+01],\n",
            "        [3.3425e+01, 1.2217e+02, 8.5822e+01, 1.7410e+02],\n",
            "        [9.5086e+01, 8.7089e+01, 1.2330e+02, 1.1558e+02],\n",
            "        [1.2580e+02, 2.5536e+01, 1.5404e+02, 5.4017e+01],\n",
            "        [6.4639e+01, 1.2302e+02, 9.2687e+01, 1.5138e+02],\n",
            "        [1.4562e+02, 0.0000e+00, 1.9825e+02, 5.1724e+01],\n",
            "        [1.5651e+02, 9.7282e+01, 1.8474e+02, 1.2576e+02],\n",
            "        [2.1788e+02, 1.0243e+02, 2.4614e+02, 1.3095e+02],\n",
            "        [8.4983e+01, 1.2298e+02, 1.1309e+02, 1.5139e+02],\n",
            "        [9.5029e+01, 1.7397e+02, 1.2329e+02, 2.0245e+02],\n",
            "        [1.3091e+02, 9.7270e+01, 1.5915e+02, 1.2576e+02],\n",
            "        [8.0718e+00, 1.7928e+02, 3.6279e+01, 2.0778e+02],\n",
            "        [1.4645e+02, 1.7930e+02, 1.7455e+02, 2.0769e+02],\n",
            "        [1.4629e+02, 1.0750e+02, 1.7451e+02, 1.3598e+02],\n",
            "        [1.7190e+02, 2.0459e+01, 2.0007e+02, 4.8881e+01],\n",
            "        [7.3320e+01, 1.4262e+02, 1.2613e+02, 1.9480e+02],\n",
            "        [1.3495e+02, 9.2410e+00, 1.8783e+02, 6.1410e+01],\n",
            "        [1.3615e+02, 1.9451e+02, 1.6430e+02, 2.2291e+02],\n",
            "        [7.9717e+01, 9.7215e+01, 1.0794e+02, 1.2567e+02]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0692, 0.0681, 0.0680, 0.0675, 0.0667, 0.0651, 0.0650, 0.0642, 0.0641,\n",
            "        0.0634, 0.0632, 0.0630, 0.0630, 0.0628, 0.0626, 0.0620, 0.0619, 0.0619,\n",
            "        0.0619, 0.0617, 0.0616, 0.0615, 0.0608, 0.0605, 0.0605, 0.0599, 0.0594,\n",
            "        0.0592, 0.0589, 0.0589, 0.0588, 0.0585, 0.0581, 0.0581, 0.0579, 0.0578,\n",
            "        0.0578, 0.0578, 0.0576, 0.0575, 0.0574, 0.0574, 0.0572, 0.0571, 0.0571,\n",
            "        0.0569, 0.0568, 0.0568, 0.0566, 0.0563, 0.0562, 0.0561, 0.0561, 0.0558,\n",
            "        0.0556, 0.0555, 0.0554, 0.0552, 0.0552, 0.0552, 0.0551, 0.0550, 0.0548,\n",
            "        0.0548, 0.0547, 0.0545, 0.0545, 0.0545, 0.0545, 0.0544, 0.0543, 0.0543,\n",
            "        0.0543, 0.0542, 0.0542, 0.0542, 0.0541, 0.0541, 0.0541, 0.0541, 0.0540,\n",
            "        0.0539, 0.0538, 0.0536, 0.0536, 0.0536, 0.0535, 0.0534, 0.0534, 0.0532,\n",
            "        0.0532, 0.0531, 0.0531, 0.0531, 0.0531, 0.0530, 0.0530, 0.0530, 0.0529,\n",
            "        0.0529, 0.0528, 0.0528, 0.0527, 0.0527, 0.0526, 0.0526, 0.0526, 0.0524,\n",
            "        0.0523, 0.0523, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0521, 0.0520,\n",
            "        0.0519, 0.0519, 0.0519, 0.0519, 0.0518, 0.0518, 0.0517, 0.0516, 0.0516,\n",
            "        0.0515, 0.0515, 0.0515, 0.0515, 0.0514, 0.0514, 0.0512, 0.0512, 0.0511,\n",
            "        0.0511, 0.0511, 0.0511, 0.0509, 0.0509, 0.0509, 0.0509, 0.0508, 0.0507,\n",
            "        0.0506, 0.0506, 0.0506, 0.0506, 0.0506, 0.0506, 0.0506, 0.0506, 0.0505,\n",
            "        0.0505, 0.0505, 0.0505, 0.0505, 0.0505, 0.0505, 0.0504, 0.0504, 0.0503,\n",
            "        0.0503, 0.0502, 0.0502, 0.0502, 0.0502, 0.0502, 0.0502, 0.0502, 0.0502,\n",
            "        0.0502, 0.0502, 0.0501, 0.0501, 0.0501, 0.0500, 0.0500, 0.0500],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2,\n",
            "        2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2,\n",
            "        2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1,\n",
            "        2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
            "        1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1,\n",
            "        1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2,\n",
            "        1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2], device='cuda:0')}, {'boxes': tensor([[7.5116e+01, 8.3773e-02, 1.0296e+02, 2.8212e+01],\n",
            "        [6.4869e+01, 6.9436e-02, 9.2747e+01, 2.8222e+01],\n",
            "        [1.6205e+02, 1.0248e+02, 1.8997e+02, 1.3071e+02],\n",
            "        ...,\n",
            "        [6.3654e+01, 8.1482e+01, 1.1621e+02, 1.3361e+02],\n",
            "        [3.3647e+01, 5.0847e+01, 8.5880e+01, 1.0281e+02],\n",
            "        [5.3578e+01, 1.5285e+02, 1.0608e+02, 2.0481e+02]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0699, 0.0668, 0.0655, 0.0654, 0.0647, 0.0646, 0.0643, 0.0641, 0.0635,\n",
            "        0.0634, 0.0634, 0.0632, 0.0627, 0.0626, 0.0626, 0.0626, 0.0623, 0.0620,\n",
            "        0.0618, 0.0618, 0.0618, 0.0616, 0.0615, 0.0615, 0.0614, 0.0614, 0.0610,\n",
            "        0.0610, 0.0609, 0.0609, 0.0608, 0.0608, 0.0608, 0.0608, 0.0608, 0.0608,\n",
            "        0.0605, 0.0605, 0.0604, 0.0604, 0.0604, 0.0603, 0.0603, 0.0603, 0.0602,\n",
            "        0.0602, 0.0601, 0.0601, 0.0600, 0.0600, 0.0600, 0.0599, 0.0599, 0.0599,\n",
            "        0.0598, 0.0598, 0.0597, 0.0597, 0.0596, 0.0596, 0.0596, 0.0596, 0.0595,\n",
            "        0.0595, 0.0595, 0.0594, 0.0594, 0.0593, 0.0593, 0.0592, 0.0591, 0.0590,\n",
            "        0.0590, 0.0589, 0.0589, 0.0589, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588,\n",
            "        0.0587, 0.0587, 0.0587, 0.0587, 0.0587, 0.0587, 0.0586, 0.0586, 0.0586,\n",
            "        0.0586, 0.0585, 0.0584, 0.0584, 0.0583, 0.0583, 0.0583, 0.0583, 0.0583,\n",
            "        0.0583, 0.0583, 0.0581, 0.0580, 0.0580, 0.0580, 0.0579, 0.0579, 0.0579,\n",
            "        0.0579, 0.0579, 0.0579, 0.0579, 0.0578, 0.0578, 0.0578, 0.0578, 0.0578,\n",
            "        0.0578, 0.0577, 0.0577, 0.0577, 0.0576, 0.0576, 0.0575, 0.0575, 0.0574,\n",
            "        0.0574, 0.0574, 0.0574, 0.0573, 0.0573, 0.0573, 0.0572, 0.0572, 0.0572,\n",
            "        0.0572, 0.0572, 0.0572, 0.0570, 0.0570, 0.0570, 0.0569, 0.0569, 0.0569,\n",
            "        0.0569, 0.0569, 0.0568, 0.0568, 0.0567, 0.0567, 0.0567, 0.0567, 0.0567,\n",
            "        0.0566, 0.0566, 0.0566, 0.0566, 0.0566, 0.0566, 0.0565, 0.0564, 0.0564,\n",
            "        0.0564, 0.0563, 0.0563, 0.0563, 0.0563, 0.0562, 0.0562, 0.0561, 0.0561,\n",
            "        0.0561, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
            "        0.0560, 0.0560, 0.0559, 0.0559, 0.0558, 0.0558, 0.0558, 0.0558, 0.0558,\n",
            "        0.0558, 0.0557, 0.0557, 0.0557, 0.0557, 0.0557, 0.0557, 0.0556, 0.0556,\n",
            "        0.0556, 0.0556, 0.0556, 0.0556, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555,\n",
            "        0.0554, 0.0553, 0.0553, 0.0553, 0.0553, 0.0552, 0.0552, 0.0552, 0.0552,\n",
            "        0.0552, 0.0551, 0.0551, 0.0551, 0.0551, 0.0550, 0.0550, 0.0550, 0.0550,\n",
            "        0.0550, 0.0550, 0.0550, 0.0550, 0.0550, 0.0549, 0.0548, 0.0548, 0.0548,\n",
            "        0.0548, 0.0548, 0.0548, 0.0548, 0.0547, 0.0547, 0.0547, 0.0547, 0.0547,\n",
            "        0.0547, 0.0547, 0.0547, 0.0547, 0.0546, 0.0546, 0.0546, 0.0546, 0.0545,\n",
            "        0.0545, 0.0545, 0.0545, 0.0545, 0.0545, 0.0545, 0.0544, 0.0544, 0.0544,\n",
            "        0.0544, 0.0543, 0.0542, 0.0540, 0.0539, 0.0538, 0.0538, 0.0537, 0.0534,\n",
            "        0.0532, 0.0532, 0.0532, 0.0531, 0.0529, 0.0529, 0.0528, 0.0528, 0.0527,\n",
            "        0.0527, 0.0527, 0.0527, 0.0527, 0.0527, 0.0526, 0.0526, 0.0525, 0.0525,\n",
            "        0.0524, 0.0524, 0.0524, 0.0523, 0.0523, 0.0522, 0.0521, 0.0520, 0.0520,\n",
            "        0.0520, 0.0519, 0.0519], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2,\n",
            "        1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2,\n",
            "        2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2,\n",
            "        2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1,\n",
            "        1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1,\n",
            "        2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2,\n",
            "        2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1,\n",
            "        1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1,\n",
            "        2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2,\n",
            "        1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')}, {'boxes': tensor([[1.7221e+02, 2.1509e+02, 2.0020e+02, 2.4337e+02],\n",
            "        [1.3122e+02, 1.6390e+02, 1.5922e+02, 1.9219e+02],\n",
            "        [1.6199e+02, 2.1509e+02, 1.8997e+02, 2.4336e+02],\n",
            "        [1.3633e+02, 1.5369e+02, 1.6434e+02, 1.8200e+02],\n",
            "        [1.5172e+02, 2.1509e+02, 1.7972e+02, 2.4338e+02],\n",
            "        [1.2098e+02, 1.6389e+02, 1.4899e+02, 1.9219e+02],\n",
            "        [1.8233e+02, 2.1507e+02, 2.1038e+02, 2.4340e+02],\n",
            "        [1.4136e+02, 1.6389e+02, 1.6941e+02, 1.9223e+02],\n",
            "        [1.2612e+02, 1.5369e+02, 1.5412e+02, 1.8199e+02],\n",
            "        [1.3113e+02, 1.7410e+02, 1.5919e+02, 2.0244e+02],\n",
            "        [1.6705e+02, 2.0489e+02, 1.9507e+02, 2.3320e+02],\n",
            "        [1.5680e+02, 2.0488e+02, 1.8482e+02, 2.3319e+02],\n",
            "        [1.2090e+02, 1.7410e+02, 1.4896e+02, 2.0243e+02],\n",
            "        [1.7726e+02, 2.0490e+02, 2.0529e+02, 2.3323e+02],\n",
            "        [1.5676e+02, 1.9462e+02, 1.8480e+02, 2.2296e+02],\n",
            "        [1.4133e+02, 1.7412e+02, 1.6941e+02, 2.0248e+02],\n",
            "        [1.4653e+02, 2.0486e+02, 1.7457e+02, 2.3320e+02],\n",
            "        [1.4142e+02, 2.1507e+02, 1.6947e+02, 2.4340e+02],\n",
            "        [1.6698e+02, 1.9463e+02, 1.9503e+02, 2.2297e+02],\n",
            "        [1.4650e+02, 1.9461e+02, 1.7456e+02, 2.2295e+02],\n",
            "        [1.4643e+02, 1.5366e+02, 1.7452e+02, 1.8204e+02],\n",
            "        [1.1067e+02, 1.6899e+02, 1.3874e+02, 1.9733e+02],\n",
            "        [1.4647e+02, 1.8437e+02, 1.7456e+02, 2.1273e+02],\n",
            "        [1.3628e+02, 1.4346e+02, 1.6434e+02, 1.7182e+02],\n",
            "        [1.3620e+02, 1.8433e+02, 1.6431e+02, 2.1271e+02],\n",
            "        [1.5672e+02, 1.8439e+02, 1.8480e+02, 2.1276e+02],\n",
            "        [1.3122e+02, 1.6390e+02, 1.5922e+02, 1.9219e+02],\n",
            "        [1.7221e+02, 2.1509e+02, 2.0020e+02, 2.4337e+02],\n",
            "        [1.1060e+02, 1.7920e+02, 1.3871e+02, 2.0758e+02],\n",
            "        [1.1580e+02, 1.5365e+02, 1.4387e+02, 1.8200e+02],\n",
            "        [1.6199e+02, 2.1509e+02, 1.8997e+02, 2.4336e+02],\n",
            "        [1.4643e+02, 1.4343e+02, 1.7453e+02, 1.7183e+02],\n",
            "        [1.7717e+02, 1.9463e+02, 2.0526e+02, 2.2301e+02],\n",
            "        [1.2593e+02, 1.8431e+02, 1.5406e+02, 2.1270e+02],\n",
            "        [1.0036e+02, 1.7410e+02, 1.2848e+02, 2.0249e+02],\n",
            "        [1.3620e+02, 1.9457e+02, 1.6432e+02, 2.2296e+02],\n",
            "        [1.6693e+02, 1.8439e+02, 1.9503e+02, 2.1278e+02],\n",
            "        [1.3633e+02, 1.5369e+02, 1.6434e+02, 1.8200e+02],\n",
            "        [1.8736e+02, 2.0488e+02, 2.1548e+02, 2.3330e+02],\n",
            "        [1.3621e+02, 2.0482e+02, 1.6432e+02, 2.3320e+02],\n",
            "        [1.5172e+02, 2.1509e+02, 1.7972e+02, 2.4338e+02],\n",
            "        [1.2098e+02, 1.6389e+02, 1.4899e+02, 1.9219e+02],\n",
            "        [1.5152e+02, 1.7413e+02, 1.7965e+02, 2.0253e+02],\n",
            "        [1.2602e+02, 1.4343e+02, 1.5411e+02, 1.7181e+02],\n",
            "        [1.0031e+02, 1.8432e+02, 1.2845e+02, 2.1273e+02],\n",
            "        [1.3113e+02, 1.7410e+02, 1.5919e+02, 2.0244e+02],\n",
            "        [1.4136e+02, 1.6389e+02, 1.6941e+02, 1.9223e+02],\n",
            "        [1.8233e+02, 2.1507e+02, 2.1038e+02, 2.4340e+02],\n",
            "        [1.6660e+02, 2.2485e+02, 1.9496e+02, 2.5334e+02],\n",
            "        [1.5146e+02, 1.6387e+02, 1.7961e+02, 1.9229e+02],\n",
            "        [1.2612e+02, 1.5369e+02, 1.5412e+02, 1.8199e+02],\n",
            "        [1.0036e+02, 1.6386e+02, 1.2849e+02, 1.9227e+02],\n",
            "        [1.8736e+02, 5.5286e-03, 2.1551e+02, 2.8395e+01],\n",
            "        [9.0078e+01, 1.7409e+02, 1.1823e+02, 2.0250e+02],\n",
            "        [1.2575e+02, 1.5332e+02, 1.7792e+02, 2.0512e+02],\n",
            "        [1.5641e+02, 2.2486e+02, 1.8474e+02, 2.5334e+02],\n",
            "        [1.6705e+02, 2.0489e+02, 1.9507e+02, 2.3320e+02],\n",
            "        [1.5680e+02, 2.0488e+02, 1.8482e+02, 2.3319e+02],\n",
            "        [1.7713e+02, 2.7100e-03, 2.0528e+02, 2.8398e+01],\n",
            "        [1.2090e+02, 1.7410e+02, 1.4896e+02, 2.0243e+02],\n",
            "        [1.3594e+02, 1.6357e+02, 1.8814e+02, 2.1545e+02],\n",
            "        [9.0049e+01, 1.8431e+02, 1.1822e+02, 2.1274e+02],\n",
            "        [1.1545e+02, 1.6324e+02, 1.6770e+02, 2.1503e+02],\n",
            "        [1.7712e+02, 1.8438e+02, 2.0526e+02, 2.1280e+02],\n",
            "        [1.4614e+02, 1.7374e+02, 1.9841e+02, 2.2565e+02],\n",
            "        [1.7726e+02, 2.0490e+02, 2.0529e+02, 2.3323e+02],\n",
            "        [1.1050e+02, 1.8941e+02, 1.3868e+02, 2.1785e+02],\n",
            "        [1.4638e+02, 1.3318e+02, 1.7454e+02, 1.6161e+02],\n",
            "        [1.5676e+02, 1.9462e+02, 1.8480e+02, 2.2296e+02],\n",
            "        [1.4616e+02, 2.2488e+02, 1.7450e+02, 2.5336e+02],\n",
            "        [1.2558e+02, 1.7336e+02, 1.7792e+02, 2.2523e+02],\n",
            "        [1.1564e+02, 1.4308e+02, 1.6779e+02, 1.9492e+02],\n",
            "        [1.9234e+02, 2.1504e+02, 2.2054e+02, 2.4349e+02],\n",
            "        [1.9755e+02, 4.6057e-03, 2.2573e+02, 2.8418e+01],\n",
            "        [1.0534e+02, 1.5309e+02, 1.5755e+02, 2.0489e+02],\n",
            "        [7.9798e+01, 1.7407e+02, 1.0797e+02, 2.0251e+02],\n",
            "        [1.4133e+02, 1.7412e+02, 1.6941e+02, 2.0248e+02],\n",
            "        [1.3105e+02, 2.1500e+02, 1.5921e+02, 2.4341e+02],\n",
            "        [9.0068e+01, 1.6386e+02, 1.1823e+02, 1.9229e+02],\n",
            "        [3.3699e+01, 1.7408e+02, 6.1884e+01, 2.0253e+02],\n",
            "        [1.4653e+02, 2.0486e+02, 1.7457e+02, 2.3320e+02],\n",
            "        [1.2588e+02, 1.9453e+02, 1.5405e+02, 2.2296e+02],\n",
            "        [2.1291e+02, 1.6898e+02, 2.4109e+02, 1.9743e+02],\n",
            "        [1.8730e+02, 1.9462e+02, 2.1547e+02, 2.2306e+02],\n",
            "        [2.3459e+01, 1.7407e+02, 5.1644e+01, 2.0252e+02],\n",
            "        [1.4142e+02, 2.1507e+02, 1.6947e+02, 2.4340e+02],\n",
            "        [1.4650e+02, 1.9461e+02, 1.7456e+02, 2.2295e+02],\n",
            "        [9.5112e+01, 1.9454e+02, 1.2331e+02, 2.2300e+02],\n",
            "        [1.6698e+02, 1.9463e+02, 1.9503e+02, 2.2297e+02],\n",
            "        [1.3577e+02, 1.4325e+02, 1.8806e+02, 1.9527e+02],\n",
            "        [1.3220e+01, 1.6896e+02, 4.1409e+01, 1.9741e+02],\n",
            "        [1.0546e+02, 1.5362e+02, 1.3361e+02, 1.8204e+02],\n",
            "        [4.3930e+01, 1.7408e+02, 7.2122e+01, 2.0253e+02],\n",
            "        [1.6686e+02, 2.3743e-03, 1.9504e+02, 2.8424e+01],\n",
            "        [1.4643e+02, 1.5366e+02, 1.7452e+02, 1.8204e+02],\n",
            "        [1.7675e+02, 2.2480e+02, 2.0517e+02, 2.5335e+02],\n",
            "        [1.1067e+02, 1.6899e+02, 1.3874e+02, 1.9733e+02],\n",
            "        [7.9793e+01, 1.6385e+02, 1.0797e+02, 1.9230e+02],\n",
            "        [6.9533e+01, 1.7407e+02, 9.7723e+01, 2.0252e+02],\n",
            "        [2.3463e+01, 1.6385e+02, 5.1648e+01, 1.9230e+02],\n",
            "        [1.4134e+02, 1.8435e+02, 1.6943e+02, 2.1272e+02],\n",
            "        [3.3694e+01, 1.6386e+02, 6.1884e+01, 1.9231e+02],\n",
            "        [7.9769e+01, 1.8430e+02, 1.0797e+02, 2.1275e+02],\n",
            "        [1.3616e+02, 1.3318e+02, 1.6432e+02, 1.6162e+02],\n",
            "        [1.6172e+02, 1.7413e+02, 1.8989e+02, 2.0257e+02],\n",
            "        [8.4881e+01, 1.9455e+02, 1.1308e+02, 2.2300e+02],\n",
            "        [1.4594e+02, 1.5348e+02, 1.9827e+02, 2.0560e+02],\n",
            "        [2.0265e+02, 1.7407e+02, 2.3085e+02, 2.0253e+02],\n",
            "        [1.3207e+01, 1.5873e+02, 4.1405e+01, 1.8720e+02],\n",
            "        [5.4165e+01, 1.7407e+02, 8.2362e+01, 2.0253e+02],\n",
            "        [3.3648e+01, 1.8429e+02, 6.1868e+01, 2.1277e+02],\n",
            "        [1.5580e+02, 1.8358e+02, 2.0847e+02, 2.3562e+02],\n",
            "        [1.3628e+02, 1.4346e+02, 1.6434e+02, 1.7182e+02],\n",
            "        [1.3183e+01, 1.7917e+02, 4.1399e+01, 2.0764e+02],\n",
            "        [1.3552e+02, 1.8325e+02, 1.8813e+02, 2.3523e+02],\n",
            "        [1.5654e+02, 1.3826e+02, 1.8474e+02, 1.6673e+02],\n",
            "        [1.5160e+02, 1.8438e+02, 1.7968e+02, 2.1274e+02],\n",
            "        [9.4793e+01, 1.6313e+02, 1.4721e+02, 2.1506e+02],\n",
            "        [1.5652e+02, 1.4850e+02, 1.8472e+02, 1.7697e+02],\n",
            "        [1.2568e+02, 1.3301e+02, 1.7794e+02, 1.8507e+02],\n",
            "        [4.3919e+01, 1.6385e+02, 7.2120e+01, 1.9232e+02],\n",
            "        [1.3107e+02, 1.8432e+02, 1.5918e+02, 2.1270e+02],\n",
            "        [1.1568e+02, 1.4339e+02, 1.4385e+02, 1.7183e+02],\n",
            "        [1.8730e+02, 1.8435e+02, 2.1548e+02, 2.1280e+02],\n",
            "        [1.5621e+02, 1.6373e+02, 2.0856e+02, 2.1590e+02],\n",
            "        [2.3406e+01, 1.8428e+02, 5.1631e+01, 2.1276e+02],\n",
            "        [1.0480e+02, 1.7310e+02, 1.5736e+02, 2.2510e+02],\n",
            "        [4.3877e+01, 1.8429e+02, 7.2102e+01, 2.1277e+02],\n",
            "        [6.9530e+01, 1.6385e+02, 9.7729e+01, 1.9231e+02],\n",
            "        [2.1284e+02, 1.7916e+02, 2.4106e+02, 2.0763e+02],\n",
            "        [1.1060e+02, 1.7920e+02, 1.3871e+02, 2.0758e+02],\n",
            "        [1.5655e+02, 1.2803e+02, 1.8475e+02, 1.5650e+02],\n",
            "        [1.2587e+02, 2.0477e+02, 1.5406e+02, 2.3322e+02],\n",
            "        [1.6619e+02, 1.7382e+02, 2.1873e+02, 2.2601e+02],\n",
            "        [1.6183e+02, 1.8440e+02, 1.8991e+02, 2.1277e+02],\n",
            "        [1.1580e+02, 1.5365e+02, 1.4387e+02, 1.8200e+02],\n",
            "        [6.9488e+01, 1.8429e+02, 9.7712e+01, 2.1277e+02],\n",
            "        [5.4152e+01, 1.6385e+02, 8.2363e+01, 1.9232e+02],\n",
            "        [1.4643e+02, 1.4343e+02, 1.7453e+02, 1.7183e+02],\n",
            "        [1.7717e+02, 1.9463e+02, 2.0526e+02, 2.2301e+02],\n",
            "        [9.5034e+01, 1.4291e+02, 1.4732e+02, 1.9493e+02],\n",
            "        [1.3620e+02, 1.9457e+02, 1.6432e+02, 2.2296e+02],\n",
            "        [1.2080e+02, 1.8430e+02, 1.4893e+02, 2.1270e+02],\n",
            "        [1.0036e+02, 1.7410e+02, 1.2848e+02, 2.0249e+02],\n",
            "        [8.4602e+01, 1.5304e+02, 1.3700e+02, 2.0509e+02],\n",
            "        [7.4610e+01, 1.9454e+02, 1.0284e+02, 2.2302e+02],\n",
            "        [5.4108e+01, 1.8428e+02, 8.2340e+01, 2.1276e+02],\n",
            "        [7.9720e+01, 2.0479e+02, 1.0795e+02, 2.3327e+02],\n",
            "        [1.5657e+02, 1.1743e-03, 1.8479e+02, 2.8461e+01],\n",
            "        [1.7192e+02, 1.7412e+02, 2.0012e+02, 2.0259e+02],\n",
            "        [1.9240e+02, 1.7408e+02, 2.2061e+02, 2.0256e+02],\n",
            "        [9.5135e+01, 1.5361e+02, 1.2334e+02, 1.8208e+02],\n",
            "        [1.0529e+02, 1.3281e+02, 1.5755e+02, 1.8491e+02],\n",
            "        [2.0263e+02, 1.6385e+02, 2.3086e+02, 1.9233e+02],\n",
            "        [1.0529e+02, 1.9963e+02, 1.3353e+02, 2.2813e+02],\n",
            "        [8.0380e+00, 1.4850e+02, 3.6278e+01, 1.7700e+02],\n",
            "        [1.8736e+02, 2.0488e+02, 2.1548e+02, 2.3330e+02],\n",
            "        [1.6660e+02, 2.2485e+02, 1.9496e+02, 2.5334e+02],\n",
            "        [1.3621e+02, 2.0482e+02, 1.6432e+02, 2.3320e+02],\n",
            "        [8.9928e+01, 2.0477e+02, 1.1817e+02, 2.3327e+02],\n",
            "        [2.3413e+01, 1.5361e+02, 5.1638e+01, 1.8210e+02],\n",
            "        [2.2289e+02, 1.6894e+02, 2.5120e+02, 1.9753e+02],\n",
            "        [1.9746e+02, 1.8430e+02, 2.2569e+02, 2.1278e+02],\n",
            "        [1.0031e+02, 1.8432e+02, 1.2845e+02, 2.1273e+02],\n",
            "        [1.1555e+02, 1.9963e+02, 1.4379e+02, 2.2811e+02],\n",
            "        [1.5641e+02, 2.2486e+02, 1.8474e+02, 2.5334e+02],\n",
            "        [7.4076e+01, 1.6316e+02, 1.2664e+02, 2.1531e+02],\n",
            "        [2.1285e+02, 1.5875e+02, 2.4108e+02, 1.8724e+02],\n",
            "        [6.9476e+01, 2.0478e+02, 9.7715e+01, 2.3328e+02],\n",
            "        [2.0768e+02, 0.0000e+00, 2.3593e+02, 2.8471e+01],\n",
            "        [1.4564e+02, 1.3296e+02, 1.9818e+02, 1.8527e+02],\n",
            "        [1.5152e+02, 1.7413e+02, 1.7965e+02, 2.0253e+02],\n",
            "        [1.8215e+02, 1.7410e+02, 2.1037e+02, 2.0258e+02],\n",
            "        [3.3641e+01, 1.5361e+02, 6.1875e+01, 1.8211e+02],\n",
            "        [8.4064e+01, 1.7313e+02, 1.3679e+02, 2.2531e+02],\n",
            "        [1.3583e+02, 2.2485e+02, 1.6425e+02, 2.5340e+02],\n",
            "        [8.4854e+01, 1.5361e+02, 1.1308e+02, 1.8210e+02],\n",
            "        [1.2602e+02, 1.4343e+02, 1.5411e+02, 1.7181e+02],\n",
            "        [1.3111e+01, 1.8939e+02, 4.1380e+01, 2.1790e+02]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0620, 0.0620, 0.0615, 0.0609, 0.0603, 0.0602, 0.0598, 0.0597, 0.0597,\n",
            "        0.0596, 0.0594, 0.0591, 0.0588, 0.0587, 0.0584, 0.0580, 0.0580, 0.0578,\n",
            "        0.0578, 0.0578, 0.0576, 0.0573, 0.0572, 0.0571, 0.0569, 0.0567, 0.0566,\n",
            "        0.0565, 0.0562, 0.0561, 0.0561, 0.0560, 0.0560, 0.0559, 0.0556, 0.0556,\n",
            "        0.0555, 0.0555, 0.0555, 0.0551, 0.0550, 0.0550, 0.0549, 0.0549, 0.0548,\n",
            "        0.0547, 0.0546, 0.0546, 0.0545, 0.0544, 0.0544, 0.0544, 0.0543, 0.0543,\n",
            "        0.0542, 0.0542, 0.0541, 0.0540, 0.0540, 0.0539, 0.0539, 0.0539, 0.0538,\n",
            "        0.0537, 0.0535, 0.0535, 0.0535, 0.0535, 0.0534, 0.0533, 0.0533, 0.0533,\n",
            "        0.0532, 0.0532, 0.0532, 0.0532, 0.0532, 0.0531, 0.0531, 0.0531, 0.0530,\n",
            "        0.0530, 0.0530, 0.0529, 0.0529, 0.0529, 0.0528, 0.0528, 0.0528, 0.0528,\n",
            "        0.0528, 0.0527, 0.0527, 0.0527, 0.0526, 0.0526, 0.0525, 0.0524, 0.0524,\n",
            "        0.0524, 0.0523, 0.0523, 0.0523, 0.0523, 0.0523, 0.0522, 0.0522, 0.0521,\n",
            "        0.0521, 0.0521, 0.0521, 0.0521, 0.0521, 0.0521, 0.0521, 0.0521, 0.0520,\n",
            "        0.0520, 0.0520, 0.0519, 0.0519, 0.0519, 0.0518, 0.0518, 0.0517, 0.0517,\n",
            "        0.0517, 0.0517, 0.0517, 0.0516, 0.0516, 0.0516, 0.0514, 0.0513, 0.0513,\n",
            "        0.0513, 0.0512, 0.0512, 0.0512, 0.0512, 0.0512, 0.0510, 0.0510, 0.0509,\n",
            "        0.0509, 0.0509, 0.0509, 0.0509, 0.0508, 0.0508, 0.0508, 0.0508, 0.0508,\n",
            "        0.0507, 0.0507, 0.0506, 0.0506, 0.0506, 0.0505, 0.0505, 0.0504, 0.0504,\n",
            "        0.0504, 0.0504, 0.0504, 0.0503, 0.0503, 0.0502, 0.0502, 0.0502, 0.0502,\n",
            "        0.0502, 0.0502, 0.0502, 0.0502, 0.0502, 0.0501, 0.0501, 0.0500],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1,\n",
            "        2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1,\n",
            "        2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2,\n",
            "        1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1,\n",
            "        2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1,\n",
            "        1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2,\n",
            "        2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2], device='cuda:0')}, {'boxes': tensor([[1.1106e+02, 2.1002e+02, 1.3882e+02, 2.3811e+02],\n",
            "        [1.2129e+02, 2.1002e+02, 1.4905e+02, 2.3811e+02],\n",
            "        [1.1617e+02, 1.9980e+02, 1.4393e+02, 2.2789e+02],\n",
            "        [1.2640e+02, 1.9979e+02, 1.5417e+02, 2.2789e+02],\n",
            "        [1.3149e+02, 2.1002e+02, 1.5927e+02, 2.3813e+02],\n",
            "        [1.0593e+02, 1.9981e+02, 1.3371e+02, 2.2793e+02],\n",
            "        [1.3658e+02, 1.9978e+02, 1.6438e+02, 2.2791e+02],\n",
            "        [1.0081e+02, 2.1002e+02, 1.2860e+02, 2.3814e+02],\n",
            "        [1.2126e+02, 1.8957e+02, 1.4905e+02, 2.1770e+02],\n",
            "        [1.3149e+02, 1.8957e+02, 1.5929e+02, 2.1770e+02],\n",
            "        [1.4171e+02, 1.8955e+02, 1.6952e+02, 2.1769e+02],\n",
            "        [1.1102e+02, 1.8958e+02, 1.3882e+02, 2.1771e+02],\n",
            "        [1.5190e+02, 1.8952e+02, 1.7973e+02, 2.1767e+02],\n",
            "        [1.1601e+02, 2.2012e+02, 1.4389e+02, 2.4826e+02],\n",
            "        [1.2624e+02, 2.2012e+02, 1.5412e+02, 2.4827e+02],\n",
            "        [1.4161e+02, 2.1000e+02, 1.6947e+02, 2.3818e+02],\n",
            "        [1.0575e+02, 2.2011e+02, 1.3365e+02, 2.4827e+02],\n",
            "        [1.4672e+02, 1.9975e+02, 1.7458e+02, 2.2793e+02],\n",
            "        [1.5192e+02, 1.7933e+02, 1.7976e+02, 2.0751e+02],\n",
            "        [1.3641e+02, 2.2012e+02, 1.6433e+02, 2.4830e+02],\n",
            "        [1.6203e+02, 1.8440e+02, 1.8992e+02, 2.1261e+02],\n",
            "        [1.1106e+02, 2.1002e+02, 1.3882e+02, 2.3811e+02],\n",
            "        [1.2129e+02, 2.1002e+02, 1.4905e+02, 2.3811e+02],\n",
            "        [1.1617e+02, 1.9980e+02, 1.4393e+02, 2.2789e+02],\n",
            "        [1.0071e+02, 1.8956e+02, 1.2858e+02, 2.1775e+02],\n",
            "        [1.2640e+02, 1.9979e+02, 1.5417e+02, 2.2789e+02],\n",
            "        [1.3149e+02, 2.1002e+02, 1.5927e+02, 2.3813e+02],\n",
            "        [1.4169e+02, 1.7934e+02, 1.6954e+02, 2.0754e+02],\n",
            "        [9.5588e+01, 1.9979e+02, 1.2347e+02, 2.2798e+02],\n",
            "        [1.0593e+02, 1.9981e+02, 1.3371e+02, 2.2793e+02],\n",
            "        [1.3658e+02, 1.9978e+02, 1.6438e+02, 2.2791e+02],\n",
            "        [1.0081e+02, 2.1002e+02, 1.2860e+02, 2.3814e+02],\n",
            "        [1.1602e+02, 1.7936e+02, 1.4392e+02, 2.0759e+02],\n",
            "        [1.2126e+02, 1.8957e+02, 1.4905e+02, 2.1770e+02],\n",
            "        [9.5439e+01, 2.2010e+02, 1.2341e+02, 2.4832e+02],\n",
            "        [1.3149e+02, 1.8957e+02, 1.5929e+02, 2.1770e+02],\n",
            "        [1.4171e+02, 1.8955e+02, 1.6952e+02, 2.1769e+02],\n",
            "        [1.6191e+02, 1.9459e+02, 1.8988e+02, 2.2285e+02],\n",
            "        [1.3141e+02, 1.7935e+02, 1.5929e+02, 2.0758e+02],\n",
            "        [1.1601e+02, 2.2012e+02, 1.4389e+02, 2.4826e+02],\n",
            "        [1.1102e+02, 1.8958e+02, 1.3882e+02, 2.1771e+02],\n",
            "        [1.5190e+02, 1.8952e+02, 1.7973e+02, 2.1767e+02],\n",
            "        [9.0441e+01, 2.1000e+02, 1.1834e+02, 2.3820e+02],\n",
            "        [1.2624e+02, 2.2012e+02, 1.5412e+02, 2.4827e+02],\n",
            "        [1.0577e+02, 1.7934e+02, 1.3368e+02, 2.0759e+02],\n",
            "        [1.0575e+02, 2.2011e+02, 1.3365e+02, 2.4827e+02],\n",
            "        [1.4161e+02, 2.1000e+02, 1.6947e+02, 2.3818e+02],\n",
            "        [1.1657e+02, 1.8386e+02, 1.6827e+02, 2.3480e+02],\n",
            "        [1.6197e+02, 1.7422e+02, 1.8994e+02, 2.0250e+02],\n",
            "        [1.4672e+02, 1.9975e+02, 1.7458e+02, 2.2793e+02],\n",
            "        [1.4648e+02, 2.2011e+02, 1.7451e+02, 2.4838e+02],\n",
            "        [1.3641e+02, 2.2012e+02, 1.6433e+02, 2.4830e+02],\n",
            "        [1.5165e+02, 2.0997e+02, 1.7964e+02, 2.3825e+02],\n",
            "        [1.2703e+02, 1.7431e+02, 1.7850e+02, 2.2537e+02],\n",
            "        [1.5192e+02, 1.7933e+02, 1.7976e+02, 2.0751e+02],\n",
            "        [9.5454e+01, 1.8440e+02, 1.2343e+02, 2.1266e+02],\n",
            "        [1.6203e+02, 1.8440e+02, 1.8992e+02, 2.1261e+02],\n",
            "        [1.0684e+02, 1.7416e+02, 1.5821e+02, 2.2524e+02],\n",
            "        [1.0071e+02, 1.8956e+02, 1.2858e+02, 2.1775e+02],\n",
            "        [1.5176e+02, 1.6911e+02, 1.7974e+02, 1.9741e+02],\n",
            "        [9.5588e+01, 1.9979e+02, 1.2347e+02, 2.2798e+02],\n",
            "        [1.4169e+02, 1.7934e+02, 1.6954e+02, 2.0754e+02],\n",
            "        [1.3588e+02, 1.8391e+02, 1.8812e+02, 2.3527e+02],\n",
            "        [9.5439e+01, 2.2010e+02, 1.2341e+02, 2.4832e+02],\n",
            "        [9.6102e+01, 1.8352e+02, 1.4789e+02, 2.3467e+02],\n",
            "        [9.0314e+01, 1.9461e+02, 1.1831e+02, 2.2289e+02],\n",
            "        [1.6191e+02, 1.9459e+02, 1.8988e+02, 2.2285e+02],\n",
            "        [1.1602e+02, 1.7936e+02, 1.4392e+02, 2.0759e+02],\n",
            "        [1.1694e+02, 1.6422e+02, 1.6837e+02, 2.1561e+02],\n",
            "        [9.0441e+01, 2.1000e+02, 1.1834e+02, 2.3820e+02],\n",
            "        [8.0031e+01, 2.1504e+02, 1.0806e+02, 2.4334e+02],\n",
            "        [1.3141e+02, 1.7935e+02, 1.5929e+02, 2.0758e+02],\n",
            "        [1.3680e+02, 1.6427e+02, 1.8851e+02, 2.1577e+02],\n",
            "        [1.4647e+02, 3.0758e+01, 1.7455e+02, 5.9114e+01],\n",
            "        [1.0577e+02, 1.7934e+02, 1.3368e+02, 2.0759e+02],\n",
            "        [1.7194e+02, 1.8437e+02, 2.0004e+02, 2.1275e+02],\n",
            "        [1.6173e+02, 2.0481e+02, 1.8983e+02, 2.3317e+02],\n",
            "        [1.4596e+02, 1.7423e+02, 1.9820e+02, 2.2587e+02],\n",
            "        [1.4648e+02, 2.2011e+02, 1.7451e+02, 2.4838e+02],\n",
            "        [1.3624e+02, 2.5643e+01, 1.6432e+02, 5.4006e+01],\n",
            "        [6.9681e+01, 2.1504e+02, 9.7766e+01, 2.4339e+02],\n",
            "        [1.4149e+02, 1.6908e+02, 1.6950e+02, 1.9741e+02],\n",
            "        [9.5349e+01, 1.7416e+02, 1.2339e+02, 2.0251e+02],\n",
            "        [1.5668e+02, 3.5876e+01, 1.8478e+02, 6.4251e+01],\n",
            "        [1.5165e+02, 2.0997e+02, 1.7964e+02, 2.3825e+02],\n",
            "        [1.6197e+02, 1.7422e+02, 1.8994e+02, 2.0250e+02],\n",
            "        [1.4646e+02, 2.0552e+01, 1.7455e+02, 4.8938e+01],\n",
            "        [1.1657e+02, 1.8386e+02, 1.6827e+02, 2.3480e+02],\n",
            "        [1.6691e+02, 4.1000e+01, 1.9502e+02, 6.9386e+01],\n",
            "        [1.3617e+02, 3.5827e+01, 1.6430e+02, 6.4215e+01],\n",
            "        [9.5454e+01, 1.8440e+02, 1.2343e+02, 2.1266e+02],\n",
            "        [5.9415e+01, 2.0996e+02, 8.7518e+01, 2.3832e+02],\n",
            "        [1.2703e+02, 1.7431e+02, 1.7850e+02, 2.2537e+02],\n",
            "        [1.4639e+02, 4.0933e+01, 1.7453e+02, 6.9330e+01],\n",
            "        [1.5665e+02, 2.5660e+01, 1.8477e+02, 5.4064e+01],\n",
            "        [1.7713e+02, 4.6103e+01, 2.0526e+02, 7.4502e+01],\n",
            "        [9.6118e+01, 1.6391e+02, 1.4776e+02, 2.1556e+02],\n",
            "        [1.6181e+02, 1.6396e+02, 1.8991e+02, 1.9237e+02],\n",
            "        [8.5811e+01, 1.7365e+02, 1.3757e+02, 2.2519e+02],\n",
            "        [1.0553e+02, 1.6908e+02, 1.3362e+02, 1.9747e+02],\n",
            "        [5.9343e+01, 1.1266e+02, 8.7488e+01, 1.4108e+02],\n",
            "        [1.5661e+02, 4.6053e+01, 1.8477e+02, 7.4456e+01],\n",
            "        [8.0011e+01, 2.0484e+02, 1.0806e+02, 2.3318e+02],\n",
            "        [1.7182e+02, 1.9455e+02, 2.0000e+02, 2.2299e+02],\n",
            "        [1.5176e+02, 1.6911e+02, 1.7974e+02, 1.9741e+02],\n",
            "        [1.0684e+02, 1.7416e+02, 1.5821e+02, 2.2524e+02],\n",
            "        [1.2660e+02, 1.5389e+02, 1.7835e+02, 2.0574e+02],\n",
            "        [4.9157e+01, 4.6121e-02, 7.7293e+01, 2.8438e+01],\n",
            "        [1.6683e+02, 5.1175e+01, 1.9500e+02, 7.9589e+01],\n",
            "        [4.9102e+01, 1.1776e+02, 7.7254e+01, 1.4618e+02],\n",
            "        [1.3619e+02, 1.5413e+01, 1.6432e+02, 4.3824e+01],\n",
            "        [1.1576e+02, 1.6910e+02, 1.4385e+02, 1.9750e+02],\n",
            "        [1.8734e+02, 4.6097e+01, 2.1549e+02, 7.4519e+01],\n",
            "        [1.7193e+02, 1.7417e+02, 2.0007e+02, 2.0261e+02],\n",
            "        [1.2592e+02, 3.0713e+01, 1.5407e+02, 5.9124e+01],\n",
            "        [3.8835e+01, 5.0843e+00, 6.7006e+01, 3.3501e+01],\n",
            "        [9.0314e+01, 1.9461e+02, 1.1831e+02, 2.2289e+02],\n",
            "        [1.8356e+01, 5.1002e+00, 4.6525e+01, 3.3519e+01],\n",
            "        [2.8599e+01, 5.0970e+00, 5.6768e+01, 3.3518e+01],\n",
            "        [8.4997e+01, 1.7919e+02, 1.1313e+02, 2.0758e+02],\n",
            "        [1.6687e+02, 3.0767e+01, 1.9501e+02, 5.9193e+01],\n",
            "        [3.8872e+01, 1.1778e+02, 6.7028e+01, 1.4621e+02],\n",
            "        [8.5030e+01, 1.8941e+02, 1.1315e+02, 2.1779e+02],\n",
            "        [1.3117e+02, 1.6906e+02, 1.5925e+02, 1.9745e+02],\n",
            "        [8.5074e+01, 2.2007e+02, 1.1315e+02, 2.4837e+02],\n",
            "        [1.6682e+02, 5.1061e+00, 1.9500e+02, 3.3535e+01],\n",
            "        [1.2591e+02, 2.0492e+01, 1.5407e+02, 4.8915e+01],\n",
            "        [6.9655e+01, 2.0487e+02, 9.7763e+01, 2.3327e+02],\n",
            "        [1.7712e+02, 3.5878e+01, 2.0527e+02, 6.4299e+01],\n",
            "        [5.9327e+01, 2.9645e-02, 8.7495e+01, 2.8442e+01],\n",
            "        [1.3588e+02, 1.8391e+02, 1.8812e+02, 2.3527e+02],\n",
            "        [1.5647e+02, 2.2008e+02, 1.8468e+02, 2.4851e+02],\n",
            "        [1.7703e+02, 5.6285e+01, 2.0523e+02, 8.4730e+01],\n",
            "        [6.9534e+01, 1.0755e+02, 9.7711e+01, 1.3600e+02],\n",
            "        [1.5154e+02, 1.5881e+02, 1.7967e+02, 1.8722e+02],\n",
            "        [1.5660e+02, 1.5396e+01, 1.8476e+02, 4.3833e+01],\n",
            "        [1.4620e+02, 1.5396e+02, 1.9840e+02, 2.0604e+02],\n",
            "        [1.8733e+02, 3.5870e+01, 2.1549e+02, 6.4299e+01],\n",
            "        [9.6102e+01, 1.8352e+02, 1.4789e+02, 2.3467e+02],\n",
            "        [1.0602e+02, 1.5376e+02, 1.5785e+02, 2.0574e+02],\n",
            "        [1.9753e+02, 4.0975e+01, 2.2571e+02, 6.9421e+01],\n",
            "        [1.4647e+02, 3.0758e+01, 1.7455e+02, 5.9114e+01],\n",
            "        [1.5660e+02, 5.1250e+00, 1.8477e+02, 3.3558e+01],\n",
            "        [1.4638e+02, 1.0276e+01, 1.7454e+02, 3.8711e+01],\n",
            "        [1.2586e+02, 4.0935e+01, 1.5405e+02, 6.9383e+01],\n",
            "        [1.8725e+02, 5.6297e+01, 2.1546e+02, 8.4759e+01],\n",
            "        [8.0746e+00, 5.0827e+00, 3.6286e+01, 3.3528e+01],\n",
            "        [1.6173e+02, 2.0481e+02, 1.8983e+02, 2.3317e+02],\n",
            "        [1.1694e+02, 1.6422e+02, 1.6837e+02, 2.1561e+02],\n",
            "        [1.1049e+02, 4.6091e+01, 1.3868e+02, 7.4545e+01],\n",
            "        [4.9120e+01, 1.0756e+02, 7.7283e+01, 1.3600e+02],\n",
            "        [5.9336e+01, 1.0245e+02, 8.7510e+01, 1.3090e+02],\n",
            "        [3.3655e+01, 1.2797e+02, 6.1867e+01, 1.5644e+02],\n",
            "        [1.7700e+02, 5.1101e+00, 2.0521e+02, 3.3568e+01],\n",
            "        [1.3622e+02, 3.0737e+01, 1.6431e+02, 5.9102e+01],\n",
            "        [1.7194e+02, 1.8437e+02, 2.0004e+02, 2.1275e+02],\n",
            "        [7.4845e+01, 2.1504e+02, 1.0291e+02, 2.4337e+02],\n",
            "        [1.9748e+02, 5.1182e+01, 2.2570e+02, 7.9652e+01],\n",
            "        [1.3680e+02, 1.6427e+02, 1.8851e+02, 2.1577e+02],\n",
            "        [1.5556e+02, 1.6404e+02, 2.0819e+02, 2.1626e+02],\n",
            "        [1.3605e+02, 4.6030e+01, 1.6427e+02, 7.4495e+01],\n",
            "        [1.0534e+02, 5.6313e+01, 1.3355e+02, 8.4782e+01],\n",
            "        [1.5668e+02, 3.5876e+01, 1.8478e+02, 6.4251e+01],\n",
            "        [1.9752e+02, 3.0750e+01, 2.2571e+02, 5.9212e+01],\n",
            "        [6.4531e+01, 2.1503e+02, 9.2637e+01, 2.4339e+02],\n",
            "        [7.4854e+01, 1.8309e+02, 1.2718e+02, 2.3490e+02],\n",
            "        [1.1563e+02, 3.5841e+01, 1.4382e+02, 6.4298e+01],\n",
            "        [9.5349e+01, 1.7416e+02, 1.2339e+02, 2.0251e+02],\n",
            "        [5.9205e+01, 2.2001e+02, 8.7459e+01, 2.4846e+02],\n",
            "        [5.9352e+01, 1.9977e+02, 8.7503e+01, 2.2821e+02],\n",
            "        [1.4149e+02, 1.6908e+02, 1.6950e+02, 1.9741e+02],\n",
            "        [1.6680e+02, 2.0494e+01, 1.9499e+02, 4.8959e+01],\n",
            "        [8.4942e+01, 1.6899e+02, 1.1311e+02, 1.9744e+02],\n",
            "        [4.3848e+01, 1.2795e+02, 7.2087e+01, 1.5643e+02],\n",
            "        [1.1556e+02, 5.6308e+01, 1.4378e+02, 8.4787e+01],\n",
            "        [5.9192e+01, 1.2283e+02, 8.7434e+01, 1.5131e+02],\n",
            "        [1.2585e+02, 1.0253e+01, 1.5405e+02, 3.8716e+01],\n",
            "        [2.0773e+02, 4.0954e+01, 2.3595e+02, 6.9431e+01],\n",
            "        [8.4650e+01, 2.2480e+02, 1.1305e+02, 2.5331e+02],\n",
            "        [1.4135e+02, 2.0548e+01, 1.6944e+02, 4.8926e+01],\n",
            "        [1.4574e+02, 1.9934e+01, 1.9823e+02, 7.1978e+01],\n",
            "        [1.4596e+02, 1.7423e+02, 1.9820e+02, 2.2587e+02],\n",
            "        [1.8727e+02, 2.5621e+01, 2.1548e+02, 5.4086e+01],\n",
            "        [2.3427e+01, 1.2798e+02, 5.1647e+01, 1.5646e+02],\n",
            "        [6.9426e+01, 1.1773e+02, 9.7668e+01, 1.4621e+02],\n",
            "        [1.6689e+02, 4.6092e+01, 1.9501e+02, 7.4482e+01],\n",
            "        [1.3605e+02, 1.4348e+02, 1.8825e+02, 1.9577e+02],\n",
            "        [1.1558e+02, 1.3313e+02, 1.4380e+02, 1.6160e+02],\n",
            "        [1.7704e+02, 2.5609e+01, 2.0524e+02, 5.4076e+01],\n",
            "        [1.4639e+02, 4.0933e+01, 1.7453e+02, 6.9330e+01],\n",
            "        [1.0023e+02, 4.6075e+01, 1.2845e+02, 7.4553e+01],\n",
            "        [1.0531e+02, 6.6540e+01, 1.3355e+02, 9.5025e+01],\n",
            "        [2.8584e+01, 1.1778e+02, 5.6791e+01, 1.4625e+02],\n",
            "        [1.4627e+02, 5.1132e+01, 1.7451e+02, 7.9612e+01],\n",
            "        [1.6167e+02, 1.5366e+02, 1.8987e+02, 1.8212e+02],\n",
            "        [9.5166e+01, 1.6389e+02, 1.2335e+02, 1.9235e+02],\n",
            "        [1.2579e+02, 5.1172e+01, 1.5402e+02, 7.9663e+01],\n",
            "        [6.9510e+01, 9.7319e+01, 9.7726e+01, 1.2580e+02],\n",
            "        [1.2581e+02, 1.3312e+02, 1.5403e+02, 1.6160e+02],\n",
            "        [1.7698e+02, 1.5341e+01, 2.0522e+02, 4.3828e+01],\n",
            "        [1.0535e+02, 3.5847e+01, 1.3357e+02, 6.4332e+01],\n",
            "        [1.2528e+02, 1.9849e+01, 1.7782e+02, 7.1941e+01],\n",
            "        [1.1571e+02, 1.4331e+02, 1.6787e+02, 1.9562e+02],\n",
            "        [1.7713e+02, 4.6103e+01, 2.0526e+02, 7.4502e+01],\n",
            "        [4.9050e+01, 2.0477e+02, 7.7239e+01, 2.3320e+02],\n",
            "        [1.5572e+02, 3.0055e+01, 2.0836e+02, 8.2212e+01],\n",
            "        [1.3530e+02, 2.9953e+01, 1.8794e+02, 8.2094e+01],\n",
            "        [1.5141e+02, 1.4850e+02, 1.7963e+02, 1.7698e+02],\n",
            "        [1.5665e+02, 2.5660e+01, 1.8477e+02, 5.4064e+01],\n",
            "        [1.1554e+02, 6.6537e+01, 1.4378e+02, 9.5028e+01],\n",
            "        [1.5661e+02, 4.6053e+01, 1.8477e+02, 7.4456e+01],\n",
            "        [1.6605e+02, 2.0042e+01, 2.1863e+02, 7.2224e+01],\n",
            "        [1.1560e+02, 2.5579e+01, 1.4382e+02, 5.4056e+01],\n",
            "        [2.0768e+02, 5.1157e+01, 2.3593e+02, 7.9659e+01],\n",
            "        [1.3108e+02, 2.0517e+01, 1.5920e+02, 4.8914e+01],\n",
            "        [2.0772e+02, 3.0727e+01, 2.3595e+02, 5.9220e+01],\n",
            "        [1.5649e+02, 5.6240e+01, 1.8474e+02, 8.4728e+01],\n",
            "        [1.6690e+02, 3.5891e+01, 1.9502e+02, 6.4294e+01],\n",
            "        [5.9343e+01, 1.1266e+02, 8.7488e+01, 1.4108e+02],\n",
            "        [1.7182e+02, 1.9455e+02, 2.0000e+02, 2.2299e+02],\n",
            "        [1.3566e+02, 9.9095e+00, 1.8811e+02, 6.2013e+01],\n",
            "        [1.4124e+02, 1.5874e+02, 1.6943e+02, 1.8719e+02],\n",
            "        [1.5599e+02, 1.0012e+01, 2.0848e+02, 6.2196e+01],\n",
            "        [1.6181e+02, 1.6396e+02, 1.8991e+02, 1.9237e+02],\n",
            "        [1.7187e+02, 1.6389e+02, 2.0009e+02, 1.9239e+02],\n",
            "        [1.6670e+02, 6.1361e+01, 1.9497e+02, 8.9863e+01]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0742, 0.0739, 0.0736, 0.0732, 0.0729, 0.0723, 0.0719, 0.0717, 0.0714,\n",
            "        0.0711, 0.0710, 0.0708, 0.0703, 0.0701, 0.0698, 0.0693, 0.0692, 0.0685,\n",
            "        0.0681, 0.0681, 0.0673, 0.0673, 0.0669, 0.0667, 0.0665, 0.0664, 0.0661,\n",
            "        0.0660, 0.0657, 0.0655, 0.0653, 0.0652, 0.0646, 0.0646, 0.0644, 0.0643,\n",
            "        0.0643, 0.0642, 0.0641, 0.0641, 0.0641, 0.0639, 0.0639, 0.0638, 0.0634,\n",
            "        0.0633, 0.0629, 0.0627, 0.0624, 0.0624, 0.0622, 0.0622, 0.0620, 0.0619,\n",
            "        0.0616, 0.0611, 0.0611, 0.0608, 0.0604, 0.0601, 0.0598, 0.0597, 0.0596,\n",
            "        0.0592, 0.0592, 0.0591, 0.0588, 0.0584, 0.0582, 0.0582, 0.0580, 0.0579,\n",
            "        0.0579, 0.0578, 0.0575, 0.0572, 0.0572, 0.0570, 0.0570, 0.0569, 0.0568,\n",
            "        0.0568, 0.0567, 0.0567, 0.0566, 0.0565, 0.0559, 0.0559, 0.0558, 0.0558,\n",
            "        0.0557, 0.0556, 0.0554, 0.0554, 0.0552, 0.0551, 0.0550, 0.0550, 0.0549,\n",
            "        0.0548, 0.0547, 0.0547, 0.0546, 0.0546, 0.0545, 0.0545, 0.0545, 0.0544,\n",
            "        0.0544, 0.0543, 0.0542, 0.0542, 0.0541, 0.0541, 0.0540, 0.0540, 0.0539,\n",
            "        0.0538, 0.0538, 0.0537, 0.0536, 0.0536, 0.0535, 0.0535, 0.0535, 0.0534,\n",
            "        0.0534, 0.0534, 0.0534, 0.0533, 0.0532, 0.0532, 0.0532, 0.0531, 0.0531,\n",
            "        0.0531, 0.0531, 0.0531, 0.0530, 0.0530, 0.0529, 0.0529, 0.0529, 0.0527,\n",
            "        0.0527, 0.0526, 0.0526, 0.0526, 0.0525, 0.0525, 0.0524, 0.0523, 0.0523,\n",
            "        0.0522, 0.0522, 0.0522, 0.0522, 0.0521, 0.0521, 0.0520, 0.0519, 0.0519,\n",
            "        0.0519, 0.0518, 0.0518, 0.0518, 0.0518, 0.0517, 0.0516, 0.0516, 0.0516,\n",
            "        0.0516, 0.0516, 0.0514, 0.0514, 0.0514, 0.0514, 0.0514, 0.0513, 0.0513,\n",
            "        0.0513, 0.0513, 0.0512, 0.0511, 0.0511, 0.0511, 0.0511, 0.0511, 0.0510,\n",
            "        0.0510, 0.0510, 0.0509, 0.0508, 0.0508, 0.0508, 0.0508, 0.0507, 0.0507,\n",
            "        0.0506, 0.0506, 0.0506, 0.0506, 0.0505, 0.0505, 0.0505, 0.0505, 0.0505,\n",
            "        0.0504, 0.0504, 0.0504, 0.0504, 0.0504, 0.0504, 0.0503, 0.0503, 0.0503,\n",
            "        0.0502, 0.0502, 0.0502, 0.0502, 0.0502, 0.0501, 0.0501, 0.0501, 0.0500,\n",
            "        0.0500], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1,\n",
            "        2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1,\n",
            "        2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1,\n",
            "        1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2,\n",
            "        1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
            "        2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2,\n",
            "        2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1,\n",
            "        2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2,\n",
            "        2, 1, 1, 1, 1, 2, 1, 1, 2, 2], device='cuda:0')}]\n",
            "[{'boxes': tensor([[3.4104e+01, 1.1785e+02, 6.1981e+01, 1.4605e+02],\n",
            "        [2.8945e+01, 1.2809e+02, 5.6844e+01, 1.5630e+02],\n",
            "        [2.3822e+01, 1.3833e+02, 5.1724e+01, 1.6655e+02],\n",
            "        [2.3861e+01, 1.1786e+02, 5.1751e+01, 1.4606e+02],\n",
            "        [1.8701e+01, 1.4855e+02, 4.6610e+01, 1.7678e+02],\n",
            "        [4.4275e+01, 1.1783e+02, 7.2184e+01, 1.4605e+02],\n",
            "        [1.8709e+01, 1.2809e+02, 4.6629e+01, 1.5632e+02],\n",
            "        [3.9186e+01, 1.0764e+02, 6.7097e+01, 1.3588e+02],\n",
            "        [3.9090e+01, 1.2804e+02, 6.7039e+01, 1.5628e+02],\n",
            "        [1.3483e+01, 1.0322e+01, 4.1440e+01, 3.8586e+01],\n",
            "        [2.8959e+01, 1.0763e+02, 5.6867e+01, 1.3587e+02],\n",
            "        [1.3492e+01, 2.0563e+01, 4.1456e+01, 4.8833e+01],\n",
            "        [2.8796e+01, 1.4853e+02, 5.6774e+01, 1.7680e+02],\n",
            "        [1.8691e+01, 1.0762e+02, 4.6619e+01, 1.3587e+02],\n",
            "        [1.3577e+01, 1.3833e+02, 4.1519e+01, 1.6658e+02],\n",
            "        [1.8575e+01, 1.5875e+02, 4.6562e+01, 1.8702e+02],\n",
            "        [1.3531e+01, 1.1782e+02, 4.1490e+01, 1.4606e+02],\n",
            "        [3.3907e+01, 1.3829e+02, 6.1893e+01, 1.6657e+02],\n",
            "        [1.3446e+01, 3.0771e+01, 4.1447e+01, 5.9061e+01],\n",
            "        [4.9326e+01, 1.0763e+02, 7.7296e+01, 1.3592e+02],\n",
            "        [3.4104e+01, 1.1785e+02, 6.1981e+01, 1.4605e+02],\n",
            "        [8.4253e+00, 1.6129e-01, 3.6406e+01, 2.8451e+01],\n",
            "        [5.4343e+01, 1.1781e+02, 8.2358e+01, 1.4612e+02],\n",
            "        [1.5168e+02, 1.9975e+02, 1.7970e+02, 2.2806e+02],\n",
            "        [2.8945e+01, 1.2809e+02, 5.6844e+01, 1.5630e+02],\n",
            "        [2.3822e+01, 1.3833e+02, 5.1724e+01, 1.6655e+02],\n",
            "        [1.8701e+01, 1.4855e+02, 4.6610e+01, 1.7678e+02],\n",
            "        [2.3861e+01, 1.1786e+02, 5.1751e+01, 1.4606e+02],\n",
            "        [4.9203e+01, 1.2802e+02, 7.7235e+01, 1.5632e+02],\n",
            "        [4.4275e+01, 1.1783e+02, 7.2184e+01, 1.4605e+02],\n",
            "        [8.3752e+00, 1.5365e+02, 3.6379e+01, 1.8193e+02],\n",
            "        [2.8682e+01, 1.5873e+02, 5.6744e+01, 1.8707e+02],\n",
            "        [8.3574e+00, 1.0759e+02, 3.6372e+01, 1.3589e+02],\n",
            "        [1.8709e+01, 1.2809e+02, 4.6629e+01, 1.5632e+02],\n",
            "        [3.9090e+01, 1.2804e+02, 6.7039e+01, 1.5628e+02],\n",
            "        [3.9186e+01, 1.0764e+02, 6.7097e+01, 1.3588e+02],\n",
            "        [8.4039e+00, 1.0313e+01, 3.6365e+01, 3.8573e+01],\n",
            "        [3.9053e+01, 9.7406e+01, 6.7071e+01, 1.2574e+02],\n",
            "        [1.1072e+02, 7.6869e+01, 1.3873e+02, 1.0517e+02],\n",
            "        [1.5166e+02, 1.8954e+02, 1.7971e+02, 2.1789e+02],\n",
            "        [1.3492e+01, 2.0563e+01, 4.1456e+01, 4.8833e+01],\n",
            "        [2.8959e+01, 1.0763e+02, 5.6867e+01, 1.3587e+02],\n",
            "        [1.3323e+01, 4.0985e+01, 4.1412e+01, 6.9333e+01],\n",
            "        [2.8796e+01, 1.4853e+02, 5.6774e+01, 1.7680e+02],\n",
            "        [1.6183e+02, 1.6390e+02, 1.8990e+02, 1.9224e+02],\n",
            "        [1.4646e+02, 2.0992e+02, 1.7455e+02, 2.3827e+02],\n",
            "        [1.3546e+01, 1.1271e+02, 4.1493e+01, 1.4096e+02],\n",
            "        [1.8575e+01, 1.5875e+02, 4.6562e+01, 1.8702e+02],\n",
            "        [1.7720e+02, 6.6616e+01, 2.0526e+02, 9.4969e+01],\n",
            "        [1.3577e+01, 1.3833e+02, 4.1519e+01, 1.6658e+02],\n",
            "        [2.3501e+01, 2.5657e+01, 5.1602e+01, 5.4039e+01],\n",
            "        [2.8826e+01, 9.7391e+01, 5.6843e+01, 1.2572e+02],\n",
            "        [1.4141e+02, 1.9972e+02, 1.6948e+02, 2.2807e+02],\n",
            "        [3.3907e+01, 1.3829e+02, 6.1893e+01, 1.6657e+02],\n",
            "        [8.2354e+00, 1.6383e+02, 3.6322e+01, 1.9218e+02],\n",
            "        [1.3446e+01, 3.0771e+01, 4.1447e+01, 5.9061e+01],\n",
            "        [2.3601e+01, 1.1247e+02, 7.5679e+01, 1.6399e+02],\n",
            "        [1.8475e+01, 1.4694e-01, 4.6548e+01, 2.8508e+01],\n",
            "        [1.3433e+01, 9.7400e+01, 4.1477e+01, 1.2575e+02],\n",
            "        [8.3293e+00, 1.3315e+02, 3.6382e+01, 1.6148e+02],\n",
            "        [4.4013e+01, 1.3824e+02, 7.2107e+01, 1.6659e+02],\n",
            "        [4.9216e+01, 9.7385e+01, 7.7280e+01, 1.2576e+02],\n",
            "        [2.3500e+01, 1.5421e+01, 5.1605e+01, 4.3808e+01],\n",
            "        [3.3642e+01, 1.0246e+02, 8.5745e+01, 1.5410e+02],\n",
            "        [4.9326e+01, 1.0763e+02, 7.7296e+01, 1.3592e+02],\n",
            "        [3.8860e+01, 1.4849e+02, 6.6972e+01, 1.7687e+02],\n",
            "        [5.9398e+01, 1.0759e+02, 8.7482e+01, 1.3597e+02],\n",
            "        [1.2081e+02, 8.1954e+01, 1.4890e+02, 1.1032e+02],\n",
            "        [2.3442e+01, 3.5869e+01, 5.1577e+01, 6.4276e+01],\n",
            "        [1.5659e+02, 2.0991e+02, 1.8473e+02, 2.3829e+02],\n",
            "        [1.6172e+02, 1.9972e+02, 1.8984e+02, 2.2812e+02],\n",
            "        [1.5672e+02, 1.5370e+02, 1.8480e+02, 1.8207e+02],\n",
            "        [1.6696e+02, 6.6587e+01, 1.9505e+02, 9.4945e+01],\n",
            "        [1.6177e+02, 1.7412e+02, 1.8988e+02, 2.0249e+02],\n",
            "        [2.0783e+02, 9.2218e+01, 2.3596e+02, 1.2063e+02],\n",
            "        [5.4343e+01, 1.1781e+02, 8.2358e+01, 1.4612e+02],\n",
            "        [1.5168e+02, 1.9975e+02, 1.7970e+02, 2.2806e+02],\n",
            "        [1.8492e+01, 1.0312e+01, 4.6512e+01, 3.8624e+01],\n",
            "        [1.5158e+02, 1.6385e+02, 1.7968e+02, 1.9221e+02],\n",
            "        [1.8350e+01, 1.6892e+02, 4.6497e+01, 1.9731e+02],\n",
            "        [1.6175e+02, 1.8951e+02, 1.8987e+02, 2.1792e+02],\n",
            "        [4.9203e+01, 1.2802e+02, 7.7235e+01, 1.5632e+02],\n",
            "        [8.4253e+00, 1.6129e-01, 3.6406e+01, 2.8451e+01],\n",
            "        [2.3888e+01, 9.2263e+01, 7.5841e+01, 1.4397e+02],\n",
            "        [1.8643e+01, 1.0252e+02, 4.6611e+01, 1.3080e+02],\n",
            "        [1.5158e+02, 1.7926e+02, 1.7969e+02, 2.0765e+02],\n",
            "        [8.3752e+00, 1.5365e+02, 3.6379e+01, 1.8193e+02],\n",
            "        [3.2991e+01, 1.2253e+02, 8.5440e+01, 1.7431e+02],\n",
            "        [1.0043e+02, 7.6811e+01, 1.2850e+02, 1.0514e+02],\n",
            "        [2.0779e+02, 1.0242e+02, 2.3595e+02, 1.3083e+02],\n",
            "        [2.8682e+01, 1.5873e+02, 5.6744e+01, 1.8707e+02],\n",
            "        [1.1063e+02, 6.6686e+01, 1.3872e+02, 9.5074e+01],\n",
            "        [2.1799e+02, 1.2805e+02, 2.4617e+02, 1.5651e+02],\n",
            "        [1.4134e+02, 1.8948e+02, 1.6947e+02, 2.1788e+02],\n",
            "        [1.9759e+02, 8.7048e+01, 2.2573e+02, 1.1544e+02],\n",
            "        [1.1052e+02, 8.6984e+01, 1.3866e+02, 1.1535e+02],\n",
            "        [5.9251e+01, 1.2801e+02, 8.7416e+01, 1.5643e+02],\n",
            "        [3.1846e+00, 1.0246e+01, 3.1255e+01, 3.8597e+01],\n",
            "        [1.7716e+02, 5.6423e+01, 2.0528e+02, 8.4838e+01],\n",
            "        [1.7706e+02, 7.6760e+01, 2.0522e+02, 1.0516e+02],\n",
            "        [1.8734e+02, 7.1699e+01, 2.1547e+02, 1.0009e+02],\n",
            "        [2.2708e+01, 1.3254e+02, 7.5274e+01, 1.8441e+02],\n",
            "        [1.7191e+02, 1.6389e+02, 2.0008e+02, 1.9233e+02],\n",
            "        [1.2080e+02, 7.1788e+01, 1.4892e+02, 1.0020e+02],\n",
            "        [2.1290e+02, 1.1780e+02, 2.4108e+02, 1.4624e+02],\n",
            "        [1.1072e+02, 7.6869e+01, 1.3873e+02, 1.0517e+02],\n",
            "        [1.3616e+02, 2.0988e+02, 1.6432e+02, 2.3829e+02],\n",
            "        [1.3323e+01, 4.0985e+01, 4.1412e+01, 6.9333e+01],\n",
            "        [5.9375e+01, 9.7336e+01, 8.7501e+01, 1.2575e+02],\n",
            "        [1.6686e+02, 1.5371e+02, 1.9500e+02, 1.8216e+02],\n",
            "        [1.3232e+01, 5.1222e+01, 4.1387e+01, 7.9631e+01],\n",
            "        [1.5166e+02, 1.8954e+02, 1.7971e+02, 2.1789e+02],\n",
            "        [3.9053e+01, 9.7406e+01, 6.7071e+01, 1.2574e+02],\n",
            "        [4.4000e+01, 8.7115e+01, 7.2141e+01, 1.1554e+02],\n",
            "        [4.3025e+01, 1.1243e+02, 9.5547e+01, 1.6441e+02],\n",
            "        [1.4646e+02, 2.0992e+02, 1.7455e+02, 2.3827e+02],\n",
            "        [1.3628e+01, 1.0203e+02, 6.5733e+01, 1.5385e+02],\n",
            "        [2.1793e+02, 1.3824e+02, 2.4615e+02, 1.6671e+02],\n",
            "        [3.8760e+01, 1.5871e+02, 6.6948e+01, 1.8714e+02],\n",
            "        [1.3146e+01, 1.2220e+02, 6.5512e+01, 1.7406e+02],\n",
            "        [5.4146e+01, 1.3823e+02, 8.2321e+01, 1.6666e+02],\n",
            "        [1.6183e+02, 1.6390e+02, 1.8990e+02, 1.9224e+02],\n",
            "        [4.3432e+01, 9.2222e+01, 9.5803e+01, 1.4424e+02],\n",
            "        [2.8501e+01, 1.6892e+02, 5.6704e+01, 1.9736e+02],\n",
            "        [8.3053e+00, 1.2289e+02, 3.6362e+01, 1.5121e+02],\n",
            "        [1.4641e+02, 1.5362e+02, 1.7455e+02, 1.8203e+02],\n",
            "        [8.3313e+00, 1.0249e+02, 3.6371e+01, 1.3082e+02],\n",
            "        [3.3698e+01, 8.2086e+01, 8.5859e+01, 1.3410e+02],\n",
            "        [1.9757e+02, 7.6853e+01, 2.2572e+02, 1.0527e+02],\n",
            "        [8.2354e+00, 1.6383e+02, 3.6322e+01, 1.9218e+02],\n",
            "        [1.7720e+02, 6.6616e+01, 2.0526e+02, 9.4969e+01],\n",
            "        [2.0778e+02, 8.2008e+01, 2.3595e+02, 1.1047e+02],\n",
            "        [1.8731e+02, 6.1500e+01, 2.1546e+02, 8.9933e+01],\n",
            "        [1.7186e+02, 1.7410e+02, 2.0006e+02, 2.0255e+02],\n",
            "        [1.0037e+02, 6.6619e+01, 1.2849e+02, 9.5015e+01],\n",
            "        [6.4333e+01, 1.1777e+02, 9.2522e+01, 1.4622e+02],\n",
            "        [1.6691e+02, 5.6386e+01, 1.9506e+02, 8.4806e+01],\n",
            "        [1.4141e+02, 1.9972e+02, 1.6948e+02, 2.2807e+02],\n",
            "        [2.3501e+01, 2.5657e+01, 5.1602e+01, 5.4039e+01],\n",
            "        [2.3349e+01, 4.6089e+01, 5.1559e+01, 7.4549e+01],\n",
            "        [8.4924e+01, 1.5364e+02, 1.1308e+02, 1.8205e+02],\n",
            "        [4.4013e+01, 1.3824e+02, 7.2107e+01, 1.6659e+02],\n",
            "        [8.3293e+00, 1.3315e+02, 3.6382e+01, 1.6148e+02],\n",
            "        [2.8826e+01, 9.7391e+01, 5.6843e+01, 1.2572e+02],\n",
            "        [5.4209e+01, 8.7074e+01, 8.2370e+01, 1.1551e+02],\n",
            "        [1.9752e+02, 9.7207e+01, 2.2572e+02, 1.2565e+02],\n",
            "        [3.3760e+01, 8.7101e+01, 6.1916e+01, 1.1553e+02],\n",
            "        [2.1791e+02, 1.0758e+02, 2.4614e+02, 1.3609e+02],\n",
            "        [1.6678e+02, 7.6718e+01, 1.9499e+02, 1.0515e+02],\n",
            "        [1.8729e+02, 8.1858e+01, 2.1548e+02, 1.1028e+02],\n",
            "        [1.5659e+02, 2.0991e+02, 1.8473e+02, 2.3829e+02],\n",
            "        [1.8475e+01, 1.4694e-01, 4.6548e+01, 2.8508e+01],\n",
            "        [3.8860e+01, 1.4849e+02, 6.6972e+01, 1.7687e+02],\n",
            "        [4.9216e+01, 9.7385e+01, 7.7280e+01, 1.2576e+02],\n",
            "        [3.1230e+00, 2.0450e+01, 3.1233e+01, 4.8832e+01],\n",
            "        [2.3442e+01, 3.5869e+01, 5.1577e+01, 6.4276e+01],\n",
            "        [8.1144e+00, 6.1483e+01, 3.6288e+01, 8.9927e+01],\n",
            "        [1.2081e+02, 8.1954e+01, 1.4890e+02, 1.1032e+02],\n",
            "        [6.4423e+01, 8.7058e+01, 9.2606e+01, 1.1550e+02],\n",
            "        [1.6172e+02, 1.9972e+02, 1.8984e+02, 2.2812e+02],\n",
            "        [5.9398e+01, 1.0759e+02, 8.7482e+01, 1.3597e+02],\n",
            "        [1.8350e+01, 1.6892e+02, 4.6497e+01, 1.9731e+02],\n",
            "        [1.6696e+02, 6.6587e+01, 1.9505e+02, 9.4945e+01],\n",
            "        [1.5160e+02, 1.5876e+02, 1.7968e+02, 1.8711e+02],\n",
            "        [2.3601e+01, 1.1247e+02, 7.5679e+01, 1.6399e+02],\n",
            "        [4.9010e+01, 1.4845e+02, 7.7213e+01, 1.7690e+02],\n",
            "        [1.6177e+02, 1.7412e+02, 1.8988e+02, 2.0249e+02],\n",
            "        [2.8505e+01, 5.1438e+00, 5.6708e+01, 3.3601e+01],\n",
            "        [7.4626e+01, 8.7062e+01, 1.0283e+02, 1.1552e+02],\n",
            "        [6.9491e+01, 9.7304e+01, 9.7689e+01, 1.2576e+02],\n",
            "        [2.0272e+02, 9.2192e+01, 2.3085e+02, 1.2058e+02],\n",
            "        [1.2062e+02, 9.2101e+01, 1.4885e+02, 1.2055e+02],\n",
            "        [2.0777e+02, 1.2794e+02, 2.3598e+02, 1.5641e+02],\n",
            "        [2.1788e+02, 9.7338e+01, 2.4613e+02, 1.2586e+02],\n",
            "        [8.0366e+00, 7.1695e+01, 3.6251e+01, 1.0016e+02],\n",
            "        [3.3642e+01, 1.0246e+02, 8.5745e+01, 1.5410e+02],\n",
            "        [8.0728e+00, 8.7097e+01, 3.6289e+01, 1.1558e+02],\n",
            "        [1.6175e+02, 1.8951e+02, 1.8987e+02, 2.1792e+02],\n",
            "        [9.0075e+01, 7.6787e+01, 1.1824e+02, 1.0521e+02],\n",
            "        [1.5158e+02, 1.7926e+02, 1.7969e+02, 2.0765e+02],\n",
            "        [5.4153e+01, 7.6825e+01, 8.2356e+01, 1.0530e+02],\n",
            "        [1.0024e+02, 8.6928e+01, 1.2843e+02, 1.1534e+02],\n",
            "        [2.0779e+02, 1.0242e+02, 2.3595e+02, 1.3083e+02],\n",
            "        [8.0051e+00, 1.7399e+02, 3.6254e+01, 2.0247e+02],\n",
            "        [1.6181e+02, 1.5371e+02, 1.8991e+02, 1.8211e+02],\n",
            "        [1.0043e+02, 7.6811e+01, 1.2850e+02, 1.0514e+02],\n",
            "        [1.5156e+02, 1.6897e+02, 1.7968e+02, 1.9735e+02],\n",
            "        [9.5091e+01, 1.5362e+02, 1.2329e+02, 1.8209e+02],\n",
            "        [1.4123e+02, 1.7919e+02, 1.6944e+02, 2.0766e+02],\n",
            "        [1.5659e+02, 6.6516e+01, 1.8479e+02, 9.4970e+01],\n",
            "        [1.3089e+02, 8.1929e+01, 1.5910e+02, 1.1040e+02],\n",
            "        [1.1052e+02, 8.6984e+01, 1.3866e+02, 1.1535e+02],\n",
            "        [6.4375e+01, 7.6824e+01, 9.2593e+01, 1.0531e+02],\n",
            "        [1.7180e+02, 1.8432e+02, 2.0005e+02, 2.1282e+02],\n",
            "        [5.2886e+01, 1.0217e+02, 1.0566e+02, 1.5456e+02],\n",
            "        [7.4640e+01, 1.5356e+02, 1.0284e+02, 1.8198e+02],\n",
            "        [6.9417e+01, 1.0753e+02, 9.7647e+01, 1.3602e+02],\n",
            "        [4.3911e+01, 7.6832e+01, 7.2127e+01, 1.0531e+02],\n",
            "        [1.8353e+01, 8.7085e+01, 4.6543e+01, 1.1555e+02],\n",
            "        [1.7706e+02, 7.6760e+01, 2.0522e+02, 1.0516e+02]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0676, 0.0670, 0.0668, 0.0666, 0.0665, 0.0664, 0.0652, 0.0649, 0.0646,\n",
            "        0.0645, 0.0643, 0.0641, 0.0638, 0.0637, 0.0632, 0.0632, 0.0630, 0.0628,\n",
            "        0.0627, 0.0623, 0.0614, 0.0611, 0.0611, 0.0611, 0.0609, 0.0608, 0.0606,\n",
            "        0.0606, 0.0605, 0.0605, 0.0603, 0.0599, 0.0595, 0.0594, 0.0590, 0.0589,\n",
            "        0.0588, 0.0587, 0.0587, 0.0586, 0.0584, 0.0583, 0.0582, 0.0582, 0.0581,\n",
            "        0.0580, 0.0579, 0.0579, 0.0577, 0.0576, 0.0576, 0.0575, 0.0575, 0.0574,\n",
            "        0.0573, 0.0573, 0.0573, 0.0572, 0.0572, 0.0571, 0.0571, 0.0568, 0.0568,\n",
            "        0.0565, 0.0565, 0.0565, 0.0564, 0.0564, 0.0564, 0.0562, 0.0562, 0.0561,\n",
            "        0.0560, 0.0560, 0.0558, 0.0558, 0.0557, 0.0557, 0.0556, 0.0556, 0.0555,\n",
            "        0.0555, 0.0554, 0.0553, 0.0553, 0.0552, 0.0552, 0.0550, 0.0549, 0.0549,\n",
            "        0.0549, 0.0545, 0.0544, 0.0544, 0.0544, 0.0544, 0.0542, 0.0542, 0.0541,\n",
            "        0.0541, 0.0541, 0.0540, 0.0540, 0.0539, 0.0537, 0.0536, 0.0536, 0.0535,\n",
            "        0.0535, 0.0535, 0.0535, 0.0535, 0.0534, 0.0534, 0.0534, 0.0534, 0.0534,\n",
            "        0.0533, 0.0533, 0.0533, 0.0532, 0.0532, 0.0532, 0.0531, 0.0530, 0.0530,\n",
            "        0.0529, 0.0529, 0.0529, 0.0529, 0.0528, 0.0528, 0.0528, 0.0527, 0.0527,\n",
            "        0.0526, 0.0526, 0.0526, 0.0525, 0.0525, 0.0525, 0.0524, 0.0523, 0.0522,\n",
            "        0.0522, 0.0522, 0.0521, 0.0519, 0.0519, 0.0519, 0.0518, 0.0518, 0.0517,\n",
            "        0.0517, 0.0517, 0.0517, 0.0517, 0.0516, 0.0516, 0.0514, 0.0514, 0.0514,\n",
            "        0.0514, 0.0514, 0.0514, 0.0514, 0.0514, 0.0514, 0.0513, 0.0512, 0.0512,\n",
            "        0.0511, 0.0511, 0.0510, 0.0510, 0.0509, 0.0508, 0.0508, 0.0507, 0.0505,\n",
            "        0.0505, 0.0505, 0.0505, 0.0505, 0.0505, 0.0504, 0.0504, 0.0504, 0.0504,\n",
            "        0.0503, 0.0503, 0.0503, 0.0502, 0.0502, 0.0502, 0.0502, 0.0501, 0.0501,\n",
            "        0.0500, 0.0500], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
            "        1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1,\n",
            "        2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1,\n",
            "        2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1,\n",
            "        2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2,\n",
            "        2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1,\n",
            "        2, 2, 1, 2, 2, 2, 2, 1], device='cuda:0')}, {'boxes': tensor([[8.5113e+01, 2.0998e+02, 1.1313e+02, 2.3829e+02],\n",
            "        [2.1310e+02, 1.0759e+02, 2.4114e+02, 1.3593e+02],\n",
            "        [8.5120e+01, 1.9978e+02, 1.1315e+02, 2.2811e+02],\n",
            "        [1.2605e+02, 5.1256e+01, 1.5409e+02, 7.9587e+01],\n",
            "        [1.1581e+02, 5.6373e+01, 1.4385e+02, 8.4705e+01],\n",
            "        [1.3623e+02, 4.6132e+01, 1.6430e+02, 7.4484e+01],\n",
            "        [8.4957e+01, 2.2009e+02, 1.1309e+02, 2.4846e+02],\n",
            "        [1.2604e+02, 4.1034e+01, 1.5410e+02, 6.9373e+01],\n",
            "        [1.0553e+02, 6.1472e+01, 1.3360e+02, 8.9820e+01],\n",
            "        [7.4823e+01, 2.0993e+02, 1.0291e+02, 2.3827e+02],\n",
            "        [1.2594e+02, 6.1456e+01, 1.5404e+02, 8.9830e+01],\n",
            "        [1.1579e+02, 4.6137e+01, 1.4386e+02, 7.4494e+01],\n",
            "        [9.5179e+01, 2.0998e+02, 1.2329e+02, 2.3837e+02],\n",
            "        [2.0280e+02, 1.1266e+02, 2.3089e+02, 1.4102e+02],\n",
            "        [2.1295e+02, 1.1773e+02, 2.4108e+02, 1.4611e+02],\n",
            "        [1.3623e+02, 3.5923e+01, 1.6432e+02, 6.4299e+01],\n",
            "        [1.0553e+02, 5.1248e+01, 1.3361e+02, 7.9618e+01],\n",
            "        [1.1569e+02, 6.6552e+01, 1.4380e+02, 9.4925e+01],\n",
            "        [9.5190e+01, 1.9975e+02, 1.2330e+02, 2.2815e+02],\n",
            "        [1.3612e+02, 5.6328e+01, 1.6425e+02, 8.4728e+01],\n",
            "        [8.5113e+01, 2.0998e+02, 1.1313e+02, 2.3829e+02],\n",
            "        [2.2303e+02, 1.0752e+02, 2.5122e+02, 1.3601e+02],\n",
            "        [7.4821e+01, 1.9972e+02, 1.0291e+02, 2.2809e+02],\n",
            "        [1.4642e+02, 1.7413e+02, 1.7453e+02, 2.0252e+02],\n",
            "        [9.5103e+01, 2.2011e+02, 1.2329e+02, 2.4853e+02],\n",
            "        [1.4641e+02, 2.2013e+02, 1.7456e+02, 2.4853e+02],\n",
            "        [9.5227e+01, 6.1460e+01, 1.2336e+02, 8.9859e+01],\n",
            "        [1.4638e+02, 4.1003e+01, 1.7452e+02, 6.9412e+01],\n",
            "        [1.5150e+02, 1.8435e+02, 1.7963e+02, 2.1274e+02],\n",
            "        [1.7198e+02, 1.0244e+02, 2.0012e+02, 1.3086e+02],\n",
            "        [9.5204e+01, 5.1221e+01, 1.2335e+02, 7.9633e+01],\n",
            "        [1.3618e+02, 1.6898e+02, 1.6430e+02, 1.9736e+02],\n",
            "        [1.0029e+02, 7.1674e+01, 1.2844e+02, 1.0008e+02],\n",
            "        [9.0131e+01, 1.8953e+02, 1.1825e+02, 2.1794e+02],\n",
            "        [2.1306e+02, 1.1267e+02, 2.4111e+02, 1.4100e+02],\n",
            "        [1.3104e+02, 1.5874e+02, 1.5917e+02, 1.8714e+02],\n",
            "        [1.5663e+02, 2.2013e+02, 1.8479e+02, 2.4853e+02],\n",
            "        [1.7197e+02, 1.1265e+02, 2.0012e+02, 1.4106e+02],\n",
            "        [7.4677e+01, 2.2005e+02, 1.0287e+02, 2.4846e+02],\n",
            "        [1.2080e+02, 1.5363e+02, 1.4893e+02, 1.8203e+02],\n",
            "        [1.3254e+01, 1.9972e+02, 4.1400e+01, 2.2813e+02],\n",
            "        [1.2605e+02, 5.1256e+01, 1.5409e+02, 7.9587e+01],\n",
            "        [1.6176e+02, 1.0753e+02, 1.8990e+02, 1.3594e+02],\n",
            "        [8.5120e+01, 1.9978e+02, 1.1315e+02, 2.2811e+02],\n",
            "        [1.2596e+02, 3.0792e+01, 1.5408e+02, 5.9197e+01],\n",
            "        [1.9247e+02, 1.1775e+02, 2.2062e+02, 1.4617e+02],\n",
            "        [1.4637e+02, 1.6391e+02, 1.7452e+02, 1.9233e+02],\n",
            "        [1.1581e+02, 5.6373e+01, 1.4385e+02, 8.4705e+01],\n",
            "        [1.5148e+02, 1.1777e+02, 1.7965e+02, 1.4620e+02],\n",
            "        [1.4629e+02, 5.1189e+01, 1.7448e+02, 7.9631e+01],\n",
            "        [1.6688e+02, 2.1506e+02, 1.9502e+02, 2.4347e+02],\n",
            "        [1.2078e+02, 1.6384e+02, 1.4893e+02, 1.9225e+02],\n",
            "        [1.8222e+02, 1.1265e+02, 2.1037e+02, 1.4107e+02],\n",
            "        [1.4125e+02, 1.8431e+02, 1.6940e+02, 2.1271e+02],\n",
            "        [1.6174e+02, 4.8461e-02, 1.8990e+02, 2.8467e+01],\n",
            "        [1.3623e+02, 4.6132e+01, 1.6430e+02, 7.4484e+01],\n",
            "        [1.1572e+02, 3.5878e+01, 1.4385e+02, 6.4290e+01],\n",
            "        [1.3102e+02, 1.4853e+02, 1.5917e+02, 1.7695e+02],\n",
            "        [2.2290e+02, 1.1768e+02, 2.5117e+02, 1.4620e+02],\n",
            "        [1.5153e+02, 2.0998e+02, 1.7967e+02, 2.3839e+02],\n",
            "        [1.6173e+02, 1.1775e+02, 1.8989e+02, 1.4618e+02],\n",
            "        [1.6175e+02, 9.7305e+01, 1.8990e+02, 1.2573e+02],\n",
            "        [1.5150e+02, 1.0754e+02, 1.7966e+02, 1.3597e+02],\n",
            "        [8.4957e+01, 2.2009e+02, 1.1309e+02, 2.4846e+02],\n",
            "        [1.5659e+02, 1.7413e+02, 1.8475e+02, 2.0256e+02],\n",
            "        [1.0545e+02, 4.0995e+01, 1.3360e+02, 6.9421e+01],\n",
            "        [1.7195e+02, 9.2221e+01, 2.0012e+02, 1.2067e+02],\n",
            "        [2.1804e+02, 9.7405e+01, 2.4621e+02, 1.2587e+02],\n",
            "        [2.0277e+02, 1.0245e+02, 2.3090e+02, 1.3086e+02],\n",
            "        [2.8562e+01, 5.1333e+00, 5.6752e+01, 3.3575e+01],\n",
            "        [1.7194e+02, 2.0485e+02, 2.0011e+02, 2.3328e+02],\n",
            "        [2.0262e+02, 1.2284e+02, 2.3082e+02, 1.5128e+02],\n",
            "        [1.0025e+02, 1.8949e+02, 1.2842e+02, 2.1794e+02],\n",
            "        [1.3612e+02, 2.2010e+02, 1.6432e+02, 2.4854e+02],\n",
            "        [9.5165e+01, 4.0993e+01, 1.2333e+02, 6.9434e+01],\n",
            "        [1.2604e+02, 4.1034e+01, 1.5410e+02, 6.9373e+01],\n",
            "        [7.9775e+01, 1.2802e+02, 1.0795e+02, 1.5646e+02],\n",
            "        [1.5145e+02, 1.9457e+02, 1.7963e+02, 2.2299e+02],\n",
            "        [1.4122e+02, 1.5365e+02, 1.6939e+02, 1.8210e+02],\n",
            "        [1.0553e+02, 6.1472e+01, 1.3360e+02, 8.9820e+01],\n",
            "        [7.4823e+01, 2.0993e+02, 1.0291e+02, 2.3827e+02],\n",
            "        [1.2594e+02, 6.1456e+01, 1.5404e+02, 8.9830e+01],\n",
            "        [1.5145e+02, 5.0851e+00, 1.7964e+02, 3.3525e+01],\n",
            "        [1.6170e+02, 1.8434e+02, 1.8987e+02, 2.1277e+02],\n",
            "        [1.1053e+02, 1.5361e+02, 1.3870e+02, 1.8203e+02],\n",
            "        [1.9248e+02, 1.0753e+02, 2.2064e+02, 1.3596e+02],\n",
            "        [1.4636e+02, 3.0770e+01, 1.7453e+02, 5.9220e+01],\n",
            "        [1.2588e+02, 1.7405e+02, 1.5405e+02, 2.0247e+02],\n",
            "        [1.2077e+02, 1.4341e+02, 1.4894e+02, 1.7185e+02],\n",
            "        [7.9872e+01, 1.8950e+02, 1.0801e+02, 2.1792e+02],\n",
            "        [1.8215e+02, 1.2285e+02, 2.1035e+02, 1.5130e+02],\n",
            "        [1.8217e+02, 1.0243e+02, 2.1035e+02, 1.3088e+02],\n",
            "        [1.4126e+02, 2.0997e+02, 1.6943e+02, 2.3840e+02],\n",
            "        [1.2578e+02, 7.1645e+01, 1.5399e+02, 1.0010e+02],\n",
            "        [1.3613e+02, 2.5667e+01, 1.6430e+02, 5.4117e+01],\n",
            "        [9.0014e+01, 7.1656e+01, 1.1822e+02, 1.0011e+02],\n",
            "        [1.1560e+02, 1.7407e+02, 1.4379e+02, 2.0251e+02],\n",
            "        [1.7191e+02, 1.2285e+02, 2.0010e+02, 1.5130e+02],\n",
            "        [1.5141e+02, 1.2798e+02, 1.7962e+02, 1.5645e+02],\n",
            "        [1.1050e+02, 1.6383e+02, 1.3869e+02, 1.9227e+02],\n",
            "        [9.5175e+01, 2.1507e+02, 1.2330e+02, 2.4346e+02],\n",
            "        [6.9535e+01, 1.2800e+02, 9.7731e+01, 1.5646e+02],\n",
            "        [1.6175e+02, 2.0482e+02, 1.8991e+02, 2.3324e+02],\n",
            "        [1.1579e+02, 4.6137e+01, 1.4386e+02, 7.4494e+01],\n",
            "        [1.6171e+02, 1.9455e+02, 1.8988e+02, 2.2298e+02],\n",
            "        [1.7192e+02, 1.9460e+02, 2.0011e+02, 2.2304e+02],\n",
            "        [2.0280e+02, 1.1266e+02, 2.3089e+02, 1.4102e+02],\n",
            "        [8.4864e+01, 4.0947e+01, 1.1307e+02, 6.9406e+01],\n",
            "        [1.1569e+02, 6.6552e+01, 1.4380e+02, 9.4925e+01],\n",
            "        [9.5178e+01, 2.0486e+02, 1.2329e+02, 2.3326e+02],\n",
            "        [2.1812e+02, 1.0251e+02, 2.4623e+02, 1.3092e+02],\n",
            "        [3.3660e+01, 6.6555e+01, 6.1868e+01, 9.5011e+01],\n",
            "        [1.5651e+02, 4.0965e+01, 1.8473e+02, 6.9440e+01],\n",
            "        [1.0536e+02, 1.7921e+02, 1.3356e+02, 2.0767e+02],\n",
            "        [1.3623e+02, 3.5923e+01, 1.6432e+02, 6.4299e+01],\n",
            "        [1.3612e+02, 5.6328e+01, 1.6425e+02, 8.4728e+01],\n",
            "        [1.0553e+02, 5.1248e+01, 1.3361e+02, 7.9618e+01],\n",
            "        [1.7696e+02, 2.1504e+02, 2.0519e+02, 2.4352e+02],\n",
            "        [6.4414e+01, 1.9964e+02, 9.2614e+01, 2.2809e+02],\n",
            "        [1.1049e+02, 1.4338e+02, 1.3869e+02, 1.7184e+02],\n",
            "        [8.9967e+01, 1.2800e+02, 1.1818e+02, 1.5646e+02],\n",
            "        [4.9025e+01, 1.8946e+02, 7.7227e+01, 2.1792e+02],\n",
            "        [1.5148e+02, 9.7296e+01, 1.7966e+02, 1.2575e+02],\n",
            "        [1.4118e+02, 1.1262e+02, 1.6940e+02, 1.4109e+02],\n",
            "        [2.3425e+01, 1.9970e+02, 5.1624e+01, 2.2816e+02],\n",
            "        [1.3139e+01, 2.0987e+02, 4.1369e+01, 2.3833e+02],\n",
            "        [1.3597e+02, 6.6537e+01, 1.6422e+02, 9.5024e+01],\n",
            "        [2.2299e+02, 1.1259e+02, 2.5120e+02, 1.4108e+02],\n",
            "        [1.4118e+02, 1.4339e+02, 1.6939e+02, 1.7187e+02],\n",
            "        [8.0968e+00, 1.8951e+02, 3.6299e+01, 2.1798e+02],\n",
            "        [1.6163e+02, 1.2796e+02, 1.8985e+02, 1.5643e+02],\n",
            "        [1.4641e+02, 1.7924e+02, 1.7453e+02, 2.0762e+02],\n",
            "        [1.4119e+02, 1.0240e+02, 1.6940e+02, 1.3087e+02],\n",
            "        [1.1477e+02, 4.0381e+01, 1.6740e+02, 9.2508e+01],\n",
            "        [7.4821e+01, 1.9972e+02, 1.0291e+02, 2.2809e+02],\n",
            "        [6.9463e+01, 1.3822e+02, 9.7695e+01, 1.6670e+02],\n",
            "        [1.4117e+02, 1.9453e+02, 1.6939e+02, 2.2298e+02],\n",
            "        [1.4117e+02, 1.2285e+02, 1.6940e+02, 1.5133e+02],\n",
            "        [9.5133e+01, 1.7923e+02, 1.2334e+02, 2.0769e+02],\n",
            "        [1.6157e+02, 1.0192e+01, 1.8983e+02, 3.8688e+01],\n",
            "        [9.5207e+01, 1.9464e+02, 1.2332e+02, 2.2305e+02],\n",
            "        [1.4641e+02, 2.2013e+02, 1.7456e+02, 2.4853e+02],\n",
            "        [8.4814e+01, 5.1126e+01, 1.1306e+02, 7.9612e+01],\n",
            "        [9.5227e+01, 6.1460e+01, 1.2336e+02, 8.9859e+01],\n",
            "        [2.8492e+01, 1.5333e+01, 5.6728e+01, 4.3813e+01],\n",
            "        [1.1040e+02, 7.6721e+01, 1.3864e+02, 1.0519e+02],\n",
            "        [1.4130e+02, 1.6901e+02, 1.6941e+02, 1.9739e+02],\n",
            "        [1.2502e+02, 3.0311e+01, 1.7764e+02, 8.2516e+01],\n",
            "        [1.4116e+02, 1.3312e+02, 1.6939e+02, 1.6161e+02],\n",
            "        [1.4635e+02, 4.6098e+01, 1.7450e+02, 7.4513e+01],\n",
            "        [6.4379e+01, 2.0983e+02, 9.2617e+01, 2.3830e+02],\n",
            "        [1.9232e+02, 1.2796e+02, 2.2056e+02, 1.5644e+02],\n",
            "        [2.3412e+01, 6.6532e+01, 5.1638e+01, 9.5003e+01],\n",
            "        [3.8702e+01, 5.1319e+00, 6.6947e+01, 3.3625e+01],\n",
            "        [1.8287e+01, 1.0205e+01, 4.6522e+01, 3.8690e+01],\n",
            "        [1.5653e+02, 1.6388e+02, 1.8475e+02, 1.9236e+02],\n",
            "        [3.3673e+01, 5.6346e+01, 6.1880e+01, 8.4810e+01],\n",
            "        [1.3096e+02, 1.3827e+02, 1.5917e+02, 1.6676e+02],\n",
            "        [1.0491e+02, 3.0262e+01, 1.5739e+02, 8.2405e+01]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0608, 0.0589, 0.0589, 0.0588, 0.0585, 0.0580, 0.0575, 0.0574, 0.0571,\n",
            "        0.0570, 0.0569, 0.0565, 0.0565, 0.0562, 0.0562, 0.0561, 0.0560, 0.0559,\n",
            "        0.0559, 0.0557, 0.0556, 0.0556, 0.0554, 0.0553, 0.0551, 0.0550, 0.0549,\n",
            "        0.0548, 0.0544, 0.0544, 0.0543, 0.0542, 0.0542, 0.0541, 0.0540, 0.0540,\n",
            "        0.0539, 0.0539, 0.0539, 0.0538, 0.0538, 0.0537, 0.0537, 0.0537, 0.0537,\n",
            "        0.0535, 0.0535, 0.0534, 0.0534, 0.0534, 0.0534, 0.0533, 0.0533, 0.0532,\n",
            "        0.0531, 0.0531, 0.0531, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0529,\n",
            "        0.0529, 0.0529, 0.0528, 0.0528, 0.0527, 0.0526, 0.0526, 0.0526, 0.0525,\n",
            "        0.0525, 0.0525, 0.0524, 0.0524, 0.0524, 0.0524, 0.0524, 0.0523, 0.0522,\n",
            "        0.0522, 0.0522, 0.0522, 0.0522, 0.0521, 0.0521, 0.0521, 0.0520, 0.0519,\n",
            "        0.0519, 0.0519, 0.0519, 0.0519, 0.0519, 0.0519, 0.0518, 0.0518, 0.0518,\n",
            "        0.0517, 0.0517, 0.0517, 0.0516, 0.0516, 0.0516, 0.0515, 0.0515, 0.0515,\n",
            "        0.0515, 0.0515, 0.0514, 0.0513, 0.0513, 0.0512, 0.0512, 0.0512, 0.0512,\n",
            "        0.0511, 0.0511, 0.0511, 0.0511, 0.0511, 0.0511, 0.0511, 0.0510, 0.0509,\n",
            "        0.0509, 0.0508, 0.0508, 0.0507, 0.0507, 0.0507, 0.0507, 0.0507, 0.0506,\n",
            "        0.0506, 0.0506, 0.0506, 0.0506, 0.0504, 0.0504, 0.0504, 0.0503, 0.0503,\n",
            "        0.0503, 0.0502, 0.0502, 0.0502, 0.0502, 0.0502, 0.0502, 0.0502, 0.0502,\n",
            "        0.0502, 0.0501, 0.0501, 0.0501, 0.0500, 0.0500], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1,\n",
            "        2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 1,\n",
            "        2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1], device='cuda:0')}, {'boxes': tensor([[1.4673e+02, 3.5931e+01, 1.7461e+02, 6.4130e+01],\n",
            "        [1.5184e+02, 4.6166e+01, 1.7973e+02, 7.4369e+01],\n",
            "        [1.6209e+02, 5.6409e+01, 1.8998e+02, 8.4613e+01],\n",
            "        ...,\n",
            "        [1.2608e+02, 2.9946e+01, 1.7812e+02, 8.1455e+01],\n",
            "        [1.6650e+02, 1.0539e+01, 2.1883e+02, 6.2832e+01],\n",
            "        [1.3619e+02, 1.1050e-01, 1.6435e+02, 2.8550e+01]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0678, 0.0672, 0.0669, 0.0667, 0.0660, 0.0659, 0.0659, 0.0656, 0.0647,\n",
            "        0.0643, 0.0643, 0.0643, 0.0642, 0.0638, 0.0635, 0.0634, 0.0631, 0.0630,\n",
            "        0.0628, 0.0622, 0.0617, 0.0613, 0.0613, 0.0612, 0.0612, 0.0612, 0.0609,\n",
            "        0.0609, 0.0607, 0.0607, 0.0606, 0.0603, 0.0602, 0.0601, 0.0600, 0.0600,\n",
            "        0.0598, 0.0597, 0.0596, 0.0596, 0.0596, 0.0595, 0.0593, 0.0593, 0.0591,\n",
            "        0.0590, 0.0589, 0.0589, 0.0588, 0.0588, 0.0588, 0.0587, 0.0587, 0.0586,\n",
            "        0.0586, 0.0586, 0.0584, 0.0584, 0.0584, 0.0582, 0.0580, 0.0578, 0.0577,\n",
            "        0.0577, 0.0576, 0.0576, 0.0576, 0.0575, 0.0575, 0.0574, 0.0573, 0.0573,\n",
            "        0.0573, 0.0572, 0.0570, 0.0568, 0.0568, 0.0565, 0.0565, 0.0565, 0.0564,\n",
            "        0.0563, 0.0563, 0.0563, 0.0563, 0.0562, 0.0562, 0.0561, 0.0560, 0.0560,\n",
            "        0.0560, 0.0558, 0.0557, 0.0556, 0.0556, 0.0556, 0.0556, 0.0555, 0.0555,\n",
            "        0.0554, 0.0554, 0.0553, 0.0553, 0.0553, 0.0552, 0.0551, 0.0550, 0.0549,\n",
            "        0.0549, 0.0549, 0.0548, 0.0547, 0.0547, 0.0547, 0.0546, 0.0546, 0.0546,\n",
            "        0.0545, 0.0545, 0.0544, 0.0543, 0.0543, 0.0543, 0.0542, 0.0542, 0.0542,\n",
            "        0.0541, 0.0541, 0.0541, 0.0540, 0.0540, 0.0539, 0.0538, 0.0538, 0.0537,\n",
            "        0.0537, 0.0537, 0.0536, 0.0536, 0.0536, 0.0536, 0.0535, 0.0535, 0.0535,\n",
            "        0.0534, 0.0533, 0.0533, 0.0533, 0.0533, 0.0533, 0.0532, 0.0532, 0.0532,\n",
            "        0.0531, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0529, 0.0529, 0.0529,\n",
            "        0.0529, 0.0529, 0.0529, 0.0529, 0.0528, 0.0527, 0.0527, 0.0527, 0.0525,\n",
            "        0.0525, 0.0525, 0.0525, 0.0524, 0.0524, 0.0524, 0.0524, 0.0524, 0.0524,\n",
            "        0.0523, 0.0523, 0.0523, 0.0522, 0.0522, 0.0521, 0.0521, 0.0520, 0.0520,\n",
            "        0.0520, 0.0520, 0.0520, 0.0519, 0.0519, 0.0519, 0.0519, 0.0519, 0.0518,\n",
            "        0.0518, 0.0518, 0.0518, 0.0517, 0.0517, 0.0517, 0.0517, 0.0517, 0.0517,\n",
            "        0.0517, 0.0516, 0.0516, 0.0516, 0.0516, 0.0516, 0.0515, 0.0515, 0.0515,\n",
            "        0.0515, 0.0515, 0.0514, 0.0514, 0.0514, 0.0514, 0.0514, 0.0514, 0.0513,\n",
            "        0.0513, 0.0513, 0.0512, 0.0512, 0.0512, 0.0512, 0.0511, 0.0511, 0.0510,\n",
            "        0.0510, 0.0510, 0.0510, 0.0509, 0.0509, 0.0508, 0.0508, 0.0508, 0.0507,\n",
            "        0.0507, 0.0507, 0.0507, 0.0507, 0.0507, 0.0507, 0.0507, 0.0507, 0.0506,\n",
            "        0.0506, 0.0506, 0.0505, 0.0505, 0.0505, 0.0505, 0.0505, 0.0505, 0.0505,\n",
            "        0.0504, 0.0504, 0.0504, 0.0504, 0.0504, 0.0503, 0.0503, 0.0503, 0.0502,\n",
            "        0.0502, 0.0501, 0.0501, 0.0501, 0.0501, 0.0500, 0.0500, 0.0500],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
            "        1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2,\n",
            "        2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1,\n",
            "        2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1,\n",
            "        1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1,\n",
            "        2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1,\n",
            "        2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2,\n",
            "        2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1,\n",
            "        2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1,\n",
            "        1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2,\n",
            "        1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2,\n",
            "        2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2], device='cuda:0')}, {'boxes': tensor([[111.1628,   5.2051, 138.8268,  33.1962],\n",
            "        [106.0063,  10.3290, 133.7001,  38.3587],\n",
            "        [121.2745,   5.1871, 149.0028,  33.2243],\n",
            "        ...,\n",
            "        [ 74.3106,  81.6632, 126.6203, 133.6767],\n",
            "        [ 74.0648, 101.5397, 126.5581, 153.4631],\n",
            "        [177.3929,  20.3033, 229.3242,  71.7467]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0803, 0.0784, 0.0777, 0.0766, 0.0755, 0.0744, 0.0743, 0.0739, 0.0737,\n",
            "        0.0728, 0.0717, 0.0711, 0.0704, 0.0704, 0.0699, 0.0698, 0.0697, 0.0695,\n",
            "        0.0691, 0.0689, 0.0684, 0.0684, 0.0684, 0.0683, 0.0681, 0.0676, 0.0676,\n",
            "        0.0675, 0.0671, 0.0671, 0.0670, 0.0670, 0.0670, 0.0669, 0.0668, 0.0663,\n",
            "        0.0661, 0.0659, 0.0658, 0.0656, 0.0655, 0.0652, 0.0651, 0.0648, 0.0646,\n",
            "        0.0645, 0.0644, 0.0643, 0.0640, 0.0638, 0.0637, 0.0636, 0.0636, 0.0636,\n",
            "        0.0636, 0.0634, 0.0633, 0.0632, 0.0632, 0.0631, 0.0630, 0.0629, 0.0629,\n",
            "        0.0627, 0.0627, 0.0626, 0.0626, 0.0625, 0.0625, 0.0624, 0.0624, 0.0624,\n",
            "        0.0623, 0.0622, 0.0621, 0.0620, 0.0620, 0.0619, 0.0619, 0.0619, 0.0618,\n",
            "        0.0615, 0.0614, 0.0613, 0.0613, 0.0612, 0.0612, 0.0612, 0.0611, 0.0610,\n",
            "        0.0610, 0.0610, 0.0610, 0.0610, 0.0610, 0.0609, 0.0609, 0.0609, 0.0609,\n",
            "        0.0608, 0.0608, 0.0607, 0.0606, 0.0604, 0.0603, 0.0602, 0.0602, 0.0601,\n",
            "        0.0601, 0.0600, 0.0600, 0.0599, 0.0599, 0.0598, 0.0597, 0.0597, 0.0596,\n",
            "        0.0595, 0.0595, 0.0595, 0.0595, 0.0595, 0.0593, 0.0593, 0.0592, 0.0592,\n",
            "        0.0591, 0.0590, 0.0590, 0.0590, 0.0590, 0.0590, 0.0589, 0.0589, 0.0588,\n",
            "        0.0587, 0.0587, 0.0587, 0.0587, 0.0586, 0.0586, 0.0586, 0.0585, 0.0585,\n",
            "        0.0585, 0.0585, 0.0585, 0.0585, 0.0584, 0.0584, 0.0583, 0.0582, 0.0582,\n",
            "        0.0582, 0.0582, 0.0582, 0.0581, 0.0580, 0.0580, 0.0580, 0.0580, 0.0578,\n",
            "        0.0578, 0.0578, 0.0578, 0.0578, 0.0577, 0.0576, 0.0575, 0.0575, 0.0573,\n",
            "        0.0573, 0.0573, 0.0573, 0.0573, 0.0573, 0.0573, 0.0573, 0.0572, 0.0572,\n",
            "        0.0572, 0.0571, 0.0571, 0.0571, 0.0570, 0.0570, 0.0569, 0.0569, 0.0569,\n",
            "        0.0569, 0.0568, 0.0568, 0.0568, 0.0567, 0.0566, 0.0566, 0.0565, 0.0565,\n",
            "        0.0565, 0.0564, 0.0564, 0.0564, 0.0563, 0.0563, 0.0563, 0.0563, 0.0563,\n",
            "        0.0563, 0.0562, 0.0561, 0.0561, 0.0561, 0.0561, 0.0561, 0.0560, 0.0560,\n",
            "        0.0560, 0.0560, 0.0560, 0.0559, 0.0559, 0.0558, 0.0558, 0.0558, 0.0558,\n",
            "        0.0558, 0.0558, 0.0558, 0.0557, 0.0557, 0.0557, 0.0557, 0.0557, 0.0557,\n",
            "        0.0557, 0.0556, 0.0556, 0.0556, 0.0556, 0.0556, 0.0556, 0.0556, 0.0555,\n",
            "        0.0555, 0.0555, 0.0554, 0.0554, 0.0554, 0.0554, 0.0553, 0.0553, 0.0552,\n",
            "        0.0552, 0.0552, 0.0552, 0.0552, 0.0551, 0.0551, 0.0551, 0.0551, 0.0551,\n",
            "        0.0551, 0.0545, 0.0545, 0.0543, 0.0543, 0.0542, 0.0540, 0.0539, 0.0539,\n",
            "        0.0536, 0.0536, 0.0536, 0.0535, 0.0535, 0.0534, 0.0534, 0.0533, 0.0531,\n",
            "        0.0529, 0.0527, 0.0527, 0.0527, 0.0526, 0.0525, 0.0525, 0.0524, 0.0522,\n",
            "        0.0517, 0.0517, 0.0516, 0.0516, 0.0516, 0.0516, 0.0516, 0.0514, 0.0514,\n",
            "        0.0514, 0.0514, 0.0513], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2,\n",
            "        2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2,\n",
            "        1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2,\n",
            "        2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1,\n",
            "        2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2,\n",
            "        1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1,\n",
            "        1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2,\n",
            "        2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1,\n",
            "        2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2,\n",
            "        2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1,\n",
            "        2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2], device='cuda:0')}]\n",
            "[{'boxes': tensor([[1.9265e+02, 1.6902e+02, 2.2065e+02, 1.9733e+02],\n",
            "        [1.8240e+02, 1.6901e+02, 2.1042e+02, 1.9732e+02],\n",
            "        [1.9773e+02, 1.7924e+02, 2.2576e+02, 2.0756e+02],\n",
            "        [3.3928e+01, 6.7231e-02, 6.1954e+01, 2.8365e+01],\n",
            "        [2.0284e+02, 1.6903e+02, 2.3088e+02, 1.9735e+02],\n",
            "        [1.8747e+02, 1.7922e+02, 2.1552e+02, 2.0755e+02],\n",
            "        [2.0795e+02, 1.7926e+02, 2.3600e+02, 2.0759e+02],\n",
            "        [1.8750e+02, 1.5880e+02, 2.1554e+02, 1.8714e+02],\n",
            "        [2.0792e+02, 1.8947e+02, 2.3599e+02, 2.1782e+02],\n",
            "        [2.3702e+01, 7.1881e-02, 5.1736e+01, 2.8380e+01],\n",
            "        [1.9771e+02, 1.5881e+02, 2.2576e+02, 1.8715e+02],\n",
            "        [4.4030e+01, 5.1064e+00, 7.2124e+01, 3.3448e+01],\n",
            "        [1.9767e+02, 1.8945e+02, 2.2575e+02, 2.1780e+02],\n",
            "        [1.3367e+01, 5.1269e+00, 4.1433e+01, 3.3459e+01],\n",
            "        [1.7718e+02, 1.7919e+02, 2.0527e+02, 2.0755e+02],\n",
            "        [1.7723e+02, 1.5878e+02, 2.0530e+02, 1.8713e+02],\n",
            "        [1.7210e+02, 1.6899e+02, 2.0018e+02, 1.9734e+02],\n",
            "        [2.1806e+02, 1.8438e+02, 2.4619e+02, 2.1279e+02],\n",
            "        [2.1299e+02, 1.6903e+02, 2.4109e+02, 1.9742e+02],\n",
            "        [5.4249e+01, 5.1225e+00, 8.2368e+01, 3.3494e+01],\n",
            "        [2.1801e+02, 1.9460e+02, 2.4617e+02, 2.2302e+02],\n",
            "        [2.0784e+02, 1.9969e+02, 2.3597e+02, 2.2808e+02],\n",
            "        [1.8736e+02, 1.8941e+02, 2.1550e+02, 2.1780e+02],\n",
            "        [1.9263e+02, 1.7413e+02, 2.2065e+02, 2.0243e+02],\n",
            "        [2.0788e+02, 1.5879e+02, 2.3598e+02, 1.8718e+02],\n",
            "        [3.3712e+01, 1.0172e+01, 6.1869e+01, 3.8571e+01],\n",
            "        [1.8741e+02, 1.4855e+02, 2.1552e+02, 1.7694e+02],\n",
            "        [6.4454e+01, 5.1231e+00, 9.2598e+01, 3.3522e+01],\n",
            "        [1.8240e+02, 1.6901e+02, 2.1042e+02, 1.9732e+02],\n",
            "        [1.9264e+02, 1.6392e+02, 2.2066e+02, 1.9223e+02],\n",
            "        [2.0285e+02, 1.7414e+02, 2.3088e+02, 2.0246e+02],\n",
            "        [2.3476e+01, 1.0173e+01, 5.1629e+01, 3.8574e+01],\n",
            "        [3.3928e+01, 6.7231e-02, 6.1954e+01, 2.8365e+01],\n",
            "        [1.7714e+02, 1.4853e+02, 2.0527e+02, 1.7694e+02],\n",
            "        [1.9757e+02, 1.9965e+02, 2.2573e+02, 2.2807e+02],\n",
            "        [2.0283e+02, 1.8436e+02, 2.3088e+02, 2.1269e+02],\n",
            "        [1.6688e+02, 1.7917e+02, 1.9502e+02, 2.0758e+02],\n",
            "        [1.9762e+02, 1.4855e+02, 2.2574e+02, 1.7696e+02],\n",
            "        [1.3614e+02, 2.1503e+02, 1.6430e+02, 2.4345e+02],\n",
            "        [1.9256e+02, 1.8433e+02, 2.2063e+02, 2.1268e+02],\n",
            "        [1.8232e+02, 1.7921e+02, 2.1040e+02, 2.0755e+02],\n",
            "        [2.1303e+02, 1.8438e+02, 2.4110e+02, 2.1273e+02],\n",
            "        [1.2589e+02, 2.1502e+02, 1.5407e+02, 2.4345e+02],\n",
            "        [4.9043e+01, 1.5343e+01, 7.7231e+01, 4.3780e+01],\n",
            "        [2.0283e+02, 1.6392e+02, 2.3088e+02, 1.9226e+02],\n",
            "        [2.3594e+01, 5.0960e+00, 5.1667e+01, 3.3425e+01],\n",
            "        [2.1795e+02, 2.0483e+02, 2.4615e+02, 2.3330e+02],\n",
            "        [4.4030e+01, 5.1064e+00, 7.2124e+01, 3.3448e+01],\n",
            "        [1.6177e+02, 1.6896e+02, 1.8992e+02, 1.9738e+02],\n",
            "        [1.8238e+02, 1.5880e+02, 2.1042e+02, 1.8713e+02],\n",
            "        [1.6690e+02, 1.5873e+02, 1.9505e+02, 1.8715e+02],\n",
            "        [1.7690e+02, 1.5321e+02, 2.2914e+02, 2.0506e+02],\n",
            "        [1.4632e+02, 2.1504e+02, 1.7451e+02, 2.4349e+02],\n",
            "        [1.3367e+01, 5.1269e+00, 4.1433e+01, 3.3459e+01],\n",
            "        [7.4610e+01, 5.1143e+00, 1.0281e+02, 3.3559e+01],\n",
            "        [2.0778e+02, 2.0990e+02, 2.3596e+02, 2.3833e+02],\n",
            "        [1.3612e+02, 2.0483e+02, 1.6429e+02, 2.3327e+02],\n",
            "        [1.8661e+02, 1.6352e+02, 2.3908e+02, 2.1552e+02],\n",
            "        [1.7705e+02, 1.8938e+02, 2.0524e+02, 2.1782e+02],\n",
            "        [2.0788e+02, 1.9458e+02, 2.3598e+02, 2.2295e+02],\n",
            "        [8.0978e+00, 4.6114e+01, 3.6282e+01, 7.4566e+01],\n",
            "        [1.2588e+02, 2.0481e+02, 1.5406e+02, 2.3326e+02],\n",
            "        [2.1301e+02, 1.7415e+02, 2.4110e+02, 2.0252e+02],\n",
            "        [1.1561e+02, 2.1500e+02, 1.4382e+02, 2.4346e+02],\n",
            "        [8.0525e+00, 1.5323e+01, 3.6255e+01, 4.3764e+01],\n",
            "        [2.0780e+02, 1.4854e+02, 2.3596e+02, 1.7698e+02],\n",
            "        [5.9246e+01, 1.5340e+01, 8.7453e+01, 4.3797e+01],\n",
            "        [1.1047e+02, 4.6093e+01, 1.3867e+02, 7.4552e+01],\n",
            "        [1.5659e+02, 1.7918e+02, 1.8477e+02, 2.0763e+02],\n",
            "        [1.7210e+02, 1.6899e+02, 2.0018e+02, 1.9734e+02],\n",
            "        [1.3608e+02, 1.9458e+02, 1.6428e+02, 2.2304e+02],\n",
            "        [1.1558e+02, 5.6307e+01, 1.4379e+02, 8.4771e+01],\n",
            "        [2.1795e+02, 1.5878e+02, 2.4616e+02, 1.8727e+02],\n",
            "        [1.8731e+02, 1.3828e+02, 2.1549e+02, 1.6674e+02],\n",
            "        [1.6645e+02, 1.6307e+02, 2.1887e+02, 2.1499e+02],\n",
            "        [1.4632e+02, 2.0484e+02, 1.7451e+02, 2.3330e+02],\n",
            "        [3.0714e+00, 5.1396e+00, 3.1218e+01, 3.3538e+01],\n",
            "        [1.1562e+02, 2.0480e+02, 1.4381e+02, 2.3327e+02],\n",
            "        [1.4120e+02, 1.8433e+02, 1.6940e+02, 2.1279e+02],\n",
            "        [4.9000e+01, 2.5596e+01, 7.7218e+01, 5.4070e+01],\n",
            "        [1.9257e+02, 1.5368e+02, 2.2065e+02, 1.8205e+02],\n",
            "        [1.9762e+02, 1.9455e+02, 2.2574e+02, 2.2293e+02],\n",
            "        [1.0023e+02, 4.6060e+01, 1.2844e+02, 7.4524e+01],\n",
            "        [1.9753e+02, 1.3827e+02, 2.2572e+02, 1.6674e+02],\n",
            "        [1.8674e+02, 1.4340e+02, 2.3915e+02, 1.9561e+02],\n",
            "        [5.4249e+01, 5.1225e+00, 8.2368e+01, 3.3494e+01],\n",
            "        [2.2292e+02, 1.7409e+02, 2.5120e+02, 2.0266e+02],\n",
            "        [1.0535e+02, 2.0990e+02, 1.3356e+02, 2.3837e+02],\n",
            "        [1.2583e+02, 6.1444e+01, 1.5403e+02, 8.9904e+01],\n",
            "        [8.0398e+00, 5.6305e+01, 3.6264e+01, 8.4777e+01],\n",
            "        [1.2584e+02, 1.9456e+02, 1.5405e+02, 2.2303e+02],\n",
            "        [1.7631e+02, 1.7308e+02, 2.2895e+02, 2.2511e+02],\n",
            "        [1.8725e+02, 1.9962e+02, 2.1548e+02, 2.2809e+02],\n",
            "        [3.8775e+01, 2.0449e+01, 6.6996e+01, 4.8918e+01],\n",
            "        [2.1801e+02, 1.9460e+02, 2.4617e+02, 2.2302e+02],\n",
            "        [1.7706e+02, 1.3827e+02, 2.0526e+02, 1.6675e+02],\n",
            "        [1.7203e+02, 1.7918e+02, 2.0015e+02, 2.0756e+02],\n",
            "        [1.8304e+01, 4.6076e+01, 4.6511e+01, 7.4549e+01],\n",
            "        [1.9750e+02, 2.0987e+02, 2.2572e+02, 2.3833e+02],\n",
            "        [1.3095e+02, 1.8433e+02, 1.5917e+02, 2.1281e+02],\n",
            "        [1.0533e+02, 3.5869e+01, 1.3355e+02, 6.4349e+01],\n",
            "        [2.1788e+02, 2.1502e+02, 2.4614e+02, 2.4353e+02],\n",
            "        [3.3712e+01, 1.0172e+01, 6.1869e+01, 3.8571e+01],\n",
            "        [1.6682e+02, 1.4847e+02, 1.9502e+02, 1.7693e+02],\n",
            "        [1.2581e+02, 5.1218e+01, 1.5403e+02, 7.9698e+01],\n",
            "        [1.4629e+02, 1.9456e+02, 1.7451e+02, 2.2304e+02],\n",
            "        [1.6675e+02, 1.8938e+02, 1.9498e+02, 2.1786e+02],\n",
            "        [1.0531e+02, 5.6266e+01, 1.3355e+02, 8.4752e+01],\n",
            "        [1.6665e+02, 1.4294e+02, 2.1896e+02, 1.9499e+02],\n",
            "        [1.3605e+02, 6.1443e+01, 1.6427e+02, 8.9919e+01],\n",
            "        [1.4632e+02, 1.7408e+02, 1.7453e+02, 2.0255e+02],\n",
            "        [3.8768e+01, 3.0707e+01, 6.6994e+01, 5.9188e+01],\n",
            "        [1.7207e+02, 1.5876e+02, 2.0017e+02, 1.8714e+02],\n",
            "        [1.8271e+01, 5.6288e+01, 4.6502e+01, 8.4772e+01],\n",
            "        [2.0772e+02, 1.3826e+02, 2.3594e+02, 1.6675e+02],\n",
            "        [6.4454e+01, 5.1231e+00, 9.2598e+01, 3.3522e+01],\n",
            "        [1.5650e+02, 1.8941e+02, 1.8474e+02, 2.1789e+02],\n",
            "        [2.1296e+02, 1.6391e+02, 2.4108e+02, 1.9231e+02],\n",
            "        [1.2579e+02, 7.1653e+01, 1.5402e+02, 1.0013e+02],\n",
            "        [2.8509e+01, 4.6064e+01, 5.6746e+01, 7.4558e+01],\n",
            "        [2.0276e+02, 1.5368e+02, 2.3087e+02, 1.8207e+02],\n",
            "        [6.9416e+01, 1.5313e+01, 9.7671e+01, 4.3811e+01],\n",
            "        [1.8228e+02, 1.4855e+02, 2.1040e+02, 1.7694e+02],\n",
            "        [9.5075e+01, 2.0478e+02, 1.2331e+02, 2.3327e+02],\n",
            "        [8.0608e+00, 3.5875e+01, 3.6287e+01, 6.4364e+01],\n",
            "        [2.8495e+01, 5.6296e+01, 5.6740e+01, 8.4793e+01]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0608, 0.0600, 0.0600, 0.0595, 0.0594, 0.0594, 0.0592, 0.0585, 0.0585,\n",
            "        0.0581, 0.0579, 0.0578, 0.0577, 0.0576, 0.0571, 0.0569, 0.0569, 0.0569,\n",
            "        0.0564, 0.0561, 0.0558, 0.0558, 0.0556, 0.0555, 0.0555, 0.0551, 0.0549,\n",
            "        0.0549, 0.0548, 0.0547, 0.0546, 0.0546, 0.0543, 0.0542, 0.0542, 0.0542,\n",
            "        0.0542, 0.0541, 0.0539, 0.0537, 0.0536, 0.0535, 0.0534, 0.0533, 0.0533,\n",
            "        0.0533, 0.0532, 0.0531, 0.0530, 0.0530, 0.0529, 0.0529, 0.0529, 0.0529,\n",
            "        0.0529, 0.0528, 0.0528, 0.0528, 0.0527, 0.0526, 0.0525, 0.0525, 0.0525,\n",
            "        0.0524, 0.0524, 0.0524, 0.0523, 0.0523, 0.0522, 0.0521, 0.0519, 0.0518,\n",
            "        0.0517, 0.0517, 0.0517, 0.0516, 0.0516, 0.0516, 0.0516, 0.0515, 0.0515,\n",
            "        0.0515, 0.0515, 0.0515, 0.0515, 0.0515, 0.0515, 0.0514, 0.0514, 0.0514,\n",
            "        0.0514, 0.0514, 0.0513, 0.0513, 0.0512, 0.0511, 0.0511, 0.0511, 0.0510,\n",
            "        0.0510, 0.0510, 0.0509, 0.0509, 0.0508, 0.0508, 0.0508, 0.0507, 0.0507,\n",
            "        0.0507, 0.0507, 0.0506, 0.0506, 0.0505, 0.0505, 0.0504, 0.0504, 0.0504,\n",
            "        0.0504, 0.0503, 0.0502, 0.0502, 0.0502, 0.0502, 0.0502, 0.0502, 0.0501],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
            "        2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1,\n",
            "        2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
            "        2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2,\n",
            "        1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2,\n",
            "        1, 2, 1, 2, 2, 2], device='cuda:0')}, {'boxes': tensor([[136.6011, 174.1813, 164.4000, 202.3130],\n",
            "        [141.7153, 163.9513, 169.5149, 192.0869],\n",
            "        [131.4345, 184.3994, 159.2684, 212.5538],\n",
            "        ...,\n",
            "        [ 94.9025, 102.3245, 147.1362, 154.2445],\n",
            "        [155.7029, 173.1925, 208.3022, 225.0693],\n",
            "        [146.7694, 143.4674, 198.5847, 194.8471]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0722, 0.0718, 0.0706, 0.0699, 0.0695, 0.0686, 0.0682, 0.0682, 0.0681,\n",
            "        0.0672, 0.0670, 0.0668, 0.0661, 0.0659, 0.0655, 0.0655, 0.0652, 0.0648,\n",
            "        0.0647, 0.0646, 0.0645, 0.0643, 0.0643, 0.0642, 0.0639, 0.0639, 0.0638,\n",
            "        0.0638, 0.0636, 0.0635, 0.0633, 0.0633, 0.0632, 0.0631, 0.0630, 0.0630,\n",
            "        0.0628, 0.0627, 0.0625, 0.0625, 0.0624, 0.0624, 0.0623, 0.0623, 0.0622,\n",
            "        0.0621, 0.0621, 0.0620, 0.0620, 0.0620, 0.0619, 0.0618, 0.0617, 0.0616,\n",
            "        0.0616, 0.0616, 0.0615, 0.0614, 0.0613, 0.0613, 0.0613, 0.0613, 0.0611,\n",
            "        0.0610, 0.0610, 0.0610, 0.0610, 0.0608, 0.0608, 0.0608, 0.0607, 0.0607,\n",
            "        0.0606, 0.0606, 0.0606, 0.0605, 0.0605, 0.0605, 0.0605, 0.0604, 0.0604,\n",
            "        0.0604, 0.0603, 0.0602, 0.0602, 0.0602, 0.0602, 0.0601, 0.0601, 0.0601,\n",
            "        0.0600, 0.0600, 0.0599, 0.0599, 0.0598, 0.0598, 0.0597, 0.0596, 0.0595,\n",
            "        0.0594, 0.0594, 0.0594, 0.0593, 0.0593, 0.0592, 0.0591, 0.0591, 0.0591,\n",
            "        0.0590, 0.0590, 0.0590, 0.0589, 0.0589, 0.0589, 0.0589, 0.0588, 0.0588,\n",
            "        0.0588, 0.0588, 0.0588, 0.0588, 0.0587, 0.0587, 0.0586, 0.0585, 0.0585,\n",
            "        0.0585, 0.0585, 0.0584, 0.0584, 0.0583, 0.0583, 0.0582, 0.0582, 0.0582,\n",
            "        0.0582, 0.0582, 0.0582, 0.0582, 0.0582, 0.0581, 0.0580, 0.0580, 0.0580,\n",
            "        0.0580, 0.0579, 0.0578, 0.0577, 0.0577, 0.0577, 0.0577, 0.0576, 0.0576,\n",
            "        0.0576, 0.0575, 0.0575, 0.0575, 0.0574, 0.0574, 0.0574, 0.0573, 0.0572,\n",
            "        0.0572, 0.0572, 0.0572, 0.0572, 0.0572, 0.0572, 0.0571, 0.0571, 0.0571,\n",
            "        0.0571, 0.0571, 0.0571, 0.0570, 0.0570, 0.0570, 0.0569, 0.0569, 0.0569,\n",
            "        0.0568, 0.0568, 0.0567, 0.0567, 0.0567, 0.0567, 0.0567, 0.0567, 0.0567,\n",
            "        0.0566, 0.0566, 0.0566, 0.0565, 0.0565, 0.0565, 0.0564, 0.0564, 0.0564,\n",
            "        0.0564, 0.0563, 0.0563, 0.0563, 0.0563, 0.0563, 0.0563, 0.0563, 0.0562,\n",
            "        0.0562, 0.0561, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0559, 0.0559,\n",
            "        0.0559, 0.0559, 0.0559, 0.0559, 0.0559, 0.0559, 0.0559, 0.0558, 0.0558,\n",
            "        0.0558, 0.0558, 0.0557, 0.0557, 0.0557, 0.0557, 0.0556, 0.0556, 0.0556,\n",
            "        0.0556, 0.0556, 0.0556, 0.0556, 0.0555, 0.0555, 0.0555, 0.0555, 0.0554,\n",
            "        0.0554, 0.0554, 0.0554, 0.0554, 0.0554, 0.0553, 0.0553, 0.0553, 0.0553,\n",
            "        0.0553, 0.0552, 0.0552, 0.0552, 0.0552, 0.0552, 0.0552, 0.0551, 0.0551,\n",
            "        0.0550, 0.0550, 0.0550, 0.0550, 0.0550, 0.0550, 0.0550, 0.0549, 0.0549,\n",
            "        0.0549, 0.0549, 0.0547, 0.0547, 0.0547, 0.0546, 0.0546, 0.0545, 0.0543,\n",
            "        0.0543, 0.0542, 0.0542, 0.0541, 0.0540, 0.0540, 0.0540, 0.0539, 0.0539,\n",
            "        0.0536, 0.0535, 0.0535, 0.0533, 0.0532, 0.0532, 0.0532, 0.0531, 0.0531,\n",
            "        0.0531, 0.0531, 0.0530], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2,\n",
            "        2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2,\n",
            "        1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2,\n",
            "        2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,\n",
            "        2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2,\n",
            "        1, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2,\n",
            "        1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1,\n",
            "        2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1,\n",
            "        1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2,\n",
            "        2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 1,\n",
            "        2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1,\n",
            "        1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2], device='cuda:0')}, {'boxes': tensor([[ 18.7803,  82.0123,  46.6270, 110.1786],\n",
            "        [ 28.9831,  82.0057,  56.8480, 110.1915],\n",
            "        [  8.5326,  82.0123,  36.4091, 110.2020],\n",
            "        ...,\n",
            "        [ 23.5185, 101.8456,  75.6693, 153.4785],\n",
            "        [165.9502,  60.4995, 218.6408, 112.6150],\n",
            "        [ 43.7169, 102.0216,  95.9554, 153.7377]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0695, 0.0685, 0.0681, 0.0679, 0.0670, 0.0660, 0.0658, 0.0657, 0.0656,\n",
            "        0.0650, 0.0647, 0.0643, 0.0641, 0.0637, 0.0632, 0.0630, 0.0630, 0.0628,\n",
            "        0.0624, 0.0623, 0.0620, 0.0619, 0.0619, 0.0618, 0.0615, 0.0614, 0.0612,\n",
            "        0.0611, 0.0611, 0.0610, 0.0608, 0.0605, 0.0605, 0.0604, 0.0604, 0.0603,\n",
            "        0.0603, 0.0601, 0.0599, 0.0599, 0.0596, 0.0595, 0.0595, 0.0595, 0.0595,\n",
            "        0.0595, 0.0594, 0.0592, 0.0591, 0.0591, 0.0590, 0.0589, 0.0588, 0.0587,\n",
            "        0.0587, 0.0587, 0.0586, 0.0585, 0.0584, 0.0584, 0.0584, 0.0583, 0.0583,\n",
            "        0.0582, 0.0580, 0.0580, 0.0580, 0.0580, 0.0579, 0.0579, 0.0579, 0.0577,\n",
            "        0.0577, 0.0577, 0.0577, 0.0576, 0.0576, 0.0575, 0.0575, 0.0575, 0.0575,\n",
            "        0.0574, 0.0574, 0.0573, 0.0572, 0.0570, 0.0570, 0.0570, 0.0569, 0.0569,\n",
            "        0.0569, 0.0569, 0.0568, 0.0568, 0.0567, 0.0567, 0.0566, 0.0566, 0.0565,\n",
            "        0.0565, 0.0564, 0.0564, 0.0564, 0.0564, 0.0563, 0.0563, 0.0563, 0.0563,\n",
            "        0.0562, 0.0562, 0.0562, 0.0562, 0.0562, 0.0561, 0.0561, 0.0560, 0.0559,\n",
            "        0.0559, 0.0559, 0.0559, 0.0559, 0.0558, 0.0558, 0.0558, 0.0557, 0.0557,\n",
            "        0.0557, 0.0557, 0.0557, 0.0556, 0.0556, 0.0556, 0.0555, 0.0555, 0.0555,\n",
            "        0.0554, 0.0554, 0.0554, 0.0554, 0.0553, 0.0553, 0.0553, 0.0552, 0.0552,\n",
            "        0.0552, 0.0552, 0.0552, 0.0551, 0.0551, 0.0551, 0.0551, 0.0550, 0.0550,\n",
            "        0.0550, 0.0549, 0.0549, 0.0549, 0.0548, 0.0548, 0.0547, 0.0547, 0.0547,\n",
            "        0.0547, 0.0546, 0.0546, 0.0545, 0.0545, 0.0544, 0.0544, 0.0544, 0.0543,\n",
            "        0.0543, 0.0543, 0.0542, 0.0542, 0.0542, 0.0541, 0.0541, 0.0541, 0.0540,\n",
            "        0.0540, 0.0539, 0.0539, 0.0538, 0.0538, 0.0538, 0.0538, 0.0538, 0.0538,\n",
            "        0.0538, 0.0537, 0.0537, 0.0537, 0.0537, 0.0537, 0.0537, 0.0536, 0.0536,\n",
            "        0.0536, 0.0536, 0.0536, 0.0535, 0.0535, 0.0535, 0.0535, 0.0535, 0.0534,\n",
            "        0.0534, 0.0533, 0.0533, 0.0532, 0.0532, 0.0532, 0.0531, 0.0531, 0.0531,\n",
            "        0.0531, 0.0531, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530, 0.0530,\n",
            "        0.0530, 0.0529, 0.0529, 0.0529, 0.0529, 0.0529, 0.0528, 0.0527, 0.0527,\n",
            "        0.0527, 0.0527, 0.0527, 0.0527, 0.0527, 0.0527, 0.0526, 0.0526, 0.0526,\n",
            "        0.0526, 0.0526, 0.0525, 0.0525, 0.0525, 0.0525, 0.0525, 0.0525, 0.0524,\n",
            "        0.0524, 0.0524, 0.0524, 0.0523, 0.0523, 0.0523, 0.0523, 0.0523, 0.0523,\n",
            "        0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0521, 0.0521,\n",
            "        0.0521, 0.0521, 0.0521, 0.0521, 0.0521, 0.0520, 0.0520, 0.0520, 0.0520,\n",
            "        0.0519, 0.0519, 0.0519, 0.0516, 0.0515, 0.0515, 0.0513, 0.0513, 0.0513,\n",
            "        0.0512, 0.0510, 0.0509, 0.0508, 0.0508, 0.0508, 0.0506, 0.0506, 0.0505,\n",
            "        0.0505, 0.0503, 0.0503], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2,\n",
            "        2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1,\n",
            "        1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2,\n",
            "        2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2,\n",
            "        1, 2, 2, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1,\n",
            "        2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1,\n",
            "        1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1,\n",
            "        2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1,\n",
            "        1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2,\n",
            "        1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1,\n",
            "        1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1,\n",
            "        2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2], device='cuda:0')}, {'boxes': tensor([[141.7037,  97.3857, 169.5202, 125.5297],\n",
            "        [136.5743, 107.6206, 164.3982, 135.7689],\n",
            "        [146.8230,  87.1496, 174.6418, 115.2975],\n",
            "        ...,\n",
            "        [ 94.4326, 132.4171, 146.9778, 184.2714],\n",
            "        [127.1314,  61.5198, 178.5842, 112.7205],\n",
            "        [ 23.6905, 163.3956,  75.8229, 215.1530]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0709, 0.0708, 0.0704, 0.0701, 0.0699, 0.0697, 0.0695, 0.0693, 0.0693,\n",
            "        0.0693, 0.0688, 0.0688, 0.0687, 0.0686, 0.0686, 0.0683, 0.0679, 0.0677,\n",
            "        0.0676, 0.0674, 0.0674, 0.0673, 0.0671, 0.0670, 0.0667, 0.0667, 0.0667,\n",
            "        0.0666, 0.0664, 0.0662, 0.0662, 0.0659, 0.0657, 0.0657, 0.0657, 0.0656,\n",
            "        0.0655, 0.0655, 0.0655, 0.0654, 0.0651, 0.0649, 0.0648, 0.0647, 0.0645,\n",
            "        0.0645, 0.0645, 0.0645, 0.0645, 0.0645, 0.0644, 0.0643, 0.0642, 0.0641,\n",
            "        0.0640, 0.0640, 0.0639, 0.0639, 0.0639, 0.0639, 0.0637, 0.0636, 0.0633,\n",
            "        0.0633, 0.0633, 0.0633, 0.0631, 0.0630, 0.0630, 0.0629, 0.0629, 0.0629,\n",
            "        0.0629, 0.0627, 0.0626, 0.0626, 0.0625, 0.0625, 0.0625, 0.0625, 0.0624,\n",
            "        0.0624, 0.0624, 0.0623, 0.0623, 0.0623, 0.0621, 0.0621, 0.0621, 0.0620,\n",
            "        0.0619, 0.0619, 0.0618, 0.0616, 0.0615, 0.0615, 0.0615, 0.0614, 0.0614,\n",
            "        0.0614, 0.0613, 0.0613, 0.0612, 0.0611, 0.0610, 0.0610, 0.0610, 0.0610,\n",
            "        0.0609, 0.0608, 0.0608, 0.0607, 0.0607, 0.0606, 0.0606, 0.0606, 0.0605,\n",
            "        0.0605, 0.0605, 0.0604, 0.0604, 0.0604, 0.0603, 0.0603, 0.0603, 0.0603,\n",
            "        0.0603, 0.0602, 0.0602, 0.0602, 0.0602, 0.0601, 0.0600, 0.0600, 0.0600,\n",
            "        0.0599, 0.0599, 0.0599, 0.0599, 0.0599, 0.0599, 0.0599, 0.0599, 0.0598,\n",
            "        0.0598, 0.0597, 0.0597, 0.0597, 0.0596, 0.0596, 0.0595, 0.0595, 0.0595,\n",
            "        0.0595, 0.0594, 0.0594, 0.0594, 0.0593, 0.0592, 0.0591, 0.0591, 0.0591,\n",
            "        0.0590, 0.0589, 0.0589, 0.0589, 0.0588, 0.0588, 0.0588, 0.0587, 0.0587,\n",
            "        0.0586, 0.0586, 0.0586, 0.0586, 0.0585, 0.0585, 0.0584, 0.0583, 0.0583,\n",
            "        0.0583, 0.0583, 0.0582, 0.0582, 0.0582, 0.0582, 0.0581, 0.0580, 0.0580,\n",
            "        0.0580, 0.0579, 0.0579, 0.0579, 0.0578, 0.0578, 0.0577, 0.0577, 0.0577,\n",
            "        0.0576, 0.0576, 0.0576, 0.0576, 0.0576, 0.0575, 0.0575, 0.0575, 0.0575,\n",
            "        0.0575, 0.0574, 0.0574, 0.0573, 0.0573, 0.0572, 0.0572, 0.0572, 0.0572,\n",
            "        0.0572, 0.0570, 0.0570, 0.0570, 0.0569, 0.0569, 0.0569, 0.0569, 0.0569,\n",
            "        0.0569, 0.0569, 0.0569, 0.0568, 0.0568, 0.0568, 0.0568, 0.0567, 0.0567,\n",
            "        0.0566, 0.0566, 0.0566, 0.0566, 0.0565, 0.0565, 0.0565, 0.0565, 0.0564,\n",
            "        0.0564, 0.0564, 0.0564, 0.0563, 0.0563, 0.0563, 0.0562, 0.0562, 0.0561,\n",
            "        0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560, 0.0560,\n",
            "        0.0560, 0.0559, 0.0559, 0.0559, 0.0559, 0.0559, 0.0559, 0.0558, 0.0558,\n",
            "        0.0557, 0.0557, 0.0557, 0.0557, 0.0556, 0.0556, 0.0556, 0.0556, 0.0555,\n",
            "        0.0555, 0.0554, 0.0554, 0.0553, 0.0553, 0.0553, 0.0552, 0.0552, 0.0552,\n",
            "        0.0551, 0.0551, 0.0550, 0.0548, 0.0546, 0.0545, 0.0544, 0.0542, 0.0541,\n",
            "        0.0541, 0.0541, 0.0540], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1,\n",
            "        2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1,\n",
            "        1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1,\n",
            "        2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1,\n",
            "        2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2,\n",
            "        1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1,\n",
            "        1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 2,\n",
            "        2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1,\n",
            "        2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2,\n",
            "        1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1], device='cuda:0')}]\n",
            "[{'boxes': tensor([[187.8758, 128.1095, 215.6138, 156.1841],\n",
            "        [208.3554, 174.1912, 236.0940, 202.2670],\n",
            "        [198.1161, 179.3103, 225.8550, 207.3860],\n",
            "        ...,\n",
            "        [192.5785,  87.1690, 220.6532, 115.5493],\n",
            "        [156.7345,  92.2426, 184.8260, 120.6225],\n",
            "        [131.2180, 168.9484, 159.2458, 197.2445]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0751, 0.0750, 0.0749, 0.0749, 0.0749, 0.0749, 0.0749, 0.0748, 0.0748,\n",
            "        0.0748, 0.0748, 0.0748, 0.0747, 0.0747, 0.0747, 0.0747, 0.0747, 0.0747,\n",
            "        0.0746, 0.0746, 0.0746, 0.0746, 0.0746, 0.0745, 0.0745, 0.0745, 0.0745,\n",
            "        0.0745, 0.0745, 0.0745, 0.0745, 0.0745, 0.0745, 0.0744, 0.0744, 0.0744,\n",
            "        0.0744, 0.0744, 0.0743, 0.0741, 0.0740, 0.0739, 0.0738, 0.0737, 0.0737,\n",
            "        0.0737, 0.0737, 0.0735, 0.0734, 0.0734, 0.0733, 0.0732, 0.0732, 0.0729,\n",
            "        0.0729, 0.0725, 0.0724, 0.0723, 0.0720, 0.0720, 0.0719, 0.0718, 0.0717,\n",
            "        0.0716, 0.0716, 0.0714, 0.0713, 0.0712, 0.0712, 0.0711, 0.0709, 0.0709,\n",
            "        0.0708, 0.0707, 0.0707, 0.0702, 0.0701, 0.0700, 0.0699, 0.0694, 0.0693,\n",
            "        0.0693, 0.0692, 0.0686, 0.0683, 0.0680, 0.0679, 0.0679, 0.0679, 0.0679,\n",
            "        0.0679, 0.0678, 0.0678, 0.0678, 0.0678, 0.0678, 0.0678, 0.0678, 0.0677,\n",
            "        0.0677, 0.0677, 0.0677, 0.0677, 0.0677, 0.0676, 0.0676, 0.0676, 0.0676,\n",
            "        0.0676, 0.0676, 0.0675, 0.0675, 0.0675, 0.0675, 0.0675, 0.0675, 0.0675,\n",
            "        0.0674, 0.0674, 0.0674, 0.0674, 0.0674, 0.0674, 0.0674, 0.0673, 0.0673,\n",
            "        0.0673, 0.0672, 0.0672, 0.0671, 0.0671, 0.0671, 0.0671, 0.0671, 0.0670,\n",
            "        0.0669, 0.0668, 0.0668, 0.0668, 0.0668, 0.0667, 0.0666, 0.0666, 0.0666,\n",
            "        0.0665, 0.0664, 0.0663, 0.0663, 0.0662, 0.0661, 0.0660, 0.0658, 0.0658,\n",
            "        0.0656, 0.0654, 0.0653, 0.0651, 0.0651, 0.0650, 0.0648, 0.0648, 0.0648,\n",
            "        0.0647, 0.0647, 0.0645, 0.0645, 0.0644, 0.0643, 0.0641, 0.0640, 0.0640,\n",
            "        0.0639, 0.0639, 0.0638, 0.0637, 0.0637, 0.0637, 0.0636, 0.0636, 0.0635,\n",
            "        0.0633, 0.0633, 0.0632, 0.0632, 0.0632, 0.0632, 0.0632, 0.0632, 0.0630,\n",
            "        0.0630, 0.0629, 0.0629, 0.0629, 0.0629, 0.0628, 0.0628, 0.0628, 0.0627,\n",
            "        0.0627, 0.0626, 0.0626, 0.0625, 0.0625, 0.0625, 0.0621, 0.0620, 0.0619,\n",
            "        0.0618, 0.0618, 0.0616, 0.0613, 0.0612, 0.0611, 0.0611, 0.0610, 0.0610,\n",
            "        0.0609, 0.0608, 0.0606, 0.0604, 0.0603, 0.0601, 0.0601, 0.0599, 0.0598,\n",
            "        0.0597, 0.0597, 0.0596, 0.0595, 0.0595, 0.0595, 0.0594, 0.0593, 0.0593,\n",
            "        0.0592, 0.0591, 0.0591, 0.0590, 0.0587, 0.0587, 0.0583, 0.0581, 0.0581,\n",
            "        0.0580, 0.0580, 0.0578, 0.0577, 0.0577, 0.0576, 0.0575, 0.0575, 0.0575,\n",
            "        0.0574, 0.0573, 0.0573, 0.0572, 0.0572, 0.0572, 0.0571, 0.0570, 0.0570,\n",
            "        0.0569, 0.0568, 0.0568, 0.0567, 0.0567, 0.0567, 0.0566, 0.0566, 0.0566,\n",
            "        0.0565, 0.0563, 0.0562, 0.0562, 0.0562, 0.0559, 0.0559, 0.0558, 0.0558,\n",
            "        0.0556, 0.0555, 0.0553, 0.0553, 0.0553, 0.0552, 0.0551, 0.0549, 0.0549,\n",
            "        0.0549, 0.0548, 0.0548, 0.0547, 0.0547, 0.0546, 0.0546, 0.0545, 0.0545,\n",
            "        0.0545, 0.0543, 0.0543], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2,\n",
            "        2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
            "        2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1,\n",
            "        1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2,\n",
            "        1, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1, 1,\n",
            "        2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1,\n",
            "        1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1,\n",
            "        1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2,\n",
            "        1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1], device='cuda:0')}, {'boxes': tensor([[208.1039, 163.9092, 236.0358, 192.1305],\n",
            "        [218.1938,  41.0233, 246.2389,  69.3610],\n",
            "        [218.2144, 163.8817, 246.2119, 192.1658],\n",
            "        [197.8556, 163.9103, 225.8080, 192.1362],\n",
            "        [218.1321, 117.7919, 246.2179, 146.1472],\n",
            "        [218.0785,  51.2134, 246.1942,  79.5972],\n",
            "        [218.2609, 153.7265, 246.2639, 182.0494],\n",
            "        [208.0724, 153.7330, 236.0566, 182.0326],\n",
            "        [156.7223,  92.2180, 184.7845, 120.5513],\n",
            "        [208.1039, 163.9092, 236.0358, 192.1305],\n",
            "        [218.1503,  30.8368, 246.2489,  59.2329],\n",
            "        [202.7478, 174.0372, 230.8369, 202.3616],\n",
            "        [197.7855, 153.7195, 225.7991, 182.0236],\n",
            "        [187.5217, 163.8688, 215.5577, 192.1691],\n",
            "        [151.5853, 102.4558, 179.6712, 130.8181],\n",
            "        [192.5452, 174.0664, 220.6271, 202.3951],\n",
            "        [156.7190,  82.0064, 184.7983, 110.3645],\n",
            "        [223.0110, 127.9569, 251.2230, 156.4239],\n",
            "        [218.1938,  41.0233, 246.2389,  69.3610],\n",
            "        [207.9056,  40.9539, 236.0215,  69.3315],\n",
            "        [218.2144, 163.8817, 246.2119, 192.1658],\n",
            "        [151.5450, 112.6667, 179.6524, 141.0416],\n",
            "        [218.1148, 107.6301, 246.2345, 136.0508],\n",
            "        [197.8556, 163.9103, 225.8080, 192.1362],\n",
            "        [212.8886, 174.0115, 241.0374, 202.3831],\n",
            "        [161.7566, 102.4226, 189.8729, 130.8022],\n",
            "        [166.8458,  92.2006, 194.9707, 120.5910],\n",
            "        [227.4752, 117.6154, 256.0000, 146.4136],\n",
            "        [207.8749, 112.6353, 235.9965, 141.0213],\n",
            "        [ 23.4932, 204.8450,  51.6323, 233.2505],\n",
            "        [227.4202,  40.8069, 256.0000,  69.5791],\n",
            "        [227.4586, 158.5588, 256.0000, 187.3152],\n",
            "        [187.4651, 153.6592, 215.5398, 182.0048],\n",
            "        [166.8328,  82.0022, 194.9784, 110.4356],\n",
            "        [218.0785,  51.2134, 246.1942,  79.5972],\n",
            "        [218.1321, 117.7919, 246.2179, 146.1472],\n",
            "        [161.7390, 112.6493, 189.8773, 141.0485],\n",
            "        [146.4446,  92.1835, 174.5706, 120.5661],\n",
            "        [182.2538, 174.0587, 210.3901, 202.4386],\n",
            "        [207.7972,  51.1256, 235.9813,  79.5533],\n",
            "        [207.8659,  30.7454, 236.0169,  59.1663],\n",
            "        [217.9187,  61.4296, 246.1518,  89.9048],\n",
            "        [223.0535, 143.4065, 251.2595, 171.9037],\n",
            "        [218.2609, 153.7265, 246.2639, 182.0494],\n",
            "        [ 38.8223,   5.1511,  66.9951,  33.5839],\n",
            "        [177.1416, 163.8342, 205.2893, 192.2367],\n",
            "        [171.9265, 102.4170, 200.1017, 130.8456],\n",
            "        [ 18.3748, 194.6294,  46.5390, 223.0626],\n",
            "        [141.2844, 107.5246, 169.4355, 135.9326],\n",
            "        [202.7478, 174.0372, 230.8369, 202.3616],\n",
            "        [146.4158,  81.9382, 174.5678, 110.3472],\n",
            "        [208.0724, 153.7330, 236.0566, 182.0326],\n",
            "        [ 28.6106,   5.1299,  56.7820,  33.5611],\n",
            "        [156.7223,  92.2180, 184.7845, 120.5513],\n",
            "        [182.1677, 112.6540, 210.3533, 141.0958],\n",
            "        [171.9453, 112.6414, 200.1170, 141.0704],\n",
            "        [197.5533, 112.6181, 225.7313, 141.0529],\n",
            "        [ 13.2427, 204.7899,  41.4197, 233.2067],\n",
            "        [227.3329,  51.0130, 256.0000,  79.8032],\n",
            "        [227.4424,  30.6275, 256.0000,  59.4739],\n",
            "        [187.5217, 163.8688, 215.5577, 192.1691],\n",
            "        [218.1503,  30.8368, 246.2489,  59.2329],\n",
            "        [192.5452, 174.0664, 220.6271, 202.3951],\n",
            "        [151.5853, 102.4558, 179.6712, 130.8181],\n",
            "        [197.7855, 153.7195, 225.7991, 182.0236],\n",
            "        [177.1013, 153.6131, 205.2760, 182.0461],\n",
            "        [156.5996,  71.7649, 184.7727, 100.2141],\n",
            "        [ 18.3271,   5.1367,  46.5256,  33.5850],\n",
            "        [ 38.7501,  15.3271,  66.9698,  43.7879],\n",
            "        [223.0110, 127.9569, 251.2230, 156.4239],\n",
            "        [156.5058, 122.8170, 184.7234, 151.2597],\n",
            "        [212.8886, 174.0115, 241.0374, 202.3831],\n",
            "        [ 74.6029, 107.5315, 102.8246, 136.0061],\n",
            "        [207.9056,  40.9539, 236.0215,  69.3315],\n",
            "        [156.7190,  82.0064, 184.7983, 110.3645],\n",
            "        [212.8588, 127.8822, 241.0734, 156.3239],\n",
            "        [212.9952, 143.4181, 241.1307, 171.8413],\n",
            "        [151.5450, 112.6667, 179.6524, 141.0416],\n",
            "        [207.8033, 102.4509, 235.9903, 130.9133],\n",
            "        [141.1811, 117.6972, 169.3927, 146.1378],\n",
            "        [ 23.3317, 214.9641,  51.5925, 243.4379],\n",
            "        [182.1335, 102.4434, 210.3471, 130.9168],\n",
            "        [ 28.5083,  15.3077,  56.7431,  43.7824],\n",
            "        [166.7482, 122.8389, 194.9691, 151.2988],\n",
            "        [ 28.5203, 194.6354,  56.7344, 223.1324]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0618, 0.0602, 0.0600, 0.0600, 0.0579, 0.0577, 0.0576, 0.0571, 0.0564,\n",
            "        0.0563, 0.0562, 0.0561, 0.0559, 0.0559, 0.0556, 0.0554, 0.0552, 0.0550,\n",
            "        0.0550, 0.0549, 0.0549, 0.0548, 0.0547, 0.0547, 0.0546, 0.0544, 0.0544,\n",
            "        0.0543, 0.0540, 0.0539, 0.0537, 0.0536, 0.0535, 0.0531, 0.0531, 0.0531,\n",
            "        0.0531, 0.0530, 0.0530, 0.0525, 0.0525, 0.0525, 0.0524, 0.0523, 0.0523,\n",
            "        0.0520, 0.0519, 0.0518, 0.0518, 0.0518, 0.0518, 0.0518, 0.0518, 0.0517,\n",
            "        0.0517, 0.0516, 0.0514, 0.0514, 0.0513, 0.0512, 0.0511, 0.0510, 0.0510,\n",
            "        0.0509, 0.0509, 0.0508, 0.0507, 0.0507, 0.0507, 0.0507, 0.0506, 0.0505,\n",
            "        0.0504, 0.0504, 0.0504, 0.0504, 0.0504, 0.0503, 0.0503, 0.0502, 0.0502,\n",
            "        0.0501, 0.0501, 0.0501, 0.0501], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
            "        2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1,\n",
            "        2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')}, {'boxes': tensor([[8.0049e+01, 2.2018e+02, 1.0805e+02, 2.4845e+02],\n",
            "        [9.0256e+01, 2.2019e+02, 1.1827e+02, 2.4847e+02],\n",
            "        [6.9777e+01, 2.2016e+02, 9.7816e+01, 2.4846e+02],\n",
            "        [1.0043e+02, 2.2019e+02, 1.2849e+02, 2.4852e+02],\n",
            "        [8.0049e+01, 2.2018e+02, 1.0805e+02, 2.4845e+02],\n",
            "        [9.0256e+01, 2.2019e+02, 1.1827e+02, 2.4847e+02],\n",
            "        [8.1814e+00, 1.6558e-02, 3.6307e+01, 2.8386e+01],\n",
            "        [6.9777e+01, 2.2016e+02, 9.7816e+01, 2.4846e+02],\n",
            "        [1.1055e+02, 2.2020e+02, 1.3870e+02, 2.4861e+02],\n",
            "        [5.9387e+01, 2.2010e+02, 8.7549e+01, 2.4850e+02],\n",
            "        [1.0043e+02, 2.2019e+02, 1.2849e+02, 2.4852e+02],\n",
            "        [7.4805e+01, 2.1007e+02, 1.0292e+02, 2.3849e+02],\n",
            "        [8.5018e+01, 2.1008e+02, 1.1314e+02, 2.3853e+02],\n",
            "        [6.4498e+01, 2.1002e+02, 9.2657e+01, 2.3846e+02],\n",
            "        [8.1814e+00, 1.6558e-02, 3.6307e+01, 2.8386e+01],\n",
            "        [1.7185e+02, 1.3313e+02, 2.0010e+02, 1.6163e+02]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0620, 0.0611, 0.0601, 0.0584, 0.0564, 0.0555, 0.0549, 0.0548, 0.0543,\n",
            "        0.0542, 0.0531, 0.0530, 0.0522, 0.0514, 0.0506, 0.0502],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2], device='cuda:0')}, {'boxes': tensor([[  8.7372,   5.1896,  36.4311,  33.1950],\n",
            "        [ 75.2745,   5.1828, 102.9826,  33.2024],\n",
            "        [ 85.3814,   5.1991, 113.1397,  33.2657],\n",
            "        ...,\n",
            "        [176.2017,  29.9767, 228.7790,  81.6644],\n",
            "        [188.5729, 154.0346, 239.9524, 205.2546],\n",
            "        [ 84.0563,  60.4110, 136.6963, 112.1655]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0794, 0.0786, 0.0755, 0.0751, 0.0742, 0.0741, 0.0740, 0.0739, 0.0738,\n",
            "        0.0736, 0.0734, 0.0732, 0.0731, 0.0730, 0.0729, 0.0727, 0.0726, 0.0724,\n",
            "        0.0724, 0.0723, 0.0718, 0.0717, 0.0717, 0.0716, 0.0716, 0.0715, 0.0714,\n",
            "        0.0709, 0.0707, 0.0707, 0.0706, 0.0705, 0.0702, 0.0701, 0.0698, 0.0698,\n",
            "        0.0697, 0.0697, 0.0697, 0.0696, 0.0693, 0.0693, 0.0692, 0.0692, 0.0692,\n",
            "        0.0691, 0.0687, 0.0687, 0.0684, 0.0684, 0.0683, 0.0683, 0.0683, 0.0681,\n",
            "        0.0679, 0.0679, 0.0679, 0.0677, 0.0676, 0.0674, 0.0674, 0.0673, 0.0672,\n",
            "        0.0672, 0.0672, 0.0671, 0.0671, 0.0670, 0.0669, 0.0669, 0.0668, 0.0668,\n",
            "        0.0666, 0.0665, 0.0665, 0.0664, 0.0663, 0.0663, 0.0663, 0.0663, 0.0662,\n",
            "        0.0662, 0.0662, 0.0661, 0.0660, 0.0658, 0.0657, 0.0657, 0.0656, 0.0656,\n",
            "        0.0656, 0.0655, 0.0655, 0.0654, 0.0654, 0.0654, 0.0653, 0.0653, 0.0653,\n",
            "        0.0653, 0.0652, 0.0652, 0.0651, 0.0650, 0.0650, 0.0650, 0.0650, 0.0649,\n",
            "        0.0649, 0.0649, 0.0649, 0.0648, 0.0648, 0.0648, 0.0648, 0.0646, 0.0646,\n",
            "        0.0646, 0.0645, 0.0645, 0.0644, 0.0644, 0.0644, 0.0643, 0.0643, 0.0643,\n",
            "        0.0642, 0.0640, 0.0640, 0.0639, 0.0639, 0.0638, 0.0637, 0.0635, 0.0634,\n",
            "        0.0634, 0.0633, 0.0633, 0.0633, 0.0633, 0.0632, 0.0632, 0.0630, 0.0630,\n",
            "        0.0629, 0.0629, 0.0629, 0.0629, 0.0629, 0.0629, 0.0629, 0.0628, 0.0628,\n",
            "        0.0628, 0.0627, 0.0627, 0.0627, 0.0625, 0.0625, 0.0625, 0.0624, 0.0623,\n",
            "        0.0622, 0.0622, 0.0622, 0.0621, 0.0621, 0.0621, 0.0620, 0.0620, 0.0620,\n",
            "        0.0618, 0.0617, 0.0617, 0.0617, 0.0615, 0.0615, 0.0614, 0.0614, 0.0614,\n",
            "        0.0613, 0.0613, 0.0613, 0.0613, 0.0613, 0.0611, 0.0611, 0.0611, 0.0610,\n",
            "        0.0610, 0.0610, 0.0610, 0.0609, 0.0609, 0.0609, 0.0609, 0.0608, 0.0608,\n",
            "        0.0608, 0.0608, 0.0608, 0.0608, 0.0607, 0.0607, 0.0606, 0.0605, 0.0605,\n",
            "        0.0604, 0.0604, 0.0604, 0.0604, 0.0603, 0.0603, 0.0601, 0.0601, 0.0601,\n",
            "        0.0601, 0.0601, 0.0600, 0.0600, 0.0600, 0.0599, 0.0599, 0.0599, 0.0598,\n",
            "        0.0598, 0.0597, 0.0597, 0.0597, 0.0596, 0.0596, 0.0596, 0.0595, 0.0595,\n",
            "        0.0595, 0.0595, 0.0594, 0.0594, 0.0594, 0.0594, 0.0593, 0.0593, 0.0593,\n",
            "        0.0593, 0.0593, 0.0593, 0.0593, 0.0592, 0.0592, 0.0592, 0.0591, 0.0590,\n",
            "        0.0590, 0.0589, 0.0589, 0.0589, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588,\n",
            "        0.0587, 0.0587, 0.0587, 0.0587, 0.0587, 0.0587, 0.0586, 0.0586, 0.0585,\n",
            "        0.0585, 0.0585, 0.0585, 0.0585, 0.0583, 0.0576, 0.0576, 0.0574, 0.0570,\n",
            "        0.0567, 0.0565, 0.0565, 0.0564, 0.0563, 0.0562, 0.0562, 0.0561, 0.0561,\n",
            "        0.0560, 0.0559, 0.0557, 0.0557, 0.0557, 0.0556, 0.0554, 0.0553, 0.0553,\n",
            "        0.0548, 0.0546, 0.0545], device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
            "        2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1,\n",
            "        1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1,\n",
            "        2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2, 2, 2,\n",
            "        2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2,\n",
            "        1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2,\n",
            "        1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1,\n",
            "        1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
            "        2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2,\n",
            "        1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2,\n",
            "        2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1,\n",
            "        1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1], device='cuda:0')}]\n",
            "[{'boxes': tensor([[1.9770e+02, 1.0284e+01, 2.2576e+02, 3.8616e+01],\n",
            "        [2.0283e+02, 1.2295e+02, 2.3089e+02, 1.5129e+02],\n",
            "        [2.0793e+02, 1.5393e+01, 2.3599e+02, 4.3733e+01],\n",
            "        [1.8744e+02, 5.1568e+00, 2.1551e+02, 3.3491e+01],\n",
            "        [2.0779e+02, 1.3312e+02, 2.3593e+02, 1.6152e+02],\n",
            "        [2.1806e+02, 2.0516e+01, 2.4619e+02, 4.8921e+01],\n",
            "        [1.7718e+02, 5.5302e-02, 2.0528e+02, 2.8414e+01],\n",
            "        [1.8736e+02, 2.2014e+02, 2.1551e+02, 2.4855e+02],\n",
            "        [1.9758e+02, 2.0436e+01, 2.2573e+02, 4.8828e+01],\n",
            "        [1.8733e+02, 1.5306e+01, 2.1549e+02, 4.3704e+01],\n",
            "        [2.0780e+02, 2.5545e+01, 2.3596e+02, 5.3951e+01],\n",
            "        [2.1288e+02, 1.2296e+02, 2.4104e+02, 1.5140e+02],\n",
            "        [1.9251e+02, 1.2286e+02, 2.2064e+02, 1.5123e+02],\n",
            "        [2.0788e+02, 5.2361e+00, 2.3600e+02, 3.3649e+01],\n",
            "        [2.1803e+02, 1.0339e+01, 2.4619e+02, 3.8792e+01],\n",
            "        [2.0279e+02, 1.2802e+02, 2.3087e+02, 1.5637e+02],\n",
            "        [1.9770e+02, 1.0284e+01, 2.2576e+02, 3.8616e+01],\n",
            "        [1.9753e+02, 1.3303e+02, 2.2572e+02, 1.6145e+02],\n",
            "        [1.7707e+02, 1.0165e+01, 2.0525e+02, 3.8579e+01],\n",
            "        [2.0793e+02, 1.5393e+01, 2.3599e+02, 4.3733e+01],\n",
            "        [2.1794e+02, 3.0691e+01, 2.4615e+02, 5.9153e+01],\n",
            "        [1.9764e+02, 1.1273e+02, 2.2576e+02, 1.4114e+02],\n",
            "        [1.9752e+02, 2.2012e+02, 2.2572e+02, 2.4856e+02],\n",
            "        [1.8744e+02, 5.1568e+00, 2.1551e+02, 3.3491e+01],\n",
            "        [1.7707e+02, 2.2011e+02, 2.0527e+02, 2.4854e+02],\n",
            "        [1.6687e+02, 0.0000e+00, 1.9505e+02, 2.8396e+01],\n",
            "        [2.1806e+02, 2.0516e+01, 2.4619e+02, 4.8921e+01],\n",
            "        [1.7713e+02, 5.0822e+00, 2.0526e+02, 3.3440e+01],\n",
            "        [1.9761e+02, 1.8162e-01, 2.2578e+02, 2.8652e+01],\n",
            "        [2.0281e+02, 1.1786e+02, 2.3089e+02, 1.4624e+02],\n",
            "        [1.1557e+02, 1.0241e+01, 1.4378e+02, 3.8695e+01],\n",
            "        [1.0535e+02, 5.1103e+00, 1.3355e+02, 3.3563e+01],\n",
            "        [2.0778e+02, 1.1276e+02, 2.3596e+02, 1.4124e+02],\n",
            "        [1.9758e+02, 2.0436e+01, 2.2573e+02, 4.8828e+01],\n",
            "        [1.2580e+02, 1.5374e+01, 1.5401e+02, 4.3847e+01],\n",
            "        [1.8736e+02, 2.2014e+02, 2.1551e+02, 2.4855e+02],\n",
            "        [1.3602e+02, 2.5604e+01, 1.6426e+02, 5.4085e+01],\n",
            "        [2.0769e+02, 2.2008e+02, 2.3595e+02, 2.4857e+02],\n",
            "        [2.1286e+02, 1.2804e+02, 2.4102e+02, 1.5647e+02],\n",
            "        [1.8733e+02, 1.5306e+01, 2.1549e+02, 4.3704e+01],\n",
            "        [2.0780e+02, 2.5545e+01, 2.3596e+02, 5.3951e+01],\n",
            "        [1.8732e+02, 2.1002e+02, 2.1552e+02, 2.3850e+02],\n",
            "        [9.5063e+01, 5.0642e+00, 1.2330e+02, 3.3534e+01],\n",
            "        [2.0758e+02, 1.4330e+02, 2.3588e+02, 1.7183e+02],\n",
            "        [1.8734e+02, 1.1265e+02, 2.1552e+02, 1.4109e+02]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0589, 0.0587, 0.0585, 0.0582, 0.0569, 0.0568, 0.0566, 0.0555, 0.0554,\n",
            "        0.0548, 0.0547, 0.0544, 0.0543, 0.0543, 0.0541, 0.0538, 0.0538, 0.0538,\n",
            "        0.0537, 0.0535, 0.0535, 0.0534, 0.0533, 0.0532, 0.0530, 0.0526, 0.0520,\n",
            "        0.0520, 0.0516, 0.0516, 0.0516, 0.0515, 0.0514, 0.0511, 0.0509, 0.0508,\n",
            "        0.0507, 0.0506, 0.0506, 0.0506, 0.0505, 0.0505, 0.0504, 0.0503, 0.0501],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1,\n",
            "        2, 2, 1, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2],\n",
            "       device='cuda:0')}, {'boxes': tensor([[2.1302e+02, 1.1782e+02, 2.4110e+02, 1.4618e+02],\n",
            "        [2.0790e+02, 1.0760e+02, 2.3599e+02, 1.3598e+02],\n",
            "        [2.0273e+02, 1.1774e+02, 2.3086e+02, 1.4612e+02],\n",
            "        [2.1799e+02, 1.2801e+02, 2.4616e+02, 1.5643e+02],\n",
            "        [1.9762e+02, 1.0752e+02, 2.2575e+02, 1.3591e+02],\n",
            "        [2.0273e+02, 9.7349e+01, 2.3086e+02, 1.2576e+02],\n",
            "        [2.0778e+02, 1.2793e+02, 2.3596e+02, 1.5634e+02],\n",
            "        [2.1302e+02, 1.1782e+02, 2.4110e+02, 1.4618e+02],\n",
            "        [2.1796e+02, 1.0761e+02, 2.4616e+02, 1.3610e+02],\n",
            "        [2.0277e+02, 1.1266e+02, 2.3087e+02, 1.4103e+02],\n",
            "        [1.9245e+02, 9.7267e+01, 2.2063e+02, 1.2570e+02],\n",
            "        [2.1286e+02, 9.7345e+01, 2.4105e+02, 1.2582e+02],\n",
            "        [2.2292e+02, 1.1777e+02, 2.5119e+02, 1.4633e+02],\n",
            "        [1.3097e+02, 2.1168e-02, 1.5918e+02, 2.8474e+01],\n",
            "        [2.0265e+02, 8.7089e+01, 2.3085e+02, 1.1555e+02],\n",
            "        [1.2074e+02, 1.0520e-02, 1.4894e+02, 2.8462e+01],\n",
            "        [2.0276e+02, 1.0247e+02, 2.3087e+02, 1.3085e+02],\n",
            "        [2.1292e+02, 1.2798e+02, 2.4107e+02, 1.5637e+02],\n",
            "        [1.4111e+02, 5.0519e+00, 1.6936e+02, 3.3533e+01],\n",
            "        [1.1047e+02, 0.0000e+00, 1.3870e+02, 2.8455e+01],\n",
            "        [2.1296e+02, 1.0761e+02, 2.4109e+02, 1.3602e+02],\n",
            "        [2.1785e+02, 1.3818e+02, 2.4613e+02, 1.6668e+02],\n",
            "        [1.9240e+02, 8.7038e+01, 2.2061e+02, 1.1551e+02],\n",
            "        [1.0020e+02, 0.0000e+00, 1.2844e+02, 2.8442e+01]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'scores': tensor([0.0580, 0.0569, 0.0556, 0.0551, 0.0546, 0.0545, 0.0532, 0.0530, 0.0521,\n",
            "        0.0521, 0.0517, 0.0517, 0.0517, 0.0517, 0.0514, 0.0513, 0.0510, 0.0508,\n",
            "        0.0507, 0.0507, 0.0504, 0.0503, 0.0502, 0.0500], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2],\n",
            "       device='cuda:0')}]\n"
          ]
        }
      ],
      "source": [
        "for i, data in enumerate(valid_dl):\n",
        "        X, y = get_loop_data(data)\n",
        "        output = model_GM(X)\n",
        "        print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w33yDvHYZygP"
      },
      "outputs": [],
      "source": [
        "x = [[5,6,7,8], [1, 2, 3, 4]]\n",
        "y = torch.tensor(x)\n",
        "y.tolist()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MIDOG_PyTorch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}